
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Fine-Tuning Small Language Models in DSPy &#8212; DSPy: The Complete Guide</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=9c3e77be" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=1ae7504c"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'content/05_optimizers/05_finetuning';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Choosing Optimizers: Decision Guide and Trade-offs" href="06_choosing_optimizers.html" />
    <link rel="prev" title="KNNFewShot: Similarity-Based Example Selection" href="04_knnfewshot.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../00_frontmatter/00_preface.html">
  
  
  
  
  
  
    <p class="title logo__title">DSPy: The Complete Guide</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../00_frontmatter/01_how_to_use_this_book.html">How to Use This Book</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_frontmatter/02_prerequisites.html">Prerequisites</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00_frontmatter/03_setup_instructions.html">Setup Instructions</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 1 - Fundamentals</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../01_fundamentals/00_chapter_intro.html">Chapter 1: DSPy Fundamentals</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../01_fundamentals/01_what_is_dspy.html">What is DSPy?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01_fundamentals/02_programming_vs_prompting.html">Programming vs. Prompting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01_fundamentals/03_installation_setup.html">Installation and Setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01_fundamentals/04_first_dspy_program.html">Your First DSPy Program</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01_fundamentals/05_language_models.html">Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../01_fundamentals/06_exercises.html">Chapter 1 Exercises</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 2 - Signatures</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../02_signatures/00_chapter_intro.html">Chapter 2: Signatures</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../02_signatures/01_understanding_signatures.html">Understanding Signatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02_signatures/02_signature_syntax.html">Signature Syntax</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02_signatures/03_typed_signatures.html">Typed Signatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02_signatures/04_advanced_signatures.html">Advanced Signatures</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02_signatures/05_practical_examples.html">Practical Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../02_signatures/06_exercises.html">Chapter 2 Exercises</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 3 - Modules</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../03_modules/00_chapter_intro.html">Chapter 3: Modules</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../03_modules/01_module_basics.html">Module Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03_modules/02_predict_module.html">The Predict Module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03_modules/02a_typed_predictor.html">TypedPredictor: Type-Safe Language Model Wrappers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03_modules/03_chainofthought.html">Chain of Thought Module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03_modules/04_react_agents.html">ReAct Agents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03_modules/05_custom_modules.html">Custom Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03_modules/06_composing_modules.html">Composing Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03_modules/07_exercises.html">Chapter 3 Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../03_modules/08_assertions.html">Assertions Module</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 4 - Evaluation</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../04_evaluation/00_chapter_intro.html">Chapter 4: Evaluation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../04_evaluation/01_why_evaluation_matters.html">Why Evaluation Matters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04_evaluation/02_creating_datasets.html">Creating Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04_evaluation/03_defining_metrics.html">Defining Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04_evaluation/04_evaluation_loops.html">Evaluation Loops</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04_evaluation/05_best_practices.html">Best Practices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04_evaluation/06_exercises.html">Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04_evaluation/07_structured_prompting.html">Structured Prompting for Robust Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04_evaluation/08_llm_as_a_judge.html">LLM-as-a-Judge for Context-Sensitive Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../04_evaluation/09_human_aligned_evaluation.html">Human-Aligned Evaluation: Capturing What Really Matters</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 5 - Optimizers</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="00_chapter_intro.html">Chapter 5: Optimizers &amp; Compilation</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="01_compilation_concept.html">The Compilation Concept in DSPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="02_bootstrapfewshot.html">BootstrapFewShot: Automatic Few-Shot Example Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="02a_copro.html">COPRO: Chain-of-Thought Prompt Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="03_mipro.html">MIPRO: Multi-step Instruction and Demonstration Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="04_knnfewshot.html">KNNFewShot: Similarity-Based Example Selection</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Fine-Tuning Small Language Models in DSPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="06_choosing_optimizers.html">Choosing Optimizers: Decision Guide and Trade-offs</a></li>
<li class="toctree-l2"><a class="reference internal" href="07_constraint_driven_optimization.html">Constraint-Driven Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="07_exercises.html">Chapter 5 Exercises: Optimizers &amp; Compilation</a></li>
<li class="toctree-l2"><a class="reference internal" href="08_reflective_prompt_evolution.html">Reflective Prompt Evolution (RPE): Evolutionary Optimization Without Gradients</a></li>
<li class="toctree-l2"><a class="reference internal" href="09_copa_compiler_method.html">COPA: Compiler and Prompt Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="09a_copa_method.html">COPA: Combined Fine-Tuning and Prompt Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="10_joint_optimization.html">Joint Optimization: Fine-Tuning and Prompt Synergy</a></li>
<li class="toctree-l2"><a class="reference internal" href="11_monte_carlo_optimization.html">Monte Carlo Optimization in DSPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="12_bayesian_optimization.html">Bayesian Optimization for Prompt Tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="13_comprehensive_examples.html">Comprehensive Examples and Implementation Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="14_multistage_optimization_theory.html">Multi-stage Optimization Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="15_instruction_tuning_frameworks.html">Instruction Tuning Frameworks</a></li>
<li class="toctree-l2"><a class="reference internal" href="16_demonstration_optimization.html">Demonstration Optimization Strategies</a></li>
<li class="toctree-l2"><a class="reference internal" href="17_multistage_architectures.html">Multi-stage Program Architectures</a></li>
<li class="toctree-l2"><a class="reference internal" href="18_complex_pipeline_optimization.html">Optimization Strategies for Complex Pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="19_instruction_demonstration_interactions.html">Instruction and Demonstration Interaction Effects</a></li>
<li class="toctree-l2"><a class="reference internal" href="20_prompts_as_hyperparameters.html">Prompts as Auto-Optimized Hyperparameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="21_minimal_data_pipelines.html">Minimal Data Training Pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="22_gepa_genetic_pareto_optimization.html">GEPA: Genetic-Pareto Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="23_state_space_prompt_optimization.html">State-Space Search for Prompt Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="24_inpars_plus_synthetic_data_ir.html">InPars+: Advanced Synthetic Data Generation for Information Retrieval</a></li>
<li class="toctree-l2"><a class="reference internal" href="25_custom_mipro_enhanced_optimization.html">CustomMIPROv2: Enhanced Multi-Stage Prompt Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="26_automatic_prompt_optimization_research.html">Automatic Prompt Optimization: When AI Outperforms Humans</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 6 - Real-World Applications</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../06_real_world_applications/00_chapter_intro.html">Chapter 6: Building Real-World Applications</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../06_real_world_applications/01_rag_systems.html">RAG Systems: Building Intelligent Document Q&amp;A</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06_real_world_applications/02_multi_hop_search.html">Multi-hop Search: Complex Reasoning Across Documents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06_real_world_applications/03_classification_tasks.html">Classification Tasks: Building Robust Text Categorization Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06_real_world_applications/04_entity_extraction.html">Entity Extraction: Mining Structured Information from Text</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06_real_world_applications/05_intelligent_agents.html">Intelligent Agents: Building Autonomous Problem-Solving Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06_real_world_applications/06_code_generation.html">Code Generation: Building Automated Programming Assistants</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06_real_world_applications/07_exercises.html">Chapter 6 Exercises: Building Real-World Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06_real_world_applications/07a_perspective_driven_research.html">Perspective-Driven Research for Article Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06_real_world_applications/08_extreme_multilabel_classification.html">Extreme Multi-Label Classification: Scaling to Millions of Labels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06_real_world_applications/08a_long_form_generation.html">Long-form Article Generation with DSPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06_real_world_applications/09_outline_generation.html">Outline Generation for Structured Article Writing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06_real_world_applications/11_extreme_few_shot_learning.html">Extreme Few-Shot Learning: Training with 10 Gold Labels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06_real_world_applications/12_ir_model_training_scratch.html">IR Model Training from Scratch: Methodology and Best Practices</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06_real_world_applications/13_lingvarbench_healthcare_synthetic_data.html">LingVarBench: Synthetic Healthcare Transcript Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06_real_world_applications/14_scientific_figure_caption_generation.html">Scientific Figure Caption Generation with DSPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06_real_world_applications/15_retrieval_augmented_guardrails.html">Retrieval-Augmented Guardrails for AI Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06_real_world_applications/16_graphrag_wikipedia_tidb_tutorial.html">GraphRAG from Wikipedia: Building with DSPy, OpenAI, and TiDB</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06_real_world_applications/17_framework_comparisons_dspy_ecosystem.html">Framework Comparisons in the DSPy Ecosystem</a></li>
<li class="toctree-l2"><a class="reference internal" href="../06_real_world_applications/18_multi_agent_rag_systems.html">Multi-Agent RAG Systems with DSPy</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 7 - Advanced Topics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../07_advanced_topics/00_chapter_intro.html">Chapter 7: Advanced Topics</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../07_advanced_topics/01_adapters_tools.html">Adapters and Tools: Extending DSPy Capabilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../07_advanced_topics/02_caching_performance.html">Caching and Performance: Building High-Performance DSPy Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../07_advanced_topics/03_async_streaming.html">Async and Streaming: Building Real-Time DSPy Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../07_advanced_topics/04_debugging_tracing.html">Debugging and Tracing: Mastering DSPy Application Diagnostics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../07_advanced_topics/05_deployment_strategies.html">Deployment Strategies: Taking DSPy Applications to Production</a></li>
<li class="toctree-l2"><a class="reference internal" href="../07_advanced_topics/06_exercises.html">Chapter 7 Exercises: Advanced Topics Mastery</a></li>
<li class="toctree-l2"><a class="reference internal" href="../07_advanced_topics/07_self_refining_pipelines.html">Self-Refining Pipelines</a></li>
<li class="toctree-l2"><a class="reference internal" href="../07_advanced_topics/08_declarative_compilation.html">Declarative Language Model Compilation Techniques</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Part 8 - Case Studies</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../08_case_studies/00_introduction.html">Chapter 8: Case Studies</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../08_case_studies/01_enterprise_rag_system.html">Case Study 1: Building an Enterprise RAG System</a></li>
<li class="toctree-l2"><a class="reference internal" href="../08_case_studies/01a_healthcare_clinical_notes.html">Case Study 1: Clinical Notes Analysis with DSPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../08_case_studies/02_customer_support_chatbot.html">Case Study 2: Developing a Customer Support Chatbot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../08_case_studies/03_ai_code_assistant.html">Case Study 3: Creating an AI-Powered Code Assistant</a></li>
<li class="toctree-l2"><a class="reference internal" href="../08_case_studies/04_automated_data_analysis.html">Case Study 4: Building an Automated Data Analysis Pipeline</a></li>
<li class="toctree-l2"><a class="reference internal" href="../08_case_studies/05_exercises.html">Chapter 8 Exercises</a></li>
<li class="toctree-l2"><a class="reference internal" href="../08_case_studies/05a_storm_writing_assistant.html">Case Study 5: STORM - AI-Powered Writing Assistant for Wikipedia-like Articles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../08_case_studies/06_assertion_driven_applications.html">Case Study: Assertion-Driven Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="../08_case_studies/07_databricks_jetblue_llm_optimization.html">Case Study 7: Databricks &amp; JetBlue LLM Pipeline Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../08_case_studies/08_replit_code_repair_dspy.html">Case Study 8: Replit Code Repair with DSPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../08_case_studies/09_databricks_dspy_platform_integration.html">Case Study 9: Databricks Platform Integration with DSPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../08_case_studies/10_ddi_behavioral_simulation_automation.html">Case Study 10: DDI Behavioral Simulation Automation with DSPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../08_case_studies/11_salomatic_medical_report_generation.html">Case Study 11: Salomatic Medical Report Generation with DSPy and Langtrace</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Appendices</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../09_appendices/00_introduction.html">Chapter 9: Appendices</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../09_appendices/01_api_reference_quick.html">API Reference Quick Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../09_appendices/02_troubleshooting.html">Troubleshooting Guide</a></li>
<li class="toctree-l2"><a class="reference internal" href="../09_appendices/03_resources.html">Additional Resources</a></li>
<li class="toctree-l2"><a class="reference internal" href="../09_appendices/04_glossary.html">Glossary</a></li>
<li class="toctree-l2"><a class="reference internal" href="../09_appendices/05_community_resources.html">Community Resources and Perspectives</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/content/05_optimizers/05_finetuning.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Fine-Tuning Small Language Models in DSPy</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#when-to-use-fine-tuning">When to Use Fine-Tuning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ideal-scenarios">Ideal Scenarios</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-size-trade-offs">Model Size Trade-offs</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-up-fine-tuning">Setting Up Fine-Tuning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prerequisites">Prerequisites</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-selection">Model Selection</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qlora-parameter-efficient-fine-tuning">QLoRA: Parameter-Efficient Fine-Tuning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#qlora-configuration">QLoRA Configuration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preparation">Data Preparation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning-process">Fine-Tuning Process</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-configuration">Training Configuration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#integration-with-dspy">Integration with DSPy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#task-specific-fine-tuning">Task-Specific Fine-Tuning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-fine-tuning">Classification Fine-Tuning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rag-fine-tuning">RAG Fine-Tuning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-and-testing">Evaluation and Testing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuned-model-evaluation">Fine-Tuned Model Evaluation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-with-baseline">Comparison with Baseline</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#best-practices">Best Practices</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-quality-over-quantity">1. Data Quality Over Quantity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#balanced-training-set">2. Balanced Training Set</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-rate-scheduling">3. Learning Rate Scheduling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-clipping">4. Gradient Clipping</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#common-pitfalls-and-solutions">Common Pitfalls and Solutions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pitfall-1-catastrophic-forgetting">Pitfall 1: Catastrophic Forgetting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pitfall-2-overfitting">Pitfall 2: Overfitting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pitfall-3-memory-issues">Pitfall 3: Memory Issues</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#combined-optimization-fine-tuning-prompt-optimization">Combined Optimization: Fine-Tuning + Prompt Optimization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-fine-tuning-and-prompt-optimization-are-complementary">Why Fine-Tuning and Prompt Optimization Are Complementary</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization-order-effects">Optimization Order Effects</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-improvements-with-combined-optimization">Performance Improvements with Combined Optimization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#code-example-full-combined-optimization-pipeline">Code Example: Full Combined Optimization Pipeline</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#instruction-complexity-scaling">Instruction Complexity Scaling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstration-efficiency-fewer-shots-required">Demonstration Efficiency: Fewer Shots Required</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#integration-with-copa">Integration with COPA</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-takeaways">Key Takeaways</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next Steps</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="fine-tuning-small-language-models-in-dspy">
<h1>Fine-Tuning Small Language Models in DSPy<a class="headerlink" href="#fine-tuning-small-language-models-in-dspy" title="Link to this heading">#</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
<p>While prompt optimization and few-shot learning work well with large language models (LLMs), sometimes you need better performance from smaller models. Fine-tuning adapts small language models to your specific task, achieving competitive performance with lower computational costs.</p>
</section>
<section id="when-to-use-fine-tuning">
<h2>When to Use Fine-Tuning<a class="headerlink" href="#when-to-use-fine-tuning" title="Link to this heading">#</a></h2>
<section id="ideal-scenarios">
<h3>Ideal Scenarios<a class="headerlink" href="#ideal-scenarios" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>Domain-Specific Tasks</strong>: Medical, legal, or technical domains</p></li>
<li><p><strong>High Volume</strong>: Large-scale applications where inference cost matters</p></li>
<li><p><strong>Latency Critical</strong>: Real-time applications requiring fast responses</p></li>
<li><p><strong>Privacy Concerns</strong>: On-premises deployment without external APIs</p></li>
<li><p><strong>Consistent Performance</strong>: Need for stable, reproducible outputs</p></li>
</ul>
</section>
<section id="model-size-trade-offs">
<h3>Model Size Trade-offs<a class="headerlink" href="#model-size-trade-offs" title="Link to this heading">#</a></h3>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Model Size</p></th>
<th class="head"><p>Parameters</p></th>
<th class="head"><p>Use Case</p></th>
<th class="head"><p>Pros</p></th>
<th class="head"><p>Cons</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>&lt; 1B</p></td>
<td><p>&lt; 1B</p></td>
<td><p>Simple classification, basic QA</p></td>
<td><p>Fast, cheap</p></td>
<td><p>Limited capabilities</p></td>
</tr>
<tr class="row-odd"><td><p>1-7B</p></td>
<td><p>1-7B</p></td>
<td><p>Most tasks, good balance</p></td>
<td><p>Capable, efficient</p></td>
<td><p>Still needs optimization</p></td>
</tr>
<tr class="row-even"><td><p>7-13B</p></td>
<td><p>7-13B</p></td>
<td><p>Complex reasoning</p></td>
<td><p>Powerful, smaller</p></td>
<td><p>More resources needed</p></td>
</tr>
<tr class="row-odd"><td><p>&gt; 13B</p></td>
<td><p>&gt; 13B</p></td>
<td><p>Specialized tasks</p></td>
<td><p>High quality</p></td>
<td><p>Expensive to fine-tune</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="setting-up-fine-tuning">
<h2>Setting Up Fine-Tuning<a class="headerlink" href="#setting-up-fine-tuning" title="Link to this heading">#</a></h2>
<section id="prerequisites">
<h3>Prerequisites<a class="headerlink" href="#prerequisites" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Install required packages</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">torch</span> <span class="n">transformers</span> <span class="n">datasets</span> <span class="n">accelerate</span> <span class="n">peft</span> <span class="n">bitsandbytes</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">TrainingArguments</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">dspy</span>
</pre></div>
</div>
</section>
<section id="model-selection">
<h3>Model Selection<a class="headerlink" href="#model-selection" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Popular small models for fine-tuning</span>
<span class="n">MODELS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;mistral-7b&quot;</span><span class="p">:</span> <span class="s2">&quot;mistralai/Mistral-7B-v0.1&quot;</span><span class="p">,</span>
    <span class="s2">&quot;llama2-7b&quot;</span><span class="p">:</span> <span class="s2">&quot;meta-llama/Llama-2-7b-hf&quot;</span><span class="p">,</span>
    <span class="s2">&quot;phi-2&quot;</span><span class="p">:</span> <span class="s2">&quot;microsoft/phi-2&quot;</span><span class="p">,</span>
    <span class="s2">&quot;qwen-7b&quot;</span><span class="p">:</span> <span class="s2">&quot;Qwen/Qwen-7B&quot;</span><span class="p">,</span>
    <span class="s2">&quot;gemma-7b&quot;</span><span class="p">:</span> <span class="s2">&quot;google/gemma-7b&quot;</span>
<span class="p">}</span>

<span class="k">def</span><span class="w"> </span><span class="nf">load_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">use_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load a model for fine-tuning.&quot;&quot;&quot;</span>
    <span class="n">model_id</span> <span class="o">=</span> <span class="n">MODELS</span><span class="p">[</span><span class="n">model_name</span><span class="p">]</span>

    <span class="c1"># Load tokenizer</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>

    <span class="c1"># Load model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="n">model_id</span><span class="p">,</span>
        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
        <span class="n">device_map</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">,</span>
        <span class="n">load_in_4bit</span><span class="o">=</span><span class="n">use_4bit</span><span class="p">,</span>  <span class="c1"># QLoRA support</span>
        <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span>
</pre></div>
</div>
</section>
</section>
<section id="qlora-parameter-efficient-fine-tuning">
<h2>QLoRA: Parameter-Efficient Fine-Tuning<a class="headerlink" href="#qlora-parameter-efficient-fine-tuning" title="Link to this heading">#</a></h2>
<p>QLoRA (Quantized Low-Rank Adaptation) is a memory-efficient fine-tuning method that works with 4-bit quantized models.</p>
<section id="qlora-configuration">
<h3>QLoRA Configuration<a class="headerlink" href="#qlora-configuration" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">peft</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">get_peft_model</span><span class="p">,</span> <span class="n">prepare_model_for_kbit_training</span>

<span class="k">def</span><span class="w"> </span><span class="nf">setup_qlora</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">target_modules</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Set up QLoRA for parameter-efficient fine-tuning.&quot;&quot;&quot;</span>
    <span class="c1"># Default target modules for common architectures</span>
    <span class="k">if</span> <span class="n">target_modules</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;k_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;o_proj&quot;</span><span class="p">,</span>  <span class="c1"># Attention</span>
            <span class="s2">&quot;gate_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;up_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;down_proj&quot;</span><span class="p">,</span>     <span class="c1"># MLP</span>
            <span class="s2">&quot;lm_head&quot;</span>                                 <span class="c1"># Output</span>
        <span class="p">]</span>

    <span class="c1"># LoRA configuration</span>
    <span class="n">lora_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span>
        <span class="n">r</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>                 <span class="c1"># Rank</span>
        <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>        <span class="c1"># Alpha</span>
        <span class="n">target_modules</span><span class="o">=</span><span class="n">target_modules</span><span class="p">,</span>
        <span class="n">lora_dropout</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span>    <span class="c1"># Dropout</span>
        <span class="n">bias</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>          <span class="c1"># No bias adaptation</span>
        <span class="n">task_type</span><span class="o">=</span><span class="s2">&quot;CAUSAL_LM&quot;</span> <span class="c1"># Causal language modeling</span>
    <span class="p">)</span>

    <span class="c1"># Prepare model for 4-bit training</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">prepare_model_for_kbit_training</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="c1"># Add LoRA adapters</span>
    <span class="n">peft_model</span> <span class="o">=</span> <span class="n">get_peft_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lora_config</span><span class="p">)</span>

    <span class="c1"># Print trainable parameters</span>
    <span class="n">peft_model</span><span class="o">.</span><span class="n">print_trainable_parameters</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">peft_model</span>
</pre></div>
</div>
</section>
<section id="data-preparation">
<h3>Data Preparation<a class="headerlink" href="#data-preparation" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">prepare_training_data</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Prepare DSPy examples for fine-tuning.&quot;&quot;&quot;</span>
    <span class="n">training_data</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">:</span>
        <span class="c1"># Format as chat or instruction-following</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="s1">&#39;question&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="s1">&#39;answer&#39;</span><span class="p">):</span>
            <span class="c1"># QA format</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Question: </span><span class="si">{</span><span class="n">example</span><span class="o">.</span><span class="n">question</span><span class="si">}</span><span class="se">\n</span><span class="s2">Answer: </span><span class="si">{</span><span class="n">example</span><span class="o">.</span><span class="n">answer</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="s1">&#39;context&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="s1">&#39;response&#39;</span><span class="p">):</span>
            <span class="c1"># Instruction format</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Context: </span><span class="si">{</span><span class="n">example</span><span class="o">.</span><span class="n">context</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">Response: </span><span class="si">{</span><span class="n">example</span><span class="o">.</span><span class="n">response</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Generic format</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>

        <span class="c1"># Tokenize</span>
        <span class="n">tokenized</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">prompt</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
        <span class="p">)</span>

        <span class="n">training_data</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
            <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
            <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>  <span class="c1"># Labels = input_ids</span>
        <span class="p">})</span>

    <span class="k">return</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_list</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>

<span class="c1"># Example: Prepare QA data</span>
<span class="n">qa_examples</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">dspy</span><span class="o">.</span><span class="n">Example</span><span class="p">(</span>
        <span class="n">question</span><span class="o">=</span><span class="s2">&quot;What is machine learning?&quot;</span><span class="p">,</span>
        <span class="n">answer</span><span class="o">=</span><span class="s2">&quot;Machine learning is a field of AI where computers learn from data.&quot;</span>
    <span class="p">),</span>
    <span class="c1"># ... more examples</span>
<span class="p">]</span>

<span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;mistral-7b&quot;</span><span class="p">)</span>
<span class="n">training_data</span> <span class="o">=</span> <span class="n">prepare_training_data</span><span class="p">(</span><span class="n">qa_examples</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="fine-tuning-process">
<h2>Fine-Tuning Process<a class="headerlink" href="#fine-tuning-process" title="Link to this heading">#</a></h2>
<section id="training-configuration">
<h3>Training Configuration<a class="headerlink" href="#training-configuration" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Trainer</span>

<span class="k">def</span><span class="w"> </span><span class="nf">fine_tune_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">val_data</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Fine-tune the model with QLoRA.&quot;&quot;&quot;</span>
    <span class="c1"># Training arguments</span>
    <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
        <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;./results&quot;</span><span class="p">,</span>
        <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">per_device_eval_batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
        <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2e-4</span><span class="p">,</span>
        <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">logging_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">optim</span><span class="o">=</span><span class="s2">&quot;paged_adamw_32bit&quot;</span><span class="p">,</span>  <span class="c1"># Memory efficient optimizer</span>
        <span class="n">save_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">eval_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span> <span class="k">if</span> <span class="n">val_data</span> <span class="k">else</span> <span class="s2">&quot;no&quot;</span><span class="p">,</span>
        <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">metric_for_best_model</span><span class="o">=</span><span class="s2">&quot;eval_loss&quot;</span><span class="p">,</span>
        <span class="n">greater_is_better</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">report_to</span><span class="o">=</span><span class="s2">&quot;none&quot;</span>  <span class="c1"># Disable wandb/tensorboard</span>
    <span class="p">)</span>

    <span class="c1"># Create trainer</span>
    <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">train_dataset</span><span class="o">=</span><span class="n">training_data</span><span class="p">,</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="n">val_data</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
        <span class="n">data_collator</span><span class="o">=</span><span class="k">lambda</span> <span class="n">data</span><span class="p">:</span> <span class="p">{</span>
            <span class="s1">&#39;input_ids&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]),</span>
            <span class="s1">&#39;attention_mask&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;attention_mask&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]),</span>
            <span class="s1">&#39;labels&#39;</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">item</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">data</span><span class="p">])</span>
        <span class="p">}</span>
    <span class="p">)</span>

    <span class="c1"># Start training</span>
    <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">trainer</span><span class="o">.</span><span class="n">model</span>
</pre></div>
</div>
</section>
<section id="integration-with-dspy">
<h3>Integration with DSPy<a class="headerlink" href="#integration-with-dspy" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">FineTunedLLM</span><span class="p">(</span><span class="n">dspy</span><span class="o">.</span><span class="n">LM</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Wrapper for fine-tuned models in DSPy.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.7</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate text using the fine-tuned model.&quot;&quot;&quot;</span>
        <span class="c1"># Tokenize input</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">prompt</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span>
        <span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Generate</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
                <span class="o">**</span><span class="n">inputs</span><span class="p">,</span>
                <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                <span class="n">temperature</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">,</span>
                <span class="n">do_sample</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span>
                <span class="n">pad_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>

        <span class="c1"># Decode</span>
        <span class="n">generated_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span>
            <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="c1"># Remove input prompt from output</span>
        <span class="k">if</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="n">generated_text</span><span class="p">:</span>
            <span class="n">generated_text</span> <span class="o">=</span> <span class="n">generated_text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">generated_text</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)]</span>

<span class="c1"># Use in DSPy</span>
<span class="n">fine_tuned_model</span> <span class="o">=</span> <span class="n">FineTunedLLM</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>
<span class="n">dspy</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">configure</span><span class="p">(</span><span class="n">lm</span><span class="o">=</span><span class="n">fine_tuned_model</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="task-specific-fine-tuning">
<h2>Task-Specific Fine-Tuning<a class="headerlink" href="#task-specific-fine-tuning" title="Link to this heading">#</a></h2>
<section id="classification-fine-tuning">
<h3>Classification Fine-Tuning<a class="headerlink" href="#classification-fine-tuning" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">prepare_classification_data</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Prepare data for classification tasks.&quot;&quot;&quot;</span>
    <span class="n">training_data</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">:</span>
        <span class="c1"># Format as classification prompt</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Classify the following text into one of: </span><span class="si">{</span><span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span><span class="si">}</span>

<span class="s2">Text: </span><span class="si">{</span><span class="n">example</span><span class="o">.</span><span class="n">text</span><span class="si">}</span>

<span class="s2">Classification:&quot;&quot;&quot;</span>

        <span class="c1"># Tokenize</span>
        <span class="n">tokenized</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">prompt</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="n">example</span><span class="o">.</span><span class="n">label</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
        <span class="p">)</span>

        <span class="c1"># Create labels</span>
        <span class="n">labels_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span>
            <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
            <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

        <span class="n">training_data</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
            <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
            <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="p">})</span>

    <span class="k">return</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_list</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>

<span class="c1"># Example usage</span>
<span class="n">sentiment_examples</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">dspy</span><span class="o">.</span><span class="n">Example</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">&quot;I love this!&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;positive&quot;</span><span class="p">),</span>
    <span class="n">dspy</span><span class="o">.</span><span class="n">Example</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="s2">&quot;This is bad.&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;negative&quot;</span><span class="p">),</span>
    <span class="c1"># ... more examples</span>
<span class="p">]</span>

<span class="n">sentiment_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;positive&quot;</span><span class="p">,</span> <span class="s2">&quot;negative&quot;</span><span class="p">,</span> <span class="s2">&quot;neutral&quot;</span><span class="p">]</span>
<span class="n">sentiment_data</span> <span class="o">=</span> <span class="n">prepare_classification_data</span><span class="p">(</span>
    <span class="n">sentiment_examples</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">sentiment_labels</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="rag-fine-tuning">
<h3>RAG Fine-Tuning<a class="headerlink" href="#rag-fine-tuning" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">prepare_rag_data</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Prepare data for Retrieval-Augmented Generation.&quot;&quot;&quot;</span>
    <span class="n">training_data</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">:</span>
        <span class="c1"># Format as RAG prompt</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&quot;&quot;Context: </span><span class="si">{</span><span class="n">example</span><span class="o">.</span><span class="n">context</span><span class="si">}</span>

<span class="s2">Question: </span><span class="si">{</span><span class="n">example</span><span class="o">.</span><span class="n">question</span><span class="si">}</span>

<span class="s2">Answer:&quot;&quot;&quot;</span>

        <span class="c1"># Tokenize</span>
        <span class="n">tokenized</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">prompt</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="n">example</span><span class="o">.</span><span class="n">answer</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span>
        <span class="p">)</span>

        <span class="n">training_data</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
            <span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
            <span class="s2">&quot;attention_mask&quot;</span><span class="p">:</span> <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;attention_mask&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
            <span class="s2">&quot;labels&quot;</span><span class="p">:</span> <span class="n">tokenized</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="p">})</span>

    <span class="k">return</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_list</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>

<span class="k">class</span><span class="w"> </span><span class="nc">RAGFineTuner</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">fine_tune_rag</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">examples</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Fine-tune model for RAG tasks.&quot;&quot;&quot;</span>
        <span class="c1"># Prepare data</span>
        <span class="n">training_data</span> <span class="o">=</span> <span class="n">prepare_rag_data</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>

        <span class="c1"># Fine-tune with specific settings for RAG</span>
        <span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
            <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;./rag_results&quot;</span><span class="p">,</span>
            <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>  <span class="c1"># Lower learning rate for RAG</span>
            <span class="n">warmup_ratio</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
            <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">logging_steps</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
            <span class="n">save_steps</span><span class="o">=</span><span class="mi">50</span>
        <span class="p">)</span>

        <span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">train_dataset</span><span class="o">=</span><span class="n">training_data</span><span class="p">,</span>
            <span class="n">args</span><span class="o">=</span><span class="n">training_args</span>
        <span class="p">)</span>

        <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">trainer</span><span class="o">.</span><span class="n">model</span>
</pre></div>
</div>
</section>
</section>
<section id="evaluation-and-testing">
<h2>Evaluation and Testing<a class="headerlink" href="#evaluation-and-testing" title="Link to this heading">#</a></h2>
<section id="fine-tuned-model-evaluation">
<h3>Fine-Tuned Model Evaluation<a class="headerlink" href="#fine-tuned-model-evaluation" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">evaluate_fine_tuned_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">test_examples</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate fine-tuned model performance.&quot;&quot;&quot;</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">fine_tuned_lm</span> <span class="o">=</span> <span class="n">FineTunedLLM</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">test_examples</span><span class="p">:</span>
        <span class="c1"># Generate prediction</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="s1">&#39;question&#39;</span><span class="p">):</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Question: </span><span class="si">{</span><span class="n">example</span><span class="o">.</span><span class="n">question</span><span class="si">}</span><span class="se">\n</span><span class="s2">Answer:&quot;</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="s1">&#39;text&#39;</span><span class="p">):</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Text: </span><span class="si">{</span><span class="n">example</span><span class="o">.</span><span class="n">text</span><span class="si">}</span><span class="se">\n</span><span class="s2">Classification:&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="n">fine_tuned_lm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
            <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">example</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>

        <span class="c1"># Evaluate (adjust based on task)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="s1">&#39;answer&#39;</span><span class="p">):</span>
            <span class="c1"># QA evaluation</span>
            <span class="k">if</span> <span class="n">example</span><span class="o">.</span><span class="n">answer</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="n">prediction</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
                <span class="n">correct</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="n">total</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span> <span class="k">if</span> <span class="n">total</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">predictions</span>

<span class="c1"># Evaluate</span>
<span class="n">accuracy</span><span class="p">,</span> <span class="n">predictions</span> <span class="o">=</span> <span class="n">evaluate_fine_tuned_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">test_examples</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fine-tuned model accuracy: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="comparison-with-baseline">
<h3>Comparison with Baseline<a class="headerlink" href="#comparison-with-baseline" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">compare_models</span><span class="p">(</span><span class="n">fine_tuned_model</span><span class="p">,</span> <span class="n">baseline_lm</span><span class="p">,</span> <span class="n">test_examples</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compare fine-tuned model with baseline.&quot;&quot;&quot;</span>
    <span class="n">fine_tuned_lm</span> <span class="o">=</span> <span class="n">FineTunedLLM</span><span class="p">(</span><span class="n">fine_tuned_model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;fine_tuned&quot;</span><span class="p">:</span> <span class="p">[],</span>
        <span class="s2">&quot;baseline&quot;</span><span class="p">:</span> <span class="p">[]</span>
    <span class="p">}</span>

    <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">test_examples</span><span class="p">:</span>
        <span class="n">prompt</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Question: </span><span class="si">{</span><span class="n">example</span><span class="o">.</span><span class="n">question</span><span class="si">}</span><span class="se">\n</span><span class="s2">Answer:&quot;</span>

        <span class="c1"># Fine-tuned prediction</span>
        <span class="n">ft_pred</span> <span class="o">=</span> <span class="n">fine_tuned_lm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
        <span class="n">results</span><span class="p">[</span><span class="s2">&quot;fine_tuned&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">example</span><span class="p">,</span> <span class="n">ft_pred</span><span class="p">))</span>

        <span class="c1"># Baseline prediction</span>
        <span class="n">base_pred</span> <span class="o">=</span> <span class="n">baseline_lm</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">prompt</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">results</span><span class="p">[</span><span class="s2">&quot;baseline&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">example</span><span class="p">,</span> <span class="n">base_pred</span><span class="p">))</span>

    <span class="c1"># Calculate metrics</span>
    <span class="n">ft_correct</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">ex</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;fine_tuned&quot;</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">ex</span><span class="o">.</span><span class="n">answer</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="n">pred</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
    <span class="n">base_correct</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">ex</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;baseline&quot;</span><span class="p">]</span>
                      <span class="k">if</span> <span class="n">ex</span><span class="o">.</span><span class="n">answer</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">in</span> <span class="n">pred</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>

    <span class="n">ft_acc</span> <span class="o">=</span> <span class="n">ft_correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_examples</span><span class="p">)</span>
    <span class="n">base_acc</span> <span class="o">=</span> <span class="n">base_correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_examples</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fine-tuned accuracy: </span><span class="si">{</span><span class="n">ft_acc</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Baseline accuracy: </span><span class="si">{</span><span class="n">base_acc</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Improvement: </span><span class="si">{</span><span class="n">ft_acc</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">base_acc</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">results</span>
</pre></div>
</div>
</section>
</section>
<section id="best-practices">
<h2>Best Practices<a class="headerlink" href="#best-practices" title="Link to this heading">#</a></h2>
<section id="data-quality-over-quantity">
<h3>1. Data Quality Over Quantity<a class="headerlink" href="#data-quality-over-quantity" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">filter_high_quality_examples</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">min_length</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_length</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Filter for high-quality training examples.&quot;&quot;&quot;</span>
    <span class="n">filtered</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">:</span>
        <span class="n">text</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">min_length</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">max_length</span><span class="p">:</span>
            <span class="c1"># Additional quality checks</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">has_repetitions</span><span class="p">(</span><span class="n">text</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">has_issues</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
                <span class="n">filtered</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">filtered</span>

<span class="k">def</span><span class="w"> </span><span class="nf">has_repetitions</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Check for excessive repetitions.&quot;&quot;&quot;</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span> <span class="o">-</span> <span class="mi">2</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">words</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">words</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">words</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">2</span><span class="p">]:</span>
            <span class="k">return</span> <span class="kc">True</span>
    <span class="k">return</span> <span class="kc">False</span>
</pre></div>
</div>
</section>
<section id="balanced-training-set">
<h3>2. Balanced Training Set<a class="headerlink" href="#balanced-training-set" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">create_balanced_dataset</span><span class="p">(</span><span class="n">examples</span><span class="p">,</span> <span class="n">field_name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a balanced dataset by field.&quot;&quot;&quot;</span>
    <span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">defaultdict</span>

    <span class="c1"># Group by field</span>
    <span class="n">groups</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">examples</span><span class="p">:</span>
        <span class="n">value</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">field_name</span><span class="p">,</span> <span class="s1">&#39;unknown&#39;</span><span class="p">)</span>
        <span class="n">groups</span><span class="p">[</span><span class="n">value</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">example</span><span class="p">)</span>

    <span class="c1"># Find minimum group size</span>
    <span class="n">min_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">group</span><span class="p">)</span> <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">groups</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

    <span class="c1"># Sample from each group</span>
    <span class="n">balanced</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">groups</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
        <span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
        <span class="n">balanced</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">group</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">min_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">group</span><span class="p">))))</span>

    <span class="k">return</span> <span class="n">balanced</span>
</pre></div>
</div>
</section>
<section id="learning-rate-scheduling">
<h3>3. Learning Rate Scheduling<a class="headerlink" href="#learning-rate-scheduling" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_cosine_schedule_with_warmup</span>

<span class="k">def</span><span class="w"> </span><span class="nf">create_lr_scheduler</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">num_training_steps</span><span class="p">,</span> <span class="n">warmup_ratio</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create a learning rate scheduler.&quot;&quot;&quot;</span>
    <span class="n">warmup_steps</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">num_training_steps</span> <span class="o">*</span> <span class="n">warmup_ratio</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">get_cosine_schedule_with_warmup</span><span class="p">(</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">num_warmup_steps</span><span class="o">=</span><span class="n">warmup_steps</span><span class="p">,</span>
        <span class="n">num_training_steps</span><span class="o">=</span><span class="n">num_training_steps</span>
    <span class="p">)</span>
</pre></div>
</div>
</section>
<section id="gradient-clipping">
<h3>4. Gradient Clipping<a class="headerlink" href="#gradient-clipping" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="c1"># ... other args</span>
    <span class="n">max_grad_norm</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>  <span class="c1"># Prevent gradient explosion</span>
    <span class="c1"># ...</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="common-pitfalls-and-solutions">
<h2>Common Pitfalls and Solutions<a class="headerlink" href="#common-pitfalls-and-solutions" title="Link to this heading">#</a></h2>
<section id="pitfall-1-catastrophic-forgetting">
<h3>Pitfall 1: Catastrophic Forgetting<a class="headerlink" href="#pitfall-1-catastrophic-forgetting" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Problem: Model forgets original capabilities</span>
<span class="c1"># Solution: Include diverse examples</span>
<span class="k">def</span><span class="w"> </span><span class="nf">create_mixed_dataset</span><span class="p">(</span><span class="n">domain_examples</span><span class="p">,</span> <span class="n">general_examples</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mf">0.8</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Mix domain-specific with general examples.&quot;&quot;&quot;</span>
    <span class="n">domain_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">domain_examples</span><span class="p">)</span> <span class="o">*</span> <span class="n">ratio</span><span class="p">)</span>
    <span class="n">mixed</span> <span class="o">=</span> <span class="n">domain_examples</span><span class="p">[:</span><span class="n">domain_size</span><span class="p">]</span>
    <span class="n">mixed</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">general_examples</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">mixed</span><span class="p">)</span> <span class="o">-</span> <span class="n">domain_size</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">mixed</span>
</pre></div>
</div>
</section>
<section id="pitfall-2-overfitting">
<h3>Pitfall 2: Overfitting<a class="headerlink" href="#pitfall-2-overfitting" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Problem: Model memorizes training data</span>
<span class="c1"># Solution: Early stopping and regularization</span>
<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="c1"># ... other args</span>
    <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span>
    <span class="n">eval_steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
    <span class="n">load_best_model_at_end</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">metric_for_best_model</span><span class="o">=</span><span class="s2">&quot;eval_loss&quot;</span><span class="p">,</span>
    <span class="n">greater_is_better</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">weight_decay</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>  <span class="c1"># L2 regularization</span>
    <span class="c1"># ...</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="pitfall-3-memory-issues">
<h3>Pitfall 3: Memory Issues<a class="headerlink" href="#pitfall-3-memory-issues" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Problem: GPU memory overflow</span>
<span class="c1"># Solution: Gradient accumulation and mixed precision</span>
<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="c1"># ... other args</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">gradient_accumulation_steps</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>  <span class="c1"># Effective batch size = 16</span>
    <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="c1"># Mixed precision</span>
    <span class="n">dataloader_pin_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="c1"># ...</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="combined-optimization-fine-tuning-prompt-optimization">
<h2>Combined Optimization: Fine-Tuning + Prompt Optimization<a class="headerlink" href="#combined-optimization-fine-tuning-prompt-optimization" title="Link to this heading">#</a></h2>
<p>One of the most powerful techniques in DSPy is combining fine-tuning with prompt optimization. Research shows that these approaches are complementary, with combined optimization achieving 2-26x improvements over baseline performance.</p>
<section id="why-fine-tuning-and-prompt-optimization-are-complementary">
<h3>Why Fine-Tuning and Prompt Optimization Are Complementary<a class="headerlink" href="#why-fine-tuning-and-prompt-optimization-are-complementary" title="Link to this heading">#</a></h3>
<p>Fine-tuning and prompt optimization target different aspects of model behavior:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Aspect</p></th>
<th class="head"><p>Fine-Tuning</p></th>
<th class="head"><p>Prompt Optimization</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Target</strong></p></td>
<td><p>Model weights</p></td>
<td><p>Instructions and demonstrations</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Effect</strong></p></td>
<td><p>Deep task adaptation</p></td>
<td><p>Surface-level guidance</p></td>
</tr>
<tr class="row-even"><td><p><strong>Persistence</strong></p></td>
<td><p>Permanent (model changes)</p></td>
<td><p>Runtime (prompt changes)</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Flexibility</strong></p></td>
<td><p>Fixed after training</p></td>
<td><p>Dynamic per query</p></td>
</tr>
</tbody>
</table>
</div>
<p>When combined, fine-tuning creates a stronger foundation that prompt optimization can build upon:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># The synergistic effect of combined optimization</span>
<span class="c1"># Fine-tuning improvement: +15%</span>
<span class="c1"># Prompt optimization improvement: +10%</span>
<span class="c1"># Combined improvement: +35% (not just 25%!)</span>

<span class="c1"># This synergy occurs because:</span>
<span class="c1"># 1. Fine-tuned models follow complex instructions better</span>
<span class="c1"># 2. Better instruction following enables more sophisticated prompts</span>
<span class="c1"># 3. Optimized prompts unlock capabilities learned during fine-tuning</span>
</pre></div>
</div>
</section>
<section id="optimization-order-effects">
<h3>Optimization Order Effects<a class="headerlink" href="#optimization-order-effects" title="Link to this heading">#</a></h3>
<p><strong>Critical insight</strong>: The order of optimization matters significantly.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># RECOMMENDED: Fine-tuning FIRST, then prompt optimization</span>
<span class="k">def</span><span class="w"> </span><span class="nf">optimal_order_optimization</span><span class="p">(</span><span class="n">program</span><span class="p">,</span> <span class="n">trainset</span><span class="p">,</span> <span class="n">base_model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fine-tune first, then apply prompt optimization.</span>
<span class="sd">    This order consistently outperforms the reverse.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Step 1: Fine-tune the base model</span>
    <span class="n">finetuned_model</span> <span class="o">=</span> <span class="n">finetune_model</span><span class="p">(</span>
        <span class="n">base_model</span><span class="p">,</span>
        <span class="n">trainset</span><span class="p">,</span>
        <span class="n">epochs</span><span class="o">=</span><span class="mi">3</span>
    <span class="p">)</span>

    <span class="c1"># Step 2: Configure DSPy with fine-tuned model</span>
    <span class="n">dspy</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">configure</span><span class="p">(</span><span class="n">lm</span><span class="o">=</span><span class="n">finetuned_model</span><span class="p">)</span>

    <span class="c1"># Step 3: Apply prompt optimization</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">BootstrapFewShot</span><span class="p">(</span>
        <span class="n">metric</span><span class="o">=</span><span class="n">accuracy_metric</span><span class="p">,</span>
        <span class="n">max_bootstrapped_demos</span><span class="o">=</span><span class="mi">8</span>
    <span class="p">)</span>
    <span class="n">compiled_program</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">program</span><span class="p">,</span> <span class="n">trainset</span><span class="o">=</span><span class="n">trainset</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">compiled_program</span>

<span class="c1"># NOT RECOMMENDED: Prompt optimization first</span>
<span class="k">def</span><span class="w"> </span><span class="nf">suboptimal_order</span><span class="p">(</span><span class="n">program</span><span class="p">,</span> <span class="n">trainset</span><span class="p">,</span> <span class="n">base_model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This order yields lower performance.</span>
<span class="sd">    Prompt optimizations don&#39;t transfer well to fine-tuned models.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Prompts optimized for base model</span>
    <span class="n">dspy</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">configure</span><span class="p">(</span><span class="n">lm</span><span class="o">=</span><span class="n">base_model</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">BootstrapFewShot</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="n">accuracy_metric</span><span class="p">)</span>
    <span class="n">compiled_program</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">program</span><span class="p">,</span> <span class="n">trainset</span><span class="o">=</span><span class="n">trainset</span><span class="p">)</span>

    <span class="c1"># Fine-tuning doesn&#39;t preserve prompt-specific behaviors</span>
    <span class="n">finetuned_model</span> <span class="o">=</span> <span class="n">finetune_model</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span> <span class="n">trainset</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">compiled_program</span>  <span class="c1"># Prompts may no longer be optimal</span>
</pre></div>
</div>
</section>
<section id="performance-improvements-with-combined-optimization">
<h3>Performance Improvements with Combined Optimization<a class="headerlink" href="#performance-improvements-with-combined-optimization" title="Link to this heading">#</a></h3>
<p>Real-world benchmarks demonstrate the power of combined optimization:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Task</p></th>
<th class="head"><p>Baseline</p></th>
<th class="head"><p>Fine-Tune Only</p></th>
<th class="head"><p>Prompt Only</p></th>
<th class="head"><p>Combined</p></th>
<th class="head"><p>Synergy</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>MultiHopQA</p></td>
<td><p>12%</p></td>
<td><p>28%</p></td>
<td><p>20%</p></td>
<td><p>45%</p></td>
<td><p>+9%</p></td>
</tr>
<tr class="row-odd"><td><p>GSM8K</p></td>
<td><p>11%</p></td>
<td><p>32%</p></td>
<td><p>22%</p></td>
<td><p>55%</p></td>
<td><p>+12%</p></td>
</tr>
<tr class="row-even"><td><p>Classification</p></td>
<td><p>65%</p></td>
<td><p>82%</p></td>
<td><p>78%</p></td>
<td><p>91%</p></td>
<td><p>+4%</p></td>
</tr>
</tbody>
</table>
</div>
<p>The synergy column shows improvement beyond simple addition.</p>
</section>
<section id="code-example-full-combined-optimization-pipeline">
<h3>Code Example: Full Combined Optimization Pipeline<a class="headerlink" href="#code-example-full-combined-optimization-pipeline" title="Link to this heading">#</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">dspy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dspy.teleprompter</span><span class="w"> </span><span class="kn">import</span> <span class="n">BootstrapFewShot</span><span class="p">,</span> <span class="n">MIPRO</span>

<span class="k">def</span><span class="w"> </span><span class="nf">combined_optimization_pipeline</span><span class="p">(</span>
    <span class="n">program</span><span class="p">,</span>
    <span class="n">trainset</span><span class="p">,</span>
    <span class="n">valset</span><span class="p">,</span>
    <span class="n">base_model_name</span><span class="p">,</span>
    <span class="n">metric</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Complete pipeline for combined fine-tuning and prompt optimization.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Phase 1: Prepare fine-tuning data</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Phase 1: Preparing fine-tuning data...&quot;</span><span class="p">)</span>
    <span class="n">ft_data</span> <span class="o">=</span> <span class="n">prepare_training_data</span><span class="p">(</span><span class="n">trainset</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>

    <span class="c1"># Phase 2: Fine-tune the model</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Phase 2: Fine-tuning model...&quot;</span><span class="p">)</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">base_model_name</span><span class="p">)</span>
    <span class="n">peft_model</span> <span class="o">=</span> <span class="n">setup_qlora</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">finetuned</span> <span class="o">=</span> <span class="n">fine_tune_model</span><span class="p">(</span><span class="n">peft_model</span><span class="p">,</span> <span class="n">ft_data</span><span class="p">)</span>

    <span class="c1"># Phase 3: Create DSPy LM wrapper</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Phase 3: Creating DSPy language model...&quot;</span><span class="p">)</span>
    <span class="n">finetuned_lm</span> <span class="o">=</span> <span class="n">FineTunedLLM</span><span class="p">(</span><span class="n">finetuned</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>
    <span class="n">dspy</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">configure</span><span class="p">(</span><span class="n">lm</span><span class="o">=</span><span class="n">finetuned_lm</span><span class="p">)</span>

    <span class="c1"># Phase 4: Apply prompt optimization</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Phase 4: Optimizing prompts...&quot;</span><span class="p">)</span>
    <span class="c1"># Use BootstrapFewShot for quick optimization</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">BootstrapFewShot</span><span class="p">(</span>
        <span class="n">metric</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span>
        <span class="n">max_bootstrapped_demos</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
        <span class="n">max_labeled_demos</span><span class="o">=</span><span class="mi">4</span>
    <span class="p">)</span>

    <span class="c1"># Or use MIPRO for maximum performance</span>
    <span class="c1"># optimizer = MIPRO(metric=metric, auto=&quot;medium&quot;)</span>

    <span class="n">compiled_program</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
        <span class="n">program</span><span class="p">,</span>
        <span class="n">trainset</span><span class="o">=</span><span class="n">trainset</span><span class="p">,</span>
        <span class="n">valset</span><span class="o">=</span><span class="n">valset</span>
    <span class="p">)</span>

    <span class="c1"># Phase 5: Evaluate</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Phase 5: Evaluating...&quot;</span><span class="p">)</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">compiled_program</span><span class="p">,</span> <span class="n">valset</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Final performance: </span><span class="si">{</span><span class="n">score</span><span class="si">:</span><span class="s2">.2%</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">compiled_program</span><span class="p">,</span> <span class="n">finetuned</span>

<span class="c1"># Usage</span>
<span class="n">optimized_program</span><span class="p">,</span> <span class="n">optimized_model</span> <span class="o">=</span> <span class="n">combined_optimization_pipeline</span><span class="p">(</span>
    <span class="n">program</span><span class="o">=</span><span class="n">MyQASystem</span><span class="p">(),</span>
    <span class="n">trainset</span><span class="o">=</span><span class="n">train_examples</span><span class="p">,</span>
    <span class="n">valset</span><span class="o">=</span><span class="n">val_examples</span><span class="p">,</span>
    <span class="n">base_model_name</span><span class="o">=</span><span class="s2">&quot;mistralai/Mistral-7B-v0.1&quot;</span><span class="p">,</span>
    <span class="n">metric</span><span class="o">=</span><span class="n">exact_match_metric</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="instruction-complexity-scaling">
<h3>Instruction Complexity Scaling<a class="headerlink" href="#instruction-complexity-scaling" title="Link to this heading">#</a></h3>
<p>Fine-tuned models can follow significantly more complex instructions than base models:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Base model: Limited instruction complexity</span>
<span class="n">simple_instruction</span> <span class="o">=</span> <span class="s2">&quot;Answer the question.&quot;</span>

<span class="c1"># Fine-tuned model: Handles complex multi-step instructions</span>
<span class="n">complex_instruction</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">Analyze the question following this process:</span>
<span class="s2">1. Identify the core question and any sub-questions</span>
<span class="s2">2. Determine what knowledge domains are relevant</span>
<span class="s2">3. Consider potential ambiguities or edge cases</span>
<span class="s2">4. Synthesize information from multiple sources</span>
<span class="s2">5. Provide a clear, well-structured answer</span>
<span class="s2">6. Note any assumptions or limitations</span>
<span class="s2">&quot;&quot;&quot;</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_instruction_complexity</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">instructions</span><span class="p">,</span> <span class="n">test_set</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Test model&#39;s ability to follow complex instructions.&quot;&quot;&quot;</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">instruction</span> <span class="ow">in</span> <span class="n">instructions</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="c1"># Configure signature with instruction</span>
        <span class="n">signature</span> <span class="o">=</span> <span class="n">dspy</span><span class="o">.</span><span class="n">Signature</span><span class="p">(</span>
            <span class="s2">&quot;question -&gt; answer&quot;</span><span class="p">,</span>
            <span class="n">instruction</span>
        <span class="p">)</span>
        <span class="n">predictor</span> <span class="o">=</span> <span class="n">dspy</span><span class="o">.</span><span class="n">Predict</span><span class="p">(</span><span class="n">signature</span><span class="p">)</span>

        <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">test_set</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">pred</span> <span class="o">=</span> <span class="n">predictor</span><span class="p">(</span><span class="n">question</span><span class="o">=</span><span class="n">example</span><span class="o">.</span><span class="n">question</span><span class="p">)</span>
                <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_metric</span><span class="p">(</span><span class="n">example</span><span class="p">,</span> <span class="n">pred</span><span class="p">))</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">results</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">results</span>

<span class="c1"># Fine-tuned models show larger gains with complex instructions</span>
</pre></div>
</div>
</section>
<section id="demonstration-efficiency-fewer-shots-required">
<h3>Demonstration Efficiency: Fewer Shots Required<a class="headerlink" href="#demonstration-efficiency-fewer-shots-required" title="Link to this heading">#</a></h3>
<p>Fine-tuned models achieve equivalent performance with fewer demonstrations:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">compare_demonstration_efficiency</span><span class="p">(</span><span class="n">base_lm</span><span class="p">,</span> <span class="n">finetuned_lm</span><span class="p">,</span> <span class="n">trainset</span><span class="p">,</span> <span class="n">testset</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compare how many demonstrations each model needs.</span>
<span class="sd">    Fine-tuned models typically need 3 demos where base needs 8.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">results</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;base&quot;</span><span class="p">:</span> <span class="p">{},</span> <span class="s2">&quot;finetuned&quot;</span><span class="p">:</span> <span class="p">{}}</span>

    <span class="k">for</span> <span class="n">num_demos</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]:</span>
        <span class="c1"># Test base model</span>
        <span class="n">dspy</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">configure</span><span class="p">(</span><span class="n">lm</span><span class="o">=</span><span class="n">base_lm</span><span class="p">)</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">BootstrapFewShot</span><span class="p">(</span>
            <span class="n">metric</span><span class="o">=</span><span class="n">accuracy_metric</span><span class="p">,</span>
            <span class="n">max_bootstrapped_demos</span><span class="o">=</span><span class="n">num_demos</span>
        <span class="p">)</span>
        <span class="n">compiled_base</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">program</span><span class="p">,</span> <span class="n">trainset</span><span class="o">=</span><span class="n">trainset</span><span class="p">)</span>
        <span class="n">results</span><span class="p">[</span><span class="s2">&quot;base&quot;</span><span class="p">][</span><span class="n">num_demos</span><span class="p">]</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">compiled_base</span><span class="p">,</span> <span class="n">testset</span><span class="p">)</span>

        <span class="c1"># Test fine-tuned model</span>
        <span class="n">dspy</span><span class="o">.</span><span class="n">settings</span><span class="o">.</span><span class="n">configure</span><span class="p">(</span><span class="n">lm</span><span class="o">=</span><span class="n">finetuned_lm</span><span class="p">)</span>
        <span class="n">compiled_ft</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">program</span><span class="p">,</span> <span class="n">trainset</span><span class="o">=</span><span class="n">trainset</span><span class="p">)</span>
        <span class="n">results</span><span class="p">[</span><span class="s2">&quot;finetuned&quot;</span><span class="p">][</span><span class="n">num_demos</span><span class="p">]</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">compiled_ft</span><span class="p">,</span> <span class="n">testset</span><span class="p">)</span>

    <span class="c1"># Find efficiency ratio</span>
    <span class="n">base_8shot</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;base&quot;</span><span class="p">][</span><span class="mi">8</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">num_demos</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">results</span><span class="p">[</span><span class="s2">&quot;finetuned&quot;</span><span class="p">][</span><span class="n">num_demos</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">base_8shot</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Fine-tuned </span><span class="si">{</span><span class="n">num_demos</span><span class="si">}</span><span class="s2">-shot &gt;= Base 8-shot&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Demonstration efficiency: </span><span class="si">{</span><span class="mi">8</span><span class="o">/</span><span class="n">num_demos</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">x&quot;</span><span class="p">)</span>
            <span class="k">break</span>

    <span class="k">return</span> <span class="n">results</span>
</pre></div>
</div>
</section>
<section id="integration-with-copa">
<h3>Integration with COPA<a class="headerlink" href="#integration-with-copa" title="Link to this heading">#</a></h3>
<p>For maximum performance, use the COPA optimizer which systematically combines fine-tuning and prompt optimization:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">copa_optimizer</span><span class="w"> </span><span class="kn">import</span> <span class="n">COPAOptimizer</span>  <span class="c1"># See 09-copa-optimizer.md</span>

<span class="c1"># COPA handles the optimization order automatically</span>
<span class="n">copa</span> <span class="o">=</span> <span class="n">COPAOptimizer</span><span class="p">(</span>
    <span class="n">base_model_name</span><span class="o">=</span><span class="s2">&quot;mistralai/Mistral-7B-v0.1&quot;</span><span class="p">,</span>
    <span class="n">metric</span><span class="o">=</span><span class="n">accuracy_metric</span><span class="p">,</span>
    <span class="n">finetune_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">prompt_optimizer</span><span class="o">=</span><span class="s2">&quot;mipro&quot;</span>
<span class="p">)</span>

<span class="n">optimized_program</span><span class="p">,</span> <span class="n">optimized_model</span> <span class="o">=</span> <span class="n">copa</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span>
    <span class="n">program</span><span class="o">=</span><span class="n">MyQASystem</span><span class="p">(),</span>
    <span class="n">trainset</span><span class="o">=</span><span class="n">train_examples</span><span class="p">,</span>
    <span class="n">valset</span><span class="o">=</span><span class="n">val_examples</span>
<span class="p">)</span>

<span class="c1"># COPA achieves 2-26x improvements on complex tasks</span>
</pre></div>
</div>
<p>For more details on COPA and advanced joint optimization techniques, see <a class="reference internal" href="#09-copa-optimizer.md"><span class="xref myst">COPA: Combined Fine-Tuning and Prompt Optimization</span></a>.</p>
</section>
</section>
<section id="key-takeaways">
<h2>Key Takeaways<a class="headerlink" href="#key-takeaways" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Fine-tuning adapts small models for specific tasks efficiently</p></li>
<li><p>QLoRA enables memory-efficient fine-tuning with 4-bit models</p></li>
<li><p>Proper data preparation is crucial for success</p></li>
<li><p>Balance domain-specific and general examples</p></li>
<li><p>Monitor for overfitting and catastrophic forgetting</p></li>
<li><p>Use gradient accumulation for larger effective batch sizes</p></li>
<li><p><strong>Combined optimization (fine-tuning + prompts) achieves synergistic improvements</strong></p></li>
<li><p><strong>Always fine-tune first, then apply prompt optimization</strong></p></li>
<li><p><strong>Fine-tuned models require fewer demonstrations (3-shot vs 8-shot)</strong></p></li>
</ol>
</section>
<section id="next-steps">
<h2>Next Steps<a class="headerlink" href="#next-steps" title="Link to this heading">#</a></h2>
<p>In the next section, well explore how to choose the right optimizer for your specific needs and compare different approaches. For advanced joint optimization, see <a class="reference internal" href="#09-copa-optimizer.md"><span class="xref myst">COPA: Combined Fine-Tuning and Prompt Optimization</span></a>.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./content/05_optimizers"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="04_knnfewshot.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">KNNFewShot: Similarity-Based Example Selection</p>
      </div>
    </a>
    <a class="right-next"
       href="06_choosing_optimizers.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Choosing Optimizers: Decision Guide and Trade-offs</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#when-to-use-fine-tuning">When to Use Fine-Tuning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ideal-scenarios">Ideal Scenarios</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-size-trade-offs">Model Size Trade-offs</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#setting-up-fine-tuning">Setting Up Fine-Tuning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prerequisites">Prerequisites</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-selection">Model Selection</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qlora-parameter-efficient-fine-tuning">QLoRA: Parameter-Efficient Fine-Tuning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#qlora-configuration">QLoRA Configuration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-preparation">Data Preparation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuning-process">Fine-Tuning Process</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-configuration">Training Configuration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#integration-with-dspy">Integration with DSPy</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#task-specific-fine-tuning">Task-Specific Fine-Tuning</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-fine-tuning">Classification Fine-Tuning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#rag-fine-tuning">RAG Fine-Tuning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#evaluation-and-testing">Evaluation and Testing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-tuned-model-evaluation">Fine-Tuned Model Evaluation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-with-baseline">Comparison with Baseline</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#best-practices">Best Practices</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-quality-over-quantity">1. Data Quality Over Quantity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#balanced-training-set">2. Balanced Training Set</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-rate-scheduling">3. Learning Rate Scheduling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-clipping">4. Gradient Clipping</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#common-pitfalls-and-solutions">Common Pitfalls and Solutions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pitfall-1-catastrophic-forgetting">Pitfall 1: Catastrophic Forgetting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pitfall-2-overfitting">Pitfall 2: Overfitting</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pitfall-3-memory-issues">Pitfall 3: Memory Issues</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#combined-optimization-fine-tuning-prompt-optimization">Combined Optimization: Fine-Tuning + Prompt Optimization</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#why-fine-tuning-and-prompt-optimization-are-complementary">Why Fine-Tuning and Prompt Optimization Are Complementary</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization-order-effects">Optimization Order Effects</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-improvements-with-combined-optimization">Performance Improvements with Combined Optimization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#code-example-full-combined-optimization-pipeline">Code Example: Full Combined Optimization Pipeline</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#instruction-complexity-scaling">Instruction Complexity Scaling</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demonstration-efficiency-fewer-shots-required">Demonstration Efficiency: Fewer Shots Required</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#integration-with-copa">Integration with COPA</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-takeaways">Key Takeaways</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">Next Steps</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Dustin Ober
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
       Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>