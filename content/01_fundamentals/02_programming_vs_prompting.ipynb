{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c160b3de",
   "metadata": {},
   "source": [
    "# Programming vs. Prompting\n",
    "\n",
    "The shift from **prompting** to **programming** language models is the core innovation of DSPy. Understanding this paradigm shift is essential to mastering the framework.\n",
    "\n",
    "## The Three-Stage Architecture: DEMONSTRATE-SEARCH-PREDICT\n",
    "\n",
    "At the heart of DSPy lies the three-stage architecture that originated from the Demonstrate-Search-Predict research paper. This architecture provides a systematic way to structure complex reasoning tasks.\n",
    "\n",
    "### Stage 1: DEMONSTRATE\n",
    "\n",
    "The DEMONSTRATE stage focuses on learning from examples and building task understanding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15318f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In DSPy, demonstration is handled through:\n",
    "class TaskSignature(dspy.Signature):\n",
    "    \"\"\"Define what the task does\"\"\"\n",
    "    input_field: str = dspy.InputField()\n",
    "    output_field: str = dspy.OutputField()\n",
    "\n",
    "# Examples provide demonstrations\n",
    "trainset = [\n",
    "    dspy.Example(input_field=\"Example 1\", output_field=\"Expected output 1\"),\n",
    "    dspy.Example(input_field=\"Example 2\", output_field=\"Expected output 2\"),\n",
    "    # ... more demonstrations\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed3c9c0",
   "metadata": {},
   "source": [
    "**Key aspects**:\n",
    "- Learn task structure from demonstrations\n",
    "- Build understanding of input-output relationships\n",
    "- Create reusable patterns for similar tasks\n",
    "\n",
    "### Stage 2: SEARCH\n",
    "\n",
    "The SEARCH stage involves retrieving and synthesizing information from multiple sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ea48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Retrieval components\n",
    "        self.retrieve = dspy.Retrieve(k=5)  # Search for relevant documents\n",
    "        self.select_relevant = dspy.Predict(\"documents, query -> relevant_docs\")\n",
    "\n",
    "    def forward(self, query):\n",
    "        # Search for relevant information\n",
    "        docs = self.retrieve(query).passages\n",
    "        selected = self.select_relevant(documents=docs, query=query)\n",
    "        return selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c616ab",
   "metadata": {},
   "source": [
    "**Key aspects**:\n",
    "- Gather evidence from multiple sources\n",
    "- Filter and rank relevant information\n",
    "- Build context for final prediction\n",
    "\n",
    "### Stage 3: PREDICT\n",
    "\n",
    "The PREDICT stage generates the final output based on gathered evidence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af09f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictModule(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate = dspy.ChainOfThought(\"context, query -> answer\")\n",
    "\n",
    "    def forward(self, context, query):\n",
    "        # Generate final answer\n",
    "        result = self.generate(context=context, query=query)\n",
    "        return result.answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf6bd4e",
   "metadata": {},
   "source": [
    "**Key aspects**:\n",
    "- Synthesize information from search results\n",
    "- Generate final, accurate outputs\n",
    "- Apply reasoning patterns learned from demonstrations\n",
    "\n",
    "### Putting It All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4046f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSPipeline(dspy.Module):\n",
    "    \"\"\"Complete DEMONSTRATE-SEARCH-PREDICT pipeline\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Stage 1: Demonstration is handled by the optimizer\n",
    "        # Stage 2: Search\n",
    "        self.search = SearchModule()\n",
    "        # Stage 3: Predict\n",
    "        self.predict = PredictModule()\n",
    "\n",
    "    def forward(self, query):\n",
    "        # Execute the three stages\n",
    "        search_results = self.search(query=query)\n",
    "        final_answer = self.predict(context=search_results.relevant_docs, query=query)\n",
    "        return dspy.Prediction(answer=final_answer, context=search_results.relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e72c50e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Benefits of the Three-Stage Architecture\n",
    "\n",
    "1. **Composability**: Each stage can be optimized independently\n",
    "2. **Transparency**: Clear separation of concerns\n",
    "3. **Flexibility**: Different search strategies or prediction methods can be swapped\n",
    "4. **Optimization**: Each stage can be tuned separately\n",
    "5. **Debugging**: Issues can be isolated to specific stages\n",
    "\n",
    "This architecture maps directly to DSPy's modules:\n",
    "- **Signatures** + **Examples** → DEMONSTRATE\n",
    "- **Retrieve** + **ReAct** → SEARCH\n",
    "- **Predict** + **ChainOfThought** → PREDICT\n",
    "\n",
    "---\n",
    "\n",
    "## The Traditional Approach: Prompting\n",
    "\n",
    "### What is Prompting?\n",
    "\n",
    "Prompting is the practice of crafting text instructions to guide a language model's behavior.\n",
    "\n",
    "**Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118373dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are an expert chef. Given a list of ingredients, suggest a recipe.\n",
    "Be creative but practical. Include cooking time and difficulty level.\n",
    "\n",
    "Ingredients: chicken, garlic, olive oil, lemon, thyme\n",
    "\n",
    "Recipe:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19edc325",
   "metadata": {},
   "source": [
    "This approach has been the standard since GPT-3 launched in 2020.\n",
    "\n",
    "### The Prompting Workflow\n",
    "\n",
    "```\n",
    "1. Write a prompt\n",
    "2. Test with the model\n",
    "3. Observe output\n",
    "4. Tweak the prompt\n",
    "5. Repeat steps 2-4 until satisfied\n",
    "```\n",
    "\n",
    "This is **manual prompt engineering**—an iterative, hands-on process.\n",
    "\n",
    "---\n",
    "\n",
    "## Problems with Prompting at Scale\n",
    "\n",
    "While prompting works for simple cases, it breaks down as applications grow complex.\n",
    "\n",
    "### Problem 1: Prompt Fragility\n",
    "\n",
    "Small changes can dramatically affect results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16e38ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 1\n",
    "prompt_v1 = \"Summarize this article.\"\n",
    "\n",
    "# Version 2\n",
    "prompt_v2 = \"Summarize this article concisely.\"\n",
    "\n",
    "# Version 3\n",
    "prompt_v3 = \"Provide a concise summary of this article.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc3ecbb",
   "metadata": {},
   "source": [
    "Each version may produce different quality results, and there's no systematic way to know which is best.\n",
    "\n",
    "### Problem 2: No Composition\n",
    "\n",
    "Chaining prompts is manual and error-prone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0b87fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Extract entities\n",
    "entities_prompt = f\"Extract entities from: {text}\"\n",
    "entities = model(entities_prompt)\n",
    "\n",
    "# Step 2: Classify entities\n",
    "classification_prompt = f\"Classify these entities: {entities}\"\n",
    "classification = model(classification_prompt)\n",
    "\n",
    "# Step 3: Generate summary\n",
    "summary_prompt = f\"Summarize: {classification}\"\n",
    "summary = model(summary_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f78c2d",
   "metadata": {},
   "source": [
    "**Issues**:\n",
    "- No abstraction or reusability\n",
    "- Hard to test individual steps\n",
    "- Difficult to optimize the pipeline\n",
    "- Error handling is manual\n",
    "\n",
    "### Problem 3: No Systematic Optimization\n",
    "\n",
    "How do you improve this prompt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803f5d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = \"\"\"\n",
    "Answer the question using the provided context.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f07e5",
   "metadata": {},
   "source": [
    "Traditional approach:\n",
    "- Try different wordings manually\n",
    "- Add examples by hand\n",
    "- Test each variation\n",
    "- Hope for improvement\n",
    "\n",
    "This doesn't scale to complex applications.\n",
    "\n",
    "### Problem 4: Maintenance Nightmare\n",
    "\n",
    "As your application grows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243d5fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You end up with dozens of prompts\n",
    "SUMMARIZATION_PROMPT = \"...\"\n",
    "CLASSIFICATION_PROMPT = \"...\"\n",
    "ENTITY_EXTRACTION_PROMPT = \"...\"\n",
    "SENTIMENT_ANALYSIS_PROMPT = \"...\"\n",
    "QA_PROMPT = \"...\"\n",
    "# ... and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d46689",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Each prompt:\n",
    "- Needs individual testing\n",
    "- Requires manual updates\n",
    "- May interact with others unpredictably\n",
    "- Is hard to version and track\n",
    "\n",
    "---\n",
    "\n",
    "## The DSPy Approach: Programming\n",
    "\n",
    "DSPy flips the paradigm: instead of writing prompts, you **program** what you want the LM to do.\n",
    "\n",
    "### What is Programming with LMs?\n",
    "\n",
    "Programming means writing **declarative specifications** of tasks, not imperative instructions.\n",
    "\n",
    "**DSPy Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a39774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "class RecipeSuggestion(dspy.Signature):\n",
    "    \"\"\"Suggest a recipe based on ingredients.\"\"\"\n",
    "\n",
    "    ingredients: list[str] = dspy.InputField()\n",
    "    recipe_name: str = dspy.OutputField()\n",
    "    instructions: str = dspy.OutputField()\n",
    "    cooking_time: str = dspy.OutputField()\n",
    "    difficulty: str = dspy.OutputField(desc=\"easy, medium, or hard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d724ea24",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "No manual prompt writing—DSPy generates the prompts automatically!\n",
    "\n",
    "### The Programming Workflow\n",
    "\n",
    "```\n",
    "1. Define task signature (what to do)\n",
    "2. Choose/create module (how to do it)\n",
    "3. Optionally optimize (improve automatically)\n",
    "4. Deploy and iterate\n",
    "```\n",
    "\n",
    "This is **declarative programming**—you specify outcomes, not implementation details.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Differences\n",
    "\n",
    "### Imperative vs. Declarative\n",
    "\n",
    "**Prompting (Imperative)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c1f1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You tell the model HOW to do it\n",
    "prompt = \"\"\"\n",
    "First, read the context carefully.\n",
    "Then, identify the key information.\n",
    "Next, formulate an answer.\n",
    "Finally, provide your response in one sentence.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a53bfc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**DSPy (Declarative)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95b5fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You tell the model WHAT to do\n",
    "class AnswerQuestion(dspy.Signature):\n",
    "    \"\"\"Answer questions based on context.\"\"\"\n",
    "    context: str = dspy.InputField()\n",
    "    question: str = dspy.InputField()\n",
    "    answer: str = dspy.OutputField(desc=\"concise answer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f4933c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "DSPy figures out the HOW!\n",
    "\n",
    "### Manual vs. Automatic\n",
    "\n",
    "**Prompting**: Manual optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeff6e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different prompts manually\n",
    "prompts = [\n",
    "    \"Answer: {question}\",\n",
    "    \"Provide a clear answer to: {question}\",\n",
    "    \"Question: {question}\\nAnswer:\",\n",
    "]\n",
    "\n",
    "for prompt in prompts:\n",
    "    # Test and compare manually\n",
    "    result = test(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6591354",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**DSPy**: Automatic optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae0b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your program\n",
    "program = dspy.ChainOfThought(AnswerQuestion)\n",
    "\n",
    "# Optimize automatically\n",
    "from dspy.teleprompt import BootstrapFewShot\n",
    "optimizer = BootstrapFewShot(metric=accuracy)\n",
    "optimized_program = optimizer.compile(program, trainset=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe81fae",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Static vs. Composable\n",
    "\n",
    "**Prompting**: Static, monolithic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef7e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One big prompt for the entire task\n",
    "mega_prompt = \"\"\"\n",
    "Step 1: Extract entities from the text\n",
    "Step 2: Classify each entity\n",
    "Step 3: Summarize the entities\n",
    "Step 4: Generate final output\n",
    "\n",
    "Text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05924a73",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**DSPy**: Modular, composable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea3d495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate, reusable components\n",
    "class Pipeline(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.extract = dspy.Predict(\"text -> entities\")\n",
    "        self.classify = dspy.Predict(\"entities -> categories\")\n",
    "        self.summarize = dspy.Predict(\"categories -> summary\")\n",
    "\n",
    "    def forward(self, text):\n",
    "        entities = self.extract(text=text).entities\n",
    "        categories = self.classify(entities=entities).categories\n",
    "        summary = self.summarize(categories=categories).summary\n",
    "        return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8037bf8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The Paradigm Shift in Detail\n",
    "\n",
    "### From Monolithic Prompts to Structured Pipelines\n",
    "\n",
    "**Traditional prompting** mixes all stages into one monolithic prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eecbbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All stages crammed into one prompt\n",
    "monolithic_prompt = \"\"\"\n",
    "You are a helpful assistant. First, think about similar examples you've seen.\n",
    "Then search through your knowledge for relevant information.\n",
    "Finally, provide a clear answer.\n",
    "\n",
    "Example: Input \"2+2\" → Output \"4\"\n",
    "Example: Input \"3+3\" → Output \"6\"\n",
    "\n",
    "Now, answer this question: {query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6620d23f",
   "metadata": {},
   "source": [
    "**DSPy programming** separates and optimizes each stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6aa1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each stage is separate and optimizable\n",
    "pipeline = DSPipeline()  # Demonstrations are learned\n",
    "optimized_pipeline = optimizer.compile(pipeline, trainset=demos)\n",
    "\n",
    "result = optimized_pipeline(query=\"What is 4+4?\")\n",
    "# Each stage executed and optimized independently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4ae248",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### From Strings to Signatures\n",
    "\n",
    "**Old way** (strings):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7145fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt is a string you craft\n",
    "prompt = \"Translate '{text}' to French\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e406fb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**New way** (signatures):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920a0135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signature is a type specification\n",
    "class Translate(dspy.Signature):\n",
    "    text: str = dspy.InputField()\n",
    "    french_text: str = dspy.OutputField()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b95ab6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### From Templates to Types\n",
    "\n",
    "**Old way** (templates):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e0192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in template variables\n",
    "template = \"Context: {context}\\nQuestion: {question}\\nAnswer:\"\n",
    "filled = template.format(context=ctx, question=q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c8f53c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**New way** (typed fields):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84950a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define typed inputs and outputs\n",
    "class QA(dspy.Signature):\n",
    "    context: str = dspy.InputField()\n",
    "    question: str = dspy.InputField()\n",
    "    answer: str = dspy.OutputField()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28c43d7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### From Heuristics to Optimization\n",
    "\n",
    "**Old way** (heuristics):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f3f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add examples manually based on intuition\n",
    "examples = [\n",
    "    \"Q: What is 2+2? A: 4\",\n",
    "    \"Q: What is 3+3? A: 6\",\n",
    "]\n",
    "prompt_with_examples = f\"{examples}\\n{prompt}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c1c246",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**New way** (data-driven):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d68e7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn examples automatically from data\n",
    "optimizer = BootstrapFewShot(metric=accuracy)\n",
    "optimized = optimizer.compile(program, trainset=training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a462b5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Benefits of the Programming Paradigm\n",
    "\n",
    "### 1. Modularity\n",
    "\n",
    "Break complex tasks into simple components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e9031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each component is independent and testable\n",
    "extract_entities = dspy.Predict(\"text -> entities\")\n",
    "classify_entities = dspy.Predict(\"entities -> categories\")\n",
    "generate_summary = dspy.Predict(\"categories -> summary\")\n",
    "\n",
    "# Combine them\n",
    "def analyze(text):\n",
    "    entities = extract_entities(text=text).entities\n",
    "    categories = classify_entities(entities=entities).categories\n",
    "    summary = generate_summary(categories=categories).summary\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1a3489",
   "metadata": {},
   "source": [
    "### 2. Reusability\n",
    "\n",
    "Create once, use everywhere:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1295ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a reusable QA signature\n",
    "class QuestionAnswer(dspy.Signature):\n",
    "    context: str = dspy.InputField()\n",
    "    question: str = dspy.InputField()\n",
    "    answer: str = dspy.OutputField()\n",
    "\n",
    "# Use it in different contexts\n",
    "basic_qa = dspy.Predict(QuestionAnswer)\n",
    "reasoning_qa = dspy.ChainOfThought(QuestionAnswer)\n",
    "verified_qa = dspy.MultiChainOfThought(QuestionAnswer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fbd8aa",
   "metadata": {},
   "source": [
    "### 3. Testability\n",
    "\n",
    "Test components independently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f2df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a single module\n",
    "def test_entity_extraction():\n",
    "    extractor = dspy.Predict(\"text -> entities\")\n",
    "    result = extractor(text=\"Apple released iPhone in 2007\")\n",
    "    assert \"Apple\" in result.entities\n",
    "    assert \"iPhone\" in result.entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2b8d48",
   "metadata": {},
   "source": [
    "### 4. Automatic Optimization\n",
    "\n",
    "Improve systematically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07749d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your metric\n",
    "def accuracy_metric(example, prediction):\n",
    "    return prediction.answer == example.answer\n",
    "\n",
    "# Optimize automatically\n",
    "optimizer = BootstrapFewShot(metric=accuracy_metric)\n",
    "optimized_program = optimizer.compile(\n",
    "    MyProgram(),\n",
    "    trainset=training_examples\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ccbabd",
   "metadata": {},
   "source": [
    "### 5. Maintainability\n",
    "\n",
    "Changes are localized and manageable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e5f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change one signature\n",
    "class ImprovedQA(dspy.Signature):\n",
    "    \"\"\"Better QA with sources.\"\"\"\n",
    "    context: str = dspy.InputField()\n",
    "    question: str = dspy.InputField()\n",
    "    answer: str = dspy.OutputField()\n",
    "    sources: list[str] = dspy.OutputField()  # Added field\n",
    "\n",
    "# All modules using this signature automatically adapt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed48fb4d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Concrete Example: Building a QA System\n",
    "\n",
    "Let's build the same QA system both ways to see the difference.\n",
    "\n",
    "### Traditional Prompting Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf94aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def answer_question(context, question):\n",
    "    # Manually crafted prompt\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful assistant. Answer the question based only on the provided context.\n",
    "\n",
    "    Context: {context}\n",
    "\n",
    "    Question: {question}\n",
    "\n",
    "    Provide a clear, accurate answer based on the context above.\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Use it\n",
    "context = \"Paris is the capital of France. It has a population of 2.1 million.\"\n",
    "question = \"What is the capital of France?\"\n",
    "answer = answer_question(context, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e989f",
   "metadata": {},
   "source": [
    "**Issues**:\n",
    "- Prompt is hardcoded\n",
    "- No easy way to add reasoning\n",
    "- No systematic optimization\n",
    "- Hard to compose with other components\n",
    "\n",
    "### DSPy Programming Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6970b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "# Configure LM\n",
    "lm = dspy.LM(model=\"openai/gpt-4\")\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# Define the task\n",
    "class QuestionAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions based on provided context.\"\"\"\n",
    "    context: str = dspy.InputField()\n",
    "    question: str = dspy.InputField()\n",
    "    answer: str = dspy.OutputField()\n",
    "\n",
    "# Create module (can easily upgrade to ChainOfThought!)\n",
    "qa = dspy.Predict(QuestionAnswer)\n",
    "\n",
    "# Use it\n",
    "context = \"Paris is the capital of France. It has a population of 2.1 million.\"\n",
    "question = \"What is the capital of France?\"\n",
    "answer = qa(context=context, question=question).answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e4af83",
   "metadata": {},
   "source": [
    "**Benefits**:\n",
    "- Signature is declarative and reusable\n",
    "- Easy to upgrade (change `Predict` to `ChainOfThought`)\n",
    "- Can be optimized automatically\n",
    "- Composes naturally with other modules\n",
    "\n",
    "### Upgrading to Reasoning (DSPy Only!)\n",
    "\n",
    "With traditional prompting, adding reasoning means rewriting the prompt. With DSPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285b143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just change one line!\n",
    "qa = dspy.ChainOfThought(QuestionAnswer)\n",
    "\n",
    "# Now it reasons step-by-step automatically\n",
    "answer = qa(context=context, question=question).answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdd2c6c",
   "metadata": {},
   "source": [
    "That's it! No prompt rewriting needed.\n",
    "\n",
    "---\n",
    "\n",
    "## The Learning Curve\n",
    "\n",
    "### Traditional Prompting\n",
    "\n",
    "```\n",
    "Learn: Basic prompt structure → Practice trial and error → Build intuition\n",
    "Time: Days to weeks\n",
    "Scaling: Becomes harder with complexity\n",
    "```\n",
    "\n",
    "### DSPy Programming\n",
    "\n",
    "```\n",
    "Learn: Signatures → Modules → Optimization → Composition\n",
    "Time: Days to weeks (similar initial investment)\n",
    "Scaling: Becomes easier with complexity\n",
    "```\n",
    "\n",
    "**Key insight**: DSPy has a similar initial learning curve, but pays dividends as your application grows.\n",
    "\n",
    "---\n",
    "\n",
    "## When to Use Which Approach?\n",
    "\n",
    "### Use Traditional Prompting When:\n",
    "\n",
    "- ✅ One-off task or prototype\n",
    "- ✅ Very simple, single-step operation\n",
    "- ✅ You need specific prompt control\n",
    "- ✅ No optimization needed\n",
    "\n",
    "### Use DSPy When:\n",
    "\n",
    "- ✅ Building a complex system\n",
    "- ✅ Multiple steps or components\n",
    "- ✅ Want systematic optimization\n",
    "- ✅ Need maintainability and testability\n",
    "- ✅ Have training data available\n",
    "\n",
    "---\n",
    "\n",
    "## Analogy: Assembly vs. High-Level Languages\n",
    "\n",
    "The prompting → programming shift is like assembly → high-level languages:\n",
    "\n",
    "### Assembly (Manual Prompting)\n",
    "\n",
    "```assembly\n",
    "; Direct, detailed control\n",
    "MOV AX, 5\n",
    "ADD AX, 3\n",
    "MOV result, AX\n",
    "```\n",
    "\n",
    "- Maximum control\n",
    "- Tedious for complex tasks\n",
    "- Hard to maintain\n",
    "\n",
    "### High-Level Language (DSPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d16a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstract, declarative\n",
    "result = 5 + 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab37192",
   "metadata": {},
   "source": [
    "- Easier to write and understand\n",
    "- Better for complex systems\n",
    "- Compiler handles optimization\n",
    "\n",
    "Similarly, DSPy abstracts away prompt engineering!\n",
    "\n",
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### The Paradigm Shift\n",
    "\n",
    "| Aspect | Prompting | Programming (DSPy) |\n",
    "|--------|-----------|-------------------|\n",
    "| **Approach** | Imperative (\"how\") | Declarative (\"what\") |\n",
    "| **Optimization** | Manual trial & error | Automatic from data |\n",
    "| **Composition** | Difficult | Natural |\n",
    "| **Maintainability** | Poor for complex | Good |\n",
    "| **Scalability** | Struggles | Excels |\n",
    "| **Learning curve** | Moderate | Moderate |\n",
    "| **Best for** | Simple, one-off tasks | Complex, evolving systems |\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Prompting** = Writing instructions for the model\n",
    "2. **Programming** = Defining specifications for tasks\n",
    "3. **DSPy generates prompts** automatically from signatures\n",
    "4. **Composition and optimization** come naturally with programming\n",
    "5. **Invest in learning DSPy** for long-term productivity\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now that you understand the paradigm shift, let's get DSPy installed and configured.\n",
    "\n",
    "**Continue to**: [Installation and Setup](03-installation-setup.md)\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- **Blog**: [From Prompting to Programming](https://dspy.ai/blog/programming-vs-prompting)\n",
    "- **Paper**: Section 2 of the [DSPy paper](https://arxiv.org/abs/2310.03714) discusses this paradigm shift\n",
    "- **Tutorial**: [DSPy Tutorial on Programming Paradigm](https://dspy.ai/tutorials/programming)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
