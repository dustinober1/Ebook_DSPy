{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15a16e0a",
   "metadata": {},
   "source": [
    "# Custom Modules\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- **Previous Sections**: [ReAct Agents](./04-react-agents.md) - Understanding of advanced modules\n",
    "- **Chapter 2**: Signatures - Mastery of signature design\n",
    "- **Required Knowledge**: Object-oriented programming in Python\n",
    "- **Difficulty Level**: Advanced\n",
    "- **Estimated Reading Time**: 50 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this section, you will:\n",
    "- Understand how to build custom DSPy modules from scratch\n",
    "- Master the module lifecycle and internal architecture\n",
    "- Learn to implement specialized behaviors for unique use cases\n",
    "- Discover patterns for extensible and reusable modules\n",
    "- Build production-ready custom modules\n",
    "\n",
    "## Why Build Custom Modules?\n",
    "\n",
    "While DSPy provides powerful built-in modules, custom modules allow you to:\n",
    "\n",
    "1. **Implement unique behaviors** not covered by standard modules\n",
    "2. **Optimize for specific domains** or use cases\n",
    "3. **Integrate proprietary systems** or APIs\n",
    "4. **Add custom preprocessing** or postprocessing logic\n",
    "5. **Implement specialized reasoning** patterns\n",
    "6. **Create reusable components** for your organization\n",
    "\n",
    "## Module Architecture Deep Dive\n",
    "\n",
    "### Core Module Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b942107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from typing import Any, Dict, List, Optional\n",
    "import inspect\n",
    "\n",
    "class CustomModule(dspy.Module):\n",
    "    \"\"\"Base class showing all components of a DSPy module.\"\"\"\n",
    "\n",
    "    def __init__(self, signature, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1. Store the signature\n",
    "        self.signature = signature\n",
    "\n",
    "        # 2. Configure language model\n",
    "        self.lm = kwargs.get('lm', dspy.settings.lm)\n",
    "        self.temperature = kwargs.get('temperature', 0.7)\n",
    "\n",
    "        # 3. Setup demos (few-shot examples)\n",
    "        self.demos = kwargs.get('demos', [])\n",
    "\n",
    "        # 4. Configure instructions\n",
    "        self.instructions = kwargs.get('instructions', '')\n",
    "\n",
    "        # 5. Setup cache\n",
    "        self.cache_enabled = kwargs.get('cache', False)\n",
    "        self._cache = {} if self.cache_enabled else None\n",
    "\n",
    "        # 6. Validation\n",
    "        self.validate_configuration()\n",
    "\n",
    "        # 7. Initialize components\n",
    "        self.initialize_components(**kwargs)\n",
    "\n",
    "    def forward(self, **kwargs) -> dspy.Prediction:\n",
    "        \"\"\"Main execution method - override this in subclasses.\"\"\"\n",
    "\n",
    "        # 1. Validate inputs\n",
    "        self.validate_inputs(**kwargs)\n",
    "\n",
    "        # 2. Check cache\n",
    "        cache_key = self.get_cache_key(**kwargs)\n",
    "        if self.cache_enabled and cache_key in self._cache:\n",
    "            return self._cache[cache_key]\n",
    "\n",
    "        # 3. Preprocess inputs\n",
    "        processed_inputs = self.preprocess_inputs(**kwargs)\n",
    "\n",
    "        # 4. Construct prompt\n",
    "        prompt = self.construct_prompt(**processed_inputs)\n",
    "\n",
    "        # 5. Call LLM\n",
    "        response = self.call_llm(prompt)\n",
    "\n",
    "        # 6. Parse response\n",
    "        parsed_output = self.parse_response(response)\n",
    "\n",
    "        # 7. Postprocess\n",
    "        final_output = self.postprocess_output(parsed_output, **kwargs)\n",
    "\n",
    "        # 8. Cache result\n",
    "        if self.cache_enabled:\n",
    "            self._cache[cache_key] = final_output\n",
    "\n",
    "        return final_output\n",
    "\n",
    "    def validate_configuration(self):\n",
    "        \"\"\"Validate module configuration.\"\"\"\n",
    "        if not self.signature:\n",
    "            raise ValueError(\"Signature is required\")\n",
    "\n",
    "    def initialize_components(self, **kwargs):\n",
    "        \"\"\"Initialize module-specific components.\"\"\"\n",
    "        pass\n",
    "\n",
    "    def validate_inputs(self, **kwargs):\n",
    "        \"\"\"Validate input parameters.\"\"\"\n",
    "        # Check all required signature inputs are present\n",
    "        required_inputs = self.signature.input_fields\n",
    "        for input_field in required_inputs:\n",
    "            if input_field.name not in kwargs:\n",
    "                raise ValueError(f\"Missing required input: {input_field.name}\")\n",
    "\n",
    "    def preprocess_inputs(self, **kwargs):\n",
    "        \"\"\"Preprocess inputs before prompt construction.\"\"\"\n",
    "        return kwargs\n",
    "\n",
    "    def construct_prompt(self, **kwargs) -> str:\n",
    "        \"\"\"Construct the prompt for the LLM.\"\"\"\n",
    "        prompt_parts = []\n",
    "\n",
    "        # Add instructions\n",
    "        if self.instructions:\n",
    "            prompt_parts.append(self.instructions)\n",
    "\n",
    "        # Add demos\n",
    "        for demo in self.demos:\n",
    "            prompt_parts.append(self.format_demo(demo))\n",
    "\n",
    "        # Add current inputs\n",
    "        prompt_parts.append(self.format_inputs(**kwargs))\n",
    "\n",
    "        # Add output format guidance\n",
    "        prompt_parts.append(self.format_output_guidance())\n",
    "\n",
    "        return \"\\n\\n\".join(prompt_parts)\n",
    "\n",
    "    def format_demo(self, demo) -> str:\n",
    "        \"\"\"Format a few-shot example.\"\"\"\n",
    "        # Default implementation\n",
    "        inputs_str = \"\\n\".join([f\"{k}: {v}\" for k, v in demo.items() if not k.startswith('output_')])\n",
    "        outputs_str = \"\\n\".join([f\"{k}: {v}\" for k, v in demo.items() if k.startswith('output_')])\n",
    "        return f\"Example:\\n{inputs_str}\\n\\n{outputs_str}\"\n",
    "\n",
    "    def format_inputs(self, **kwargs) -> str:\n",
    "        \"\"\"Format current inputs.\"\"\"\n",
    "        return \"\\n\".join([f\"{k}: {v}\" for k, v in kwargs.items()])\n",
    "\n",
    "    def format_output_guidance(self) -> str:\n",
    "        \"\"\"Add guidance for output formatting.\"\"\"\n",
    "        output_fields = self.signature.output_fields\n",
    "        return f\"Provide the output in this format:\\n\" + \\\n",
    "               \"\\n\".join([f\"{field.name}: <{field.name}>\" for field in output_fields])\n",
    "\n",
    "    def call_llm(self, prompt: str) -> str:\n",
    "        \"\"\"Call the language model.\"\"\"\n",
    "        return self.lm(prompt, temperature=self.temperature)\n",
    "\n",
    "    def parse_response(self, response: str) -> Dict[str, Any]:\n",
    "        \"\"\"Parse LLM response according to signature.\"\"\"\n",
    "        # Default parsing - can be overridden\n",
    "        output_fields = self.signature.output_fields\n",
    "        parsed = {}\n",
    "\n",
    "        # Simple line-by-line parsing\n",
    "        lines = response.strip().split('\\n')\n",
    "        for line in lines:\n",
    "            for field in output_fields:\n",
    "                if line.startswith(f\"{field.name}:\"):\n",
    "                    parsed[field.name] = line[len(field.name):].strip()\n",
    "\n",
    "        # Ensure all outputs are present\n",
    "        for field in output_fields:\n",
    "            if field.name not in parsed:\n",
    "                parsed[field.name] = \"\"  # Default empty value\n",
    "\n",
    "        return parsed\n",
    "\n",
    "    def postprocess_output(self, parsed_output: Dict[str, Any], **kwargs) -> dspy.Prediction:\n",
    "        \"\"\"Postprocess parsed output.\"\"\"\n",
    "        return dspy.Prediction(**parsed_output)\n",
    "\n",
    "    def get_cache_key(self, **kwargs) -> str:\n",
    "        \"\"\"Generate cache key from inputs.\"\"\"\n",
    "        import hashlib\n",
    "        key_str = str(sorted(kwargs.items())) + str(self.temperature)\n",
    "        return hashlib.md5(key_str.encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd2843",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Simple Custom Module Example\n",
    "\n",
    "### Sentiment Analysis with Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce81459",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentAnalyzer(dspy.Module):\n",
    "    \"\"\"Custom module for sentiment analysis with confidence scoring.\"\"\"\n",
    "\n",
    "    def __init__(self, model=\"sentiment-analysis-v2\"):\n",
    "        # Define signature\n",
    "        self.signature = dspy.Signature(\n",
    "            \"text -> sentiment, confidence_score, emotional_indicators\"\n",
    "        )\n",
    "\n",
    "        # Initialize\n",
    "        super().__init__()\n",
    "\n",
    "        # Custom initialization\n",
    "        self.model = model\n",
    "        self.sentiment_labels = [\"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "        # Preload sentiment lexicon\n",
    "        self.load_sentiment_lexicon()\n",
    "\n",
    "    def load_sentiment_lexicon(self):\n",
    "        \"\"\"Load or create sentiment word lists.\"\"\"\n",
    "        self.positive_words = {\n",
    "            \"excellent\", \"amazing\", \"wonderful\", \"fantastic\", \"great\",\n",
    "            \"good\", \"love\", \"perfect\", \"awesome\", \"brilliant\"\n",
    "        }\n",
    "\n",
    "        self.negative_words = {\n",
    "            \"terrible\", \"awful\", \"horrible\", \"bad\", \"poor\",\n",
    "            \"hate\", \"worst\", \"disgusting\", \"disappointing\", \"useless\"\n",
    "        }\n",
    "\n",
    "    def preprocess_inputs(self, **kwargs):\n",
    "        \"\"\"Add sentiment word counts to inputs.\"\"\"\n",
    "        text = kwargs.get(\"text\", \"\")\n",
    "\n",
    "        # Count sentiment words\n",
    "        text_lower = text.lower()\n",
    "        pos_count = sum(1 for word in self.positive_words if word in text_lower)\n",
    "        neg_count = sum(1 for word in self.negative_words if word in text_lower)\n",
    "\n",
    "        kwargs[\"positive_word_count\"] = pos_count\n",
    "        kwargs[\"negative_word_count\"] = neg_count\n",
    "        kwargs[\"sentiment_word_ratio\"] = pos_count - neg_count\n",
    "\n",
    "        return kwargs\n",
    "\n",
    "    def format_inputs(self, **kwargs):\n",
    "        \"\"\"Custom input formatting.\"\"\"\n",
    "        text = kwargs.get(\"text\", \"\")\n",
    "        pos_count = kwargs.get(\"positive_word_count\", 0)\n",
    "        neg_count = kwargs.get(\"negative_word_count\", 0)\n",
    "\n",
    "        return f\"Text to analyze: {text}\\n\" + \\\n",
    "               f\"Positive words found: {pos_count}\\n\" + \\\n",
    "               f\"Negative words found: {neg_count}\\n\" + \\\n",
    "               f\"Sentiment word score: {pos_count - neg_count}\"\n",
    "\n",
    "    def construct_prompt(self, **kwargs):\n",
    "        \"\"\"Custom prompt construction.\"\"\"\n",
    "        text = kwargs.get(\"text\", \"\")\n",
    "\n",
    "        prompt = f\"\"\"Analyze the sentiment of this text:\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "Instructions:\n",
    "1. Determine if the sentiment is positive, negative, or neutral\n",
    "2. Provide a confidence score from 0.0 to 1.0\n",
    "3. List emotional indicators (e.g., joy, anger, surprise, fear)\n",
    "\n",
    "Output format:\n",
    "sentiment: <positive/negative/neutral>\n",
    "confidence_score: <0.0-1.0>\n",
    "emotional_indicators: <list of emotions>\n",
    "\"\"\"\n",
    "        return prompt\n",
    "\n",
    "    def postprocess_output(self, parsed_output, **kwargs):\n",
    "        \"\"\"Ensure confidence score is valid and normalized.\"\"\"\n",
    "        confidence = parsed_output.get(\"confidence_score\", \"0.5\")\n",
    "\n",
    "        # Extract numeric value\n",
    "        if isinstance(confidence, str):\n",
    "            import re\n",
    "            match = re.search(r'[\\d.]+', confidence)\n",
    "            if match:\n",
    "                confidence = float(match.group())\n",
    "            else:\n",
    "                confidence = 0.5\n",
    "\n",
    "        # Ensure within valid range\n",
    "        confidence = max(0.0, min(1.0, confidence))\n",
    "\n",
    "        # Adjust based on sentiment word evidence\n",
    "        pos_count = kwargs.get(\"positive_word_count\", 0)\n",
    "        neg_count = kwargs.get(\"negative_word_count\", 0)\n",
    "        word_confidence = (pos_count + neg_count) / (len(kwargs.get(\"text\", \"\").split()) + 1)\n",
    "\n",
    "        # Blend model confidence with word evidence\n",
    "        final_confidence = 0.7 * confidence + 0.3 * min(1.0, word_confidence)\n",
    "\n",
    "        parsed_output[\"confidence_score\"] = round(final_confidence, 2)\n",
    "\n",
    "        return dspy.Prediction(**parsed_output)\n",
    "\n",
    "# Use the custom module\n",
    "analyzer = SentimentAnalyzer()\n",
    "result = analyzer(text=\"I absolutely love this product! It works perfectly and exceeded all my expectations.\")\n",
    "print(f\"Sentiment: {result.sentiment}\")\n",
    "print(f\"Confidence: {result.confidence_score}\")\n",
    "print(f\"Emotions: {result.emotional_indicators}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25f1982",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Advanced Custom Module - MultiStepProcessor\n",
    "\n",
    "### Module with Multiple Processing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce9b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiStepProcessor(dspy.Module):\n",
    "    \"\"\"Module that processes data through multiple customizable steps.\"\"\"\n",
    "\n",
    "    def __init__(self, steps: List[Dict[str, Any]], signature: dspy.Signature):\n",
    "        \"\"\"\n",
    "        Initialize with processing steps.\n",
    "\n",
    "        Args:\n",
    "            steps: List of step configurations\n",
    "            signature: DSPy signature for the module\n",
    "        \"\"\"\n",
    "        self.steps = steps\n",
    "        self.signature = signature\n",
    "        self.step_results = {}\n",
    "\n",
    "        # Validate steps\n",
    "        self.validate_steps()\n",
    "\n",
    "        # Initialize components\n",
    "        super().__init__()\n",
    "\n",
    "    def validate_steps(self):\n",
    "        \"\"\"Validate that steps are properly configured.\"\"\"\n",
    "        required_keys = [\"name\", \"type\", \"prompt\"]\n",
    "        for i, step in enumerate(self.steps):\n",
    "            for key in required_keys:\n",
    "                if key not in step:\n",
    "                    raise ValueError(f\"Step {i} missing required key: {key}\")\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        \"\"\"Execute all processing steps sequentially.\"\"\"\n",
    "        # Store initial inputs\n",
    "        self.step_results[\"initial\"] = kwargs.copy()\n",
    "\n",
    "        # Process each step\n",
    "        current_data = kwargs.copy()\n",
    "        for step in self.steps:\n",
    "            current_data = self.execute_step(step, current_data)\n",
    "            self.step_results[step[\"name\"]] = current_data.copy()\n",
    "\n",
    "        # Final formatting according to signature\n",
    "        return self.format_final_output(current_data)\n",
    "\n",
    "    def execute_step(self, step: Dict[str, Any], data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute a single processing step.\"\"\"\n",
    "        step_type = step[\"type\"]\n",
    "\n",
    "        if step_type == \"transform\":\n",
    "            return self.execute_transform_step(step, data)\n",
    "        elif step_type == \"analyze\":\n",
    "            return self.execute_analyze_step(step, data)\n",
    "        elif step_type == \"filter\":\n",
    "            return self.execute_filter_step(step, data)\n",
    "        elif step_type == \"aggregate\":\n",
    "            return self.execute_aggregate_step(step, data)\n",
    "        elif step_type == \"enrich\":\n",
    "            return self.execute_enrich_step(step, data)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown step type: {step_type}\")\n",
    "\n",
    "    def execute_transform_step(self, step: Dict[str, Any], data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute a transformation step.\"\"\"\n",
    "        field_name = step.get(\"field\")\n",
    "        transformation = step.get(\"transformation\", \"uppercase\")\n",
    "\n",
    "        if field_name and field_name in data:\n",
    "            original_value = str(data[field_name])\n",
    "\n",
    "            if transformation == \"uppercase\":\n",
    "                data[f\"{field_name}_transformed\"] = original_value.upper()\n",
    "            elif transformation == \"lowercase\":\n",
    "                data[f\"{field_name}_transformed\"] = original_value.lower()\n",
    "            elif transformation == \"length\":\n",
    "                data[f\"{field_name}_length\"] = len(original_value)\n",
    "            elif transformation == \"reverse\":\n",
    "                data[f\"{field_name}_reversed\"] = original_value[::-1]\n",
    "\n",
    "        return data\n",
    "\n",
    "    def execute_analyze_step(self, step: Dict[str, Any], data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute an analysis step using the LLM.\"\"\"\n",
    "        analysis_prompt = step[\"prompt\"].format(**data)\n",
    "\n",
    "        # Use LM for analysis\n",
    "        analysis_result = self.lm(analysis_prompt)\n",
    "\n",
    "        data[f\"{step['name']}_analysis\"] = analysis_result\n",
    "        return data\n",
    "\n",
    "    def execute_filter_step(self, step: Dict[str, Any], data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute a filtering step.\"\"\"\n",
    "        condition = step.get(\"condition\", \"all\")\n",
    "        field = step.get(\"field\")\n",
    "\n",
    "        if condition == \"non_empty\" and field:\n",
    "            if field in data and data[field]:\n",
    "                data[f\"{field}_passed_filter\"] = True\n",
    "            else:\n",
    "                data[f\"{field}_passed_filter\"] = False\n",
    "\n",
    "        return data\n",
    "\n",
    "    def execute_aggregate_step(self, step: Dict[str, Any], data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute an aggregation step.\"\"\"\n",
    "        fields = step.get(\"fields\", [])\n",
    "        operation = step.get(\"operation\", \"combine\")\n",
    "\n",
    "        if operation == \"combine\" and fields:\n",
    "            combined = []\n",
    "            for field in fields:\n",
    "                if field in data:\n",
    "                    combined.append(str(data[field]))\n",
    "            data[f\"combined_{'_'.join(fields)}\"] = \" \".join(combined)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def execute_enrich_step(self, step: Dict[str, Any], data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Execute an enrichment step (add external information).\"\"\"\n",
    "        field = step.get(\"field\")\n",
    "        enrich_type = step.get(\"type\", \"timestamp\")\n",
    "\n",
    "        if field and field in data:\n",
    "            if enrich_type == \"timestamp\":\n",
    "                from datetime import datetime\n",
    "                data[f\"{field}_enriched_at\"] = datetime.now().isoformat()\n",
    "            elif enrich_type == \"length\":\n",
    "                data[f\"{field}_length\"] = len(str(data[field]))\n",
    "            elif enrich_type == \"hash\":\n",
    "                import hashlib\n",
    "                content = str(data[field])\n",
    "                data[f\"{field}_hash\"] = hashlib.md5(content.encode()).hexdigest()\n",
    "\n",
    "        return data\n",
    "\n",
    "    def format_final_output(self, data: Dict[str, Any]) -> dspy.Prediction:\n",
    "        \"\"\"Format the final output according to signature.\"\"\"\n",
    "        output = {}\n",
    "\n",
    "        # Extract fields that match signature outputs\n",
    "        for field in self.signature.output_fields:\n",
    "            if field.name in data:\n",
    "                output[field.name] = data[field.name]\n",
    "            else:\n",
    "                # Try to find related fields\n",
    "                related = [k for k in data.keys() if field.name.lower() in k.lower()]\n",
    "                if related:\n",
    "                    output[field.name] = str(data[related[0]])\n",
    "                else:\n",
    "                    output[field.name] = \"\"  # Default empty value\n",
    "\n",
    "        return dspy.Prediction(**output)\n",
    "\n",
    "# Example usage\n",
    "steps = [\n",
    "    {\n",
    "        \"name\": \"text_cleanup\",\n",
    "        \"type\": \"transform\",\n",
    "        \"field\": \"content\",\n",
    "        \"transformation\": \"lowercase\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"sentiment_check\",\n",
    "        \"type\": \"analyze\",\n",
    "        \"prompt\": \"Analyze the sentiment of this text: {content_transformed}. Is it positive, negative, or neutral?\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"timestamp\",\n",
    "        \"type\": \"enrich\",\n",
    "        \"field\": \"content\",\n",
    "        \"type\": \"timestamp\"\n",
    "    }\n",
    "]\n",
    "\n",
    "signature = dspy.Signature(\"content -> cleaned_content, sentiment_analysis, processed_at\")\n",
    "processor = MultiStepProcessor(steps, signature)\n",
    "\n",
    "result = processor(content=\"This is an AMAZING product! I love it so much!\")\n",
    "print(f\"Cleaned: {result.cleaned_content}\")\n",
    "print(f\"Sentiment: {result.sentiment_analysis}\")\n",
    "print(f\"Processed at: {result.processed_at}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1704277",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Domain-Specific Custom Module\n",
    "\n",
    "### Financial Document Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialDocumentAnalyzer(dspy.Module):\n",
    "    \"\"\"Specialized module for analyzing financial documents.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.signature = dspy.Signature(\n",
    "            \"document_text, document_type -> financial_metrics, risk_indicators, recommendations\"\n",
    "        )\n",
    "\n",
    "        # Financial analysis patterns\n",
    "        self.metric_patterns = {\n",
    "            \"revenue\": r\"\\$[\\d,]+\\.?\\d*\\s*(?:million|billion|thousand)\",\n",
    "            \"profit_margin\": r\"profit\\s*margin[:\\s]*[\\d.]+%\",\n",
    "            \"growth\": r\"growth[:\\s]*[\\d.]+%\"\n",
    "        }\n",
    "\n",
    "        # Risk keywords\n",
    "        self.risk_keywords = [\n",
    "            \"debt\", \"liability\", \"risk\", \"decline\", \"loss\",\n",
    "            \"bankruptcy\", \"default\", \"delinquent\"\n",
    "        ]\n",
    "\n",
    "        # Initialize\n",
    "        super().__init__()\n",
    "\n",
    "        # Load financial knowledge base\n",
    "        self.load_financial_knowledge()\n",
    "\n",
    "    def load_financial_knowledge(self):\n",
    "        \"\"\"Load financial analysis rules.\"\"\"\n",
    "        self.financial_rules = {\n",
    "            \"healthy_profit_margin\": (15, 50),  # min, max percent\n",
    "            \"debt_to_equity\": (0, 2),  # ratio range\n",
    "            \"revenue_growth\": (5, 100)  # percent\n",
    "        }\n",
    "\n",
    "    def preprocess_inputs(self, **kwargs):\n",
    "        \"\"\"Extract initial financial metrics from text.\"\"\"\n",
    "        document = kwargs.get(\"document_text\", \"\")\n",
    "\n",
    "        # Extract metrics using regex\n",
    "        extracted_metrics = self.extract_financial_metrics(document)\n",
    "        kwargs[\"extracted_metrics\"] = extracted_metrics\n",
    "\n",
    "        # Calculate initial risk score\n",
    "        risk_score = self.calculate_risk_score(document)\n",
    "        kwargs[\"initial_risk_score\"] = risk_score\n",
    "\n",
    "        return kwargs\n",
    "\n",
    "    def extract_financial_metrics(self, text: str) -> Dict[str, List[str]]:\n",
    "        \"\"\"Extract financial metrics from text.\"\"\"\n",
    "        import re\n",
    "        metrics = {}\n",
    "\n",
    "        for metric, pattern in self.metric_patterns.items():\n",
    "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "            if matches:\n",
    "                metrics[metric] = matches\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    def calculate_risk_score(self, text: str) -> float:\n",
    "        \"\"\"Calculate initial risk score based on keyword presence.\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        risk_word_count = sum(1 for word in self.risk_keywords if word in text_lower)\n",
    "        total_words = len(text.split())\n",
    "\n",
    "        # Normalize by document length\n",
    "        risk_score = min(1.0, (risk_word_count / total_words) * 100)\n",
    "        return risk_score\n",
    "\n",
    "    def construct_prompt(self, **kwargs):\n",
    "        \"\"\"Construct specialized financial analysis prompt.\"\"\"\n",
    "        document = kwargs.get(\"document_text\", \"\")\n",
    "        doc_type = kwargs.get(\"document_type\", \"unknown\")\n",
    "        metrics = kwargs.get(\"extracted_metrics\", {})\n",
    "        risk_score = kwargs.get(\"initial_risk_score\", 0)\n",
    "\n",
    "        prompt = f\"\"\"As a financial analyst, analyze this {doc_type} document:\n",
    "\n",
    "Document:\n",
    "{document}\n",
    "\n",
    "Initial Analysis:\n",
    "- Extracted Metrics: {metrics}\n",
    "- Risk Indicators Score: {risk_score:.2f}\n",
    "\n",
    "Please provide:\n",
    "1. Key Financial Metrics (with values if found)\n",
    "2. Risk Indicators (high/medium/low with reasons)\n",
    "3. Recommendations (actionable insights)\n",
    "\n",
    "Consider standard financial benchmarks:\n",
    "- Healthy profit margin: 15-50%\n",
    "- Debt-to-equity ratio should be < 2\n",
    "- Revenue growth should be positive\n",
    "\n",
    "Output format:\n",
    "financial_metrics: <structured financial metrics>\n",
    "risk_indicators: <risk assessment with details>\n",
    "recommendations: <numbered list of recommendations>\n",
    "\"\"\"\n",
    "        return prompt\n",
    "\n",
    "    def postprocess_output(self, parsed_output, **kwargs):\n",
    "        \"\"\"Enhance output with calculated values.\"\"\"\n",
    "        # Add initial metrics to output\n",
    "        if \"extracted_metrics\" in kwargs:\n",
    "            # Convert to string for display\n",
    "            metrics_str = \"\\n\".join([\n",
    "                f\"{k}: {', '.join(v)}\" for k, v in kwargs[\"extracted_metrics\"].items()\n",
    "            ])\n",
    "\n",
    "            if \"financial_metrics\" in parsed_output:\n",
    "                parsed_output[\"financial_metrics\"] = f\"Extracted:\\n{metrics_str}\\n\\nAnalyzed:\\n{parsed_output['financial_metrics']}\"\n",
    "\n",
    "        # Add risk scoring context\n",
    "        initial_score = kwargs.get(\"initial_risk_score\", 0)\n",
    "        if \"risk_indicators\" in parsed_output:\n",
    "            parsed_output[\"risk_indicators\"] = f\"Text Analysis Score: {initial_score:.2f}\\n{parsed_output['risk_indicators']}\"\n",
    "\n",
    "        return dspy.Prediction(**parsed_output)\n",
    "\n",
    "# Use the financial analyzer\n",
    "analyzer = FinancialDocumentAnalyzer()\n",
    "result = analyzer(\n",
    "    document_text=\"Quarterly report shows revenue of $5.2 million with profit margin of 18%. \"\n",
    "                  \"Company has $3 million in debt but shows steady growth of 12%.\",\n",
    "    document_type=\"quarterly_report\"\n",
    ")\n",
    "\n",
    "print(f\"Metrics: {result.financial_metrics}\")\n",
    "print(f\"Risks: {result.risk_indicators}\")\n",
    "print(f\"Recommendations: {result.recommendations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3532ad",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Module Composition Patterns\n",
    "\n",
    "### Module Wrapper for Existing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b6b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_module_from_function(func, signature):\n",
    "    \"\"\"Create a DSPy module from any Python function.\"\"\"\n",
    "\n",
    "    class FunctionModule(dspy.Module):\n",
    "        def __init__(self):\n",
    "            self.func = func\n",
    "            self.signature = signature\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, **kwargs):\n",
    "            # Extract signature inputs\n",
    "            sig_inputs = {field.name: kwargs.get(field.name)\n",
    "                          for field in self.signature.input_fields\n",
    "                          if field.name in kwargs}\n",
    "\n",
    "            # Call the function\n",
    "            result = self.func(**sig_inputs)\n",
    "\n",
    "            # Prepare output\n",
    "            if isinstance(result, dict):\n",
    "                return dspy.Prediction(**result)\n",
    "            else:\n",
    "                # Single output\n",
    "                output_field = self.signature.output_fields[0]\n",
    "                return dspy.Prediction(**{output_field.name: result})\n",
    "\n",
    "    return FunctionModule()\n",
    "\n",
    "# Example: Wrap a text processing function\n",
    "def process_text(text: str, operation: str) -> str:\n",
    "    \"\"\"Simple text processing function.\"\"\"\n",
    "    if operation == \"uppercase\":\n",
    "        return text.upper()\n",
    "    elif operation == \"lowercase\":\n",
    "        return text.lower()\n",
    "    elif operation == \"reverse\":\n",
    "        return text[::-1]\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Create module from function\n",
    "text_processor = create_module_from_function(\n",
    "    process_text,\n",
    "    dspy.Signature(\"text, operation -> processed_text\")\n",
    ")\n",
    "\n",
    "result = text_processor(text=\"Hello World\", operation=\"uppercase\")\n",
    "print(result.processed_text)  # \"HELLO WORLD\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa398657",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Testing Custom Modules\n",
    "\n",
    "### Unit Testing Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41592cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class TestSentimentAnalyzer(unittest.TestCase):\n",
    "    \"\"\"Test suite for custom SentimentAnalyzer module.\"\"\"\n",
    "\n",
    "    def setUp(self):\n",
    "        self.analyzer = SentimentAnalyzer()\n",
    "\n",
    "    def test_positive_sentiment(self):\n",
    "        \"\"\"Test analysis of positive text.\"\"\"\n",
    "        result = self.analyzer(text=\"This is absolutely wonderful!\")\n",
    "\n",
    "        self.assertEqual(result.sentiment, \"positive\")\n",
    "        self.assertGreater(result.confidence_score, 0.5)\n",
    "\n",
    "    def test_negative_sentiment(self):\n",
    "        \"\"\"Test analysis of negative text.\"\"\"\n",
    "        result = self.analyzer(text=\"This is terrible and awful.\")\n",
    "\n",
    "        self.assertEqual(result.sentiment, \"negative\")\n",
    "        self.assertGreater(result.confidence_score, 0.5)\n",
    "\n",
    "    def test_confidence_range(self):\n",
    "        \"\"\"Test that confidence is always in valid range.\"\"\"\n",
    "        for text in [\"Good\", \"Bad\", \"Neutral\", \"Amazing\", \"Terrible\"]:\n",
    "            result = self.analyzer(text=text)\n",
    "            self.assertGreaterEqual(result.confidence_score, 0.0)\n",
    "            self.assertLessEqual(result.confidence_score, 1.0)\n",
    "\n",
    "    def test_empty_text(self):\n",
    "        \"\"\"Test handling of empty text.\"\"\"\n",
    "        result = self.analyzer(text=\"\")\n",
    "\n",
    "        self.assertIn(result.sentiment, [\"positive\", \"negative\", \"neutral\"])\n",
    "        self.assertIsInstance(result.confidence_score, float)\n",
    "\n",
    "# Run tests\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7d72a1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Best Practices for Custom Modules\n",
    "\n",
    "### 1. Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c1fdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WellDocumentedModule(dspy.Module):\n",
    "    \"\"\"Example of a well-documented custom module.\n",
    "\n",
    "    This module processes text and provides multiple analyses. It demonstrates:\n",
    "    - Clear docstring explaining purpose\n",
    "    - Type hints for better IDE support\n",
    "    - Detailed parameter documentation\n",
    "    - Example usage\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 analysis_types: List[str] = None,\n",
    "                 confidence_threshold: float = 0.5):\n",
    "        \"\"\"\n",
    "        Initialize the module.\n",
    "\n",
    "        Args:\n",
    "            analysis_types: List of analyses to perform\n",
    "            confidence_threshold: Minimum confidence for outputs\n",
    "\n",
    "        Example:\n",
    "            >>> module = WellDocumentedModule(analysis_types=[\"sentiment\", \"topic\"])\n",
    "            >>> result = module(text=\"Sample text\")\n",
    "            >>> print(result.sentiment)\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4c7fee",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 2. Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda84d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustModule(dspy.Module):\n",
    "    \"\"\"Module with comprehensive error handling.\"\"\"\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        try:\n",
    "            # Main processing\n",
    "            result = self.process(**kwargs)\n",
    "\n",
    "            # Validate output\n",
    "            self.validate_output(result)\n",
    "\n",
    "            return result\n",
    "\n",
    "        except ValueError as e:\n",
    "            # Handle expected errors gracefully\n",
    "            return self.handle_error(e, **kwargs)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Log unexpected errors\n",
    "            self.log_unexpected_error(e)\n",
    "            return self.get_fallback_output(**kwargs)\n",
    "\n",
    "    def handle_error(self, error: ValueError, **kwargs) -> dspy.Prediction:\n",
    "        \"\"\"Handle expected errors with meaningful fallbacks.\"\"\"\n",
    "        return dspy.Prediction(\n",
    "            error=str(error),\n",
    "            confidence=0.0,\n",
    "            status=\"error\"\n",
    "        )\n",
    "\n",
    "    def validate_output(self, output: dspy.Prediction):\n",
    "        \"\"\"Validate output meets requirements.\"\"\"\n",
    "        # Implement validation logic\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed06772c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 3. Configuration Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c828f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurableModule(dspy.Module):\n",
    "    \"\"\"Module with flexible configuration.\"\"\"\n",
    "\n",
    "    def __init__(self, config: Dict[str, Any] = None):\n",
    "        # Load default configuration\n",
    "        self.config = self.load_default_config()\n",
    "\n",
    "        # Override with provided config\n",
    "        if config:\n",
    "            self.config.update(config)\n",
    "\n",
    "        # Validate configuration\n",
    "        self.validate_config()\n",
    "\n",
    "    def load_default_config(self) -> Dict[str, Any]:\n",
    "        \"\"\"Load default module configuration.\"\"\"\n",
    "        return {\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_tokens\": 1000,\n",
    "            \"cache_enabled\": True,\n",
    "            \"timeout\": 30,\n",
    "            \"retry_attempts\": 3\n",
    "        }\n",
    "\n",
    "    def validate_config(self):\n",
    "        \"\"\"Validate module configuration.\"\"\"\n",
    "        required_keys = [\"temperature\"]\n",
    "        for key in required_keys:\n",
    "            if key not in self.config:\n",
    "                raise ValueError(f\"Missing required configuration: {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a523a7",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Custom modules enable:\n",
    "\n",
    "- **Complete control** over module behavior\n",
    "- **Domain optimization** for specific use cases\n",
    "- **Integration capabilities** with existing systems\n",
    "- **Reusability** across projects\n",
    "- **Testing and validation** of custom logic\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Understand the module lifecycle** - Initialize → Validate → Preprocess → Prompt → LLM → Parse → Postprocess\n",
    "2. **Override carefully** - Only override methods you need to customize\n",
    "3. **Add validation** - Ensure inputs and outputs are correct\n",
    "4. **Document thoroughly** - Your modules will be used by others\n",
    "5. **Test comprehensively** - Unit tests catch bugs early\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- [Module Composition](./06-composing-modules.md) - Combine modules effectively\n",
    "- [Practical Examples](../examples/chapter03/) - See custom modules in action\n",
    "- [Exercises](./07-exercises.md) - Build your own custom modules\n",
    "- [Optimizers](../05-optimizers.md) - Automatically improve custom modules\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [DSPy Module Source Code](https://github.com/stanfordnlp/dspy/tree/main/dspy) - Learn from the implementation\n",
    "- [Design Patterns](../07-advanced-topics.md) - Advanced module patterns\n",
    "- [Testing Strategies](../09-appendices/testing.md) - Comprehensive testing approaches"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
