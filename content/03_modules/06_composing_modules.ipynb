{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90e43002",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Composing Modules\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- **Previous Sections**: [Custom Modules](./05-custom-modules.md) - Understanding of module creation\n",
    "- **Chapter 2**: Signatures - Mastery of signature design\n",
    "- **Required Knowledge**: Understanding of software design patterns\n",
    "- **Difficulty Level**: Advanced\n",
    "- **Estimated Reading Time**: 40 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this section, you will:\n",
    "- Master patterns for composing multiple DSPy modules\n",
    "- Learn to build complex workflows from simple components\n",
    "- Understand pipeline, chain, and parallel composition patterns\n",
    "- Discover how to optimize module composition for performance\n",
    "- Build sophisticated multi-module systems\n",
    "\n",
    "## Introduction to Module Composition\n",
    "\n",
    "Module composition is the art of combining multiple DSPy modules to create powerful, specialized systems. Just as functions can be composed to form complex programs, DSPy modules can be composed to create sophisticated LLM applications.\n",
    "\n",
    "### Composition Patterns\n",
    "\n",
    "1. **Sequential/Pipeline Composition** - Pass output of one module to next\n",
    "2. **Parallel Composition** - Run multiple modules simultaneously\n",
    "3. **Conditional Composition** - Choose module based on conditions\n",
    "4. **Hierarchical Composition** - Nested modules for complex logic\n",
    "5. **Feedback Loops** - Modules that iteratively refine outputs\n",
    "\n",
    "## Sequential Composition\n",
    "\n",
    "### Basic Pipeline Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b44f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "# Define individual modules\n",
    "class TextCleaner(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.signature = dspy.Signature(\"raw_text -> cleaned_text\")\n",
    "\n",
    "    def forward(self, raw_text):\n",
    "        # Simple cleaning logic\n",
    "        cleaned = raw_text.strip().lower()\n",
    "        return dspy.Prediction(cleaned_text=cleaned)\n",
    "\n",
    "class TextAnalyzer(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.analyzer = dspy.Predict(\n",
    "            \"cleaned_text -> sentiment, key_topics, entities\"\n",
    "        )\n",
    "\n",
    "    def forward(self, cleaned_text):\n",
    "        return self.analyzer(cleaned_text=cleaned_text)\n",
    "\n",
    "class ReportGenerator(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.generator = dspy.Predict(\n",
    "            \"sentiment, key_topics, entities -> report\"\n",
    "        )\n",
    "\n",
    "    def forward(self, sentiment, key_topics, entities):\n",
    "        return self.generator(\n",
    "            sentiment=sentiment,\n",
    "            key_topics=key_topics,\n",
    "            entities=entities\n",
    "        )\n",
    "\n",
    "# Compose into a pipeline\n",
    "class TextAnalysisPipeline(dspy.Module):\n",
    "    \"\"\"Pipeline that combines text cleaning, analysis, and reporting.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cleaner = TextCleaner()\n",
    "        self.analyzer = TextAnalyzer()\n",
    "        self.generator = ReportGenerator()\n",
    "\n",
    "    def forward(self, raw_text):\n",
    "        # Step 1: Clean text\n",
    "        cleaned_result = self.cleaner(raw_text=raw_text)\n",
    "        cleaned_text = cleaned_result.cleaned_text\n",
    "\n",
    "        # Step 2: Analyze text\n",
    "        analysis_result = self.analyzer(cleaned_text=cleaned_text)\n",
    "\n",
    "        # Step 3: Generate report\n",
    "        report_result = self.generator(\n",
    "            sentiment=analysis_result.sentiment,\n",
    "            key_topics=analysis_result.key_topics,\n",
    "            entities=analysis_result.entities\n",
    "        )\n",
    "\n",
    "        # Combine all results\n",
    "        return dspy.Prediction(\n",
    "            cleaned_text=cleaned_text,\n",
    "            sentiment=analysis_result.sentiment,\n",
    "            key_topics=analysis_result.key_topics,\n",
    "            entities=analysis_result.entities,\n",
    "            report=report_result.report\n",
    "        )\n",
    "\n",
    "# Use the pipeline\n",
    "pipeline = TextAnalysisPipeline()\n",
    "result = pipeline(raw_text=\"  This is an AMAZING product! I love how it works perfectly.  \")\n",
    "\n",
    "print(f\"Report: {result.report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b5dce1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Advanced Pipeline with Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49730fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobustPipeline(dspy.Module):\n",
    "    \"\"\"Pipeline with error handling and fallbacks.\"\"\"\n",
    "\n",
    "    def __init__(self, modules: List[dspy.Module], fallbacks: Dict[int, dspy.Module] = None):\n",
    "        \"\"\"\n",
    "        Initialize pipeline with modules and fallbacks.\n",
    "\n",
    "        Args:\n",
    "            modules: List of modules in execution order\n",
    "            fallbacks: Dictionary mapping module index to fallback module\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.modules = modules\n",
    "        self.fallbacks = fallbacks or {}\n",
    "        self.module_outputs = {}\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        \"\"\"Execute pipeline with error handling.\"\"\"\n",
    "        current_input = kwargs.copy()\n",
    "\n",
    "        for i, module in enumerate(self.modules):\n",
    "            try:\n",
    "                # Execute module\n",
    "                result = module(**current_input)\n",
    "                self.module_outputs[i] = result\n",
    "\n",
    "                # Extract outputs for next module\n",
    "                current_input = self.extract_outputs(result, i)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Module {i} failed: {e}\")\n",
    "\n",
    "                # Try fallback if available\n",
    "                if i in self.fallbacks:\n",
    "                    print(f\"Using fallback for module {i}\")\n",
    "                    fallback_result = self.fallbacks[i](**current_input)\n",
    "                    self.module_outputs[i] = fallback_result\n",
    "                    current_input = self.extract_outputs(fallback_result, i)\n",
    "                else:\n",
    "                    # Skip this module\n",
    "                    print(f\"No fallback for module {i}, skipping\")\n",
    "                    continue\n",
    "\n",
    "        return dspy.Prediction(**self.module_outputs)\n",
    "\n",
    "    def extract_outputs(self, result: dspy.Prediction, module_index: int) -> Dict[str, Any]:\n",
    "        \"\"\"Extract outputs from module result for next module.\"\"\"\n",
    "        # Get module signature\n",
    "        if hasattr(self.modules[module_index], 'signature'):\n",
    "            output_fields = self.modules[module_index].signature.output_fields\n",
    "            return {field.name: getattr(result, field.name, None)\n",
    "                    for field in output_fields}\n",
    "        else:\n",
    "            # Fallback: return all attributes\n",
    "            return {k: v for k, v in result.__dict__.items() if not k.startswith('_')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c55419",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Parallel Composition\n",
    "\n",
    "### Parallel Module Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a0126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelProcessor(dspy.Module):\n",
    "    \"\"\"Execute multiple modules in parallel.\"\"\"\n",
    "\n",
    "    def __init__(self, modules: List[dspy.Module], combine_mode: str = \"merge\"):\n",
    "        \"\"\"\n",
    "        Initialize parallel processor.\n",
    "\n",
    "        Args:\n",
    "            modules: List of modules to execute in parallel\n",
    "            combine_mode: How to combine outputs (\"merge\", \"vote\", \"select\")\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.modules = modules\n",
    "        self.combine_mode = combine_mode\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        \"\"\"Execute all modules in parallel.\"\"\"\n",
    "        from concurrent.futures import ThreadPoolExecutor\n",
    "        import time\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Execute modules in parallel\n",
    "        with ThreadPoolExecutor(max_workers=len(self.modules)) as executor:\n",
    "            futures = []\n",
    "            for i, module in enumerate(self.modules):\n",
    "                future = executor.submit(module, **kwargs)\n",
    "                futures.append((i, future))\n",
    "\n",
    "            # Collect results\n",
    "            results = {}\n",
    "            for i, future in futures:\n",
    "                try:\n",
    "                    result = future.result(timeout=30)\n",
    "                    results[f\"module_{i}\"] = result\n",
    "                except Exception as e:\n",
    "                    print(f\"Module {i} failed: {e}\")\n",
    "                    results[f\"module_{i}\"] = None\n",
    "\n",
    "        execution_time = time.time() - start_time\n",
    "\n",
    "        # Combine results based on mode\n",
    "        combined = self.combine_results(results)\n",
    "\n",
    "        # Add metadata\n",
    "        combined['parallel_metadata'] = {\n",
    "            'execution_time': execution_time,\n",
    "            'modules_run': len(self.modules),\n",
    "            'successful_modules': sum(1 for r in results.values() if r is not None)\n",
    "        }\n",
    "\n",
    "        return dspy.Prediction(**combined)\n",
    "\n",
    "    def combine_results(self, results: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Combine results from multiple modules.\"\"\"\n",
    "        if self.combine_mode == \"merge\":\n",
    "            return self.merge_results(results)\n",
    "        elif self.combine_mode == \"vote\":\n",
    "            return self.vote_results(results)\n",
    "        elif self.combine_mode == \"select\":\n",
    "            return self.select_best_result(results)\n",
    "        else:\n",
    "            return {\"combined_results\": results}\n",
    "\n",
    "    def merge_results(self, results: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Merge all results into one dictionary.\"\"\"\n",
    "        merged = {}\n",
    "        for name, result in results.items():\n",
    "            if result:\n",
    "                for key, value in result.__dict__.items():\n",
    "                    if not key.startswith('_'):\n",
    "                        merged[f\"{name}_{key}\"] = value\n",
    "        return merged\n",
    "\n",
    "    def vote_results(self, results: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Vote on categorical outputs.\"\"\"\n",
    "        votes = {}\n",
    "        for name, result in results.items():\n",
    "            if result and hasattr(result, 'prediction'):\n",
    "                pred = result.prediction\n",
    "                if pred not in votes:\n",
    "                    votes[pred] = []\n",
    "                votes[pred].append(name)\n",
    "\n",
    "        # Find most common prediction\n",
    "        if votes:\n",
    "            winning_pred = max(votes.keys(), key=lambda k: len(votes[k]))\n",
    "            return {\n",
    "                \"prediction\": winning_pred,\n",
    "                \"vote_counts\": {k: len(v) for k, v in votes.items()},\n",
    "                \"confidence\": len(votes[winning_pred]) / len(votes)\n",
    "            }\n",
    "\n",
    "        return {\"prediction\": None, \"vote_counts\": {}, \"confidence\": 0.0}\n",
    "\n",
    "    def select_best_result(self, results: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Select the best result based on confidence scores.\"\"\"\n",
    "        best_result = None\n",
    "        best_confidence = -1\n",
    "\n",
    "        for name, result in results.items():\n",
    "            if result and hasattr(result, 'confidence'):\n",
    "                if result.confidence > best_confidence:\n",
    "                    best_result = result\n",
    "                    best_confidence = result.confidence\n",
    "\n",
    "        if best_result:\n",
    "            best_result[\"selected_from\"] = len([r for r in results.values() if r])\n",
    "            return best_result.__dict__\n",
    "        else:\n",
    "            return {\"error\": \"No valid results found\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f2867",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Specialized Parallel Patterns\n",
    "\n",
    "#### Ensemble Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6041fac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleClassifier(dspy.Module):\n",
    "    \"\"\"Ensemble of classifiers that vote on predictions.\"\"\"\n",
    "\n",
    "    def __init__(self, classifier_configs: List[Dict[str, Any]]):\n",
    "        \"\"\"\n",
    "        Initialize ensemble with multiple classifier configurations.\n",
    "\n",
    "        Args:\n",
    "            classifier_configs: List of configs for individual classifiers\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.classifiers = []\n",
    "        self.weights = []\n",
    "\n",
    "        for config in classifier_configs:\n",
    "            # Create classifier\n",
    "            signature = dspy.Signature(config['signature'])\n",
    "            classifier = dspy.Predict(signature, **config.get('params', {}))\n",
    "            self.classifiers.append(classifier)\n",
    "            self.weights.append(config.get('weight', 1.0))\n",
    "\n",
    "    def forward(self, text: str) -> dspy.Prediction:\n",
    "        \"\"\"Get ensemble prediction.\"\"\"\n",
    "        predictions = []\n",
    "        confidences = []\n",
    "\n",
    "        # Get predictions from all classifiers\n",
    "        for classifier in self.classifiers:\n",
    "            result = classifier(text=text)\n",
    "            predictions.append(result.prediction)\n",
    "            confidences.append(getattr(result, 'confidence', 0.5))\n",
    "\n",
    "        # Weighted voting\n",
    "        weighted_votes = {}\n",
    "        for pred, conf, weight in zip(predictions, confidences, self.weights):\n",
    "            score = conf * weight\n",
    "            if pred not in weighted_votes:\n",
    "                weighted_votes[pred] = 0\n",
    "            weighted_votes[pred] += score\n",
    "\n",
    "        # Find winner\n",
    "        winner = max(weighted_votes.keys(), key=weighted_votes.get)\n",
    "        total_score = sum(weighted_votes.values())\n",
    "        confidence = weighted_votes[winner] / total_score if total_score > 0 else 0.5\n",
    "\n",
    "        return dspy.Prediction(\n",
    "            prediction=winner,\n",
    "            confidence=confidence,\n",
    "            all_predictions=predictions,\n",
    "            vote_breakdown=weighted_votes\n",
    "        )\n",
    "\n",
    "# Use ensemble classifier\n",
    "ensemble = EnsembleClassifier([\n",
    "    {\n",
    "        'signature': 'text -> prediction, confidence',\n",
    "        'params': {'temperature': 0.1},\n",
    "        'weight': 2.0\n",
    "    },\n",
    "    {\n",
    "        'signature': 'text -> prediction, confidence',\n",
    "        'params': {'temperature': 0.3},\n",
    "        'weight': 1.5\n",
    "    },\n",
    "    {\n",
    "        'signature': 'text -> prediction, confidence',\n",
    "        'params': {'temperature': 0.5},\n",
    "        'weight': 1.0\n",
    "    }\n",
    "])\n",
    "\n",
    "result = ensemble(text=\"This product is absolutely fantastic!\")\n",
    "print(f\"Ensemble prediction: {result.prediction} (confidence: {result.confidence:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ba01c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Conditional Composition\n",
    "\n",
    "### Router Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff55991",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router(dspy.Module):\n",
    "    \"\"\"Route inputs to different modules based on conditions.\"\"\"\n",
    "\n",
    "    def __init__(self, routes: Dict[str, dspy.Module], default_route: str = None):\n",
    "        \"\"\"\n",
    "        Initialize router.\n",
    "\n",
    "        Args:\n",
    "            routes: Dictionary mapping route names to modules\n",
    "            default_route: Default route if no condition matches\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.routes = routes\n",
    "        self.default_route = default_route or list(routes.keys())[0]\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        \"\"\"Route to appropriate module based on input conditions.\"\"\"\n",
    "        # Determine route\n",
    "        route_name = self.determine_route(**kwargs)\n",
    "\n",
    "        # Get module\n",
    "        module = self.routes.get(route_name, self.routes[self.default_route])\n",
    "\n",
    "        # Execute module\n",
    "        result = module(**kwargs)\n",
    "\n",
    "        # Add routing information\n",
    "        result.route_used = route_name\n",
    "\n",
    "        return result\n",
    "\n",
    "    def determine_route(self, **kwargs) -> str:\n",
    "        \"\"\"Determine which route to use based on inputs.\"\"\"\n",
    "        text = kwargs.get('text', '').lower()\n",
    "\n",
    "        # Simple routing logic\n",
    "        if any(word in text for word in ['buy', 'purchase', 'price']):\n",
    "            return 'commerce'\n",
    "        elif any(word in text for word in ['help', 'support', 'issue']):\n",
    "            return 'support'\n",
    "        elif any(word in text for word in ['what', 'how', 'why']):\n",
    "            return 'question'\n",
    "        else:\n",
    "            return self.default_route\n",
    "\n",
    "# Create routing system\n",
    "router = Router(\n",
    "    routes={\n",
    "        'commerce': dspy.Predict(\"text -> category, intent\"),\n",
    "        'support': dspy.Predict(\"text -> issue_type, priority\"),\n",
    "        'question': dspy.Predict(\"text -> answer\")\n",
    "    },\n",
    "    default_route='general'\n",
    ")\n",
    "\n",
    "# Test routing\n",
    "result1 = router(text=\"I want to buy your product\")\n",
    "print(f\"Route: {result1.route_used}, Category: {result1.category}\")\n",
    "\n",
    "result2 = router(text=\"How does this work?\")\n",
    "print(f\"Route: {result2.route_used}, Answer: {result2.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c744b398",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Adaptive Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88446a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveModule(dspy.Module):\n",
    "    \"\"\"Module that adapts its behavior based on input complexity.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.simple_module = dspy.Predict(\"query -> answer\")\n",
    "        self.complex_module = dspy.ChainOfThought(\"query -> reasoning, answer\")\n",
    "\n",
    "    def forward(self, query: str) -> dspy.Prediction:\n",
    "        \"\"\"Choose module based on query complexity.\"\"\"\n",
    "        complexity = self.assess_complexity(query)\n",
    "\n",
    "        if complexity < 0.5:\n",
    "            # Use simple module for easy queries\n",
    "            result = self.simple_module(query=query)\n",
    "            result.processing_type = \"simple\"\n",
    "        else:\n",
    "            # Use reasoning module for complex queries\n",
    "            result = self.complex_module(query=query)\n",
    "            result.processing_type = \"complex\"\n",
    "\n",
    "        result.complexity_score = complexity\n",
    "        return result\n",
    "\n",
    "    def assess_complexity(self, query: str) -> float:\n",
    "        \"\"\"Assess query complexity (0-1).\"\"\"\n",
    "        # Simple heuristic\n",
    "        complexity_indicators = [\n",
    "            len(query.split()) / 20,  # Word count\n",
    "            len([c for c in query if c.isupper()]) / len(query),  # Capitals\n",
    "            len(query.count('?') + query.count('!')) / len(query)  # Punctuation\n",
    "        ]\n",
    "\n",
    "        return min(1.0, sum(complexity_indicators) / 3)\n",
    "\n",
    "# Use adaptive module\n",
    "adaptive = AdaptiveModule()\n",
    "\n",
    "simple_result = adaptive(query=\"What time is it?\")\n",
    "print(f\"Type: {simple_result.processing_type}, Answer: {simple_result.answer}\")\n",
    "\n",
    "complex_result = adaptive(query=\"Explain the economic implications of inflation on small businesses\")\n",
    "print(f\"Type: {complex_result.processing_type}, Confidence: {complex_result.complexity_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d2e186",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Hierarchical Composition\n",
    "\n",
    "### Multi-Level Analysis System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b3e31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentAnalyzer(dspy.Module):\n",
    "    \"\"\"Multi-level document analysis system.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Level 1: Initial analysis\n",
    "        self.level1 = dspy.Predict(\"document -> summary, key_points\")\n",
    "\n",
    "        # Level 2: Deep analysis based on Level 1 results\n",
    "        self.level2_classifier = Router(\n",
    "            routes={\n",
    "                'factual': dspy.Predict(\"document, summary -> factual_analysis\"),\n",
    "                'opinion': dspy.Predict(\"document, summary -> opinion_analysis\"),\n",
    "                'mixed': dspy.ChainOfThought(\"document, summary -> detailed_analysis\")\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Level 3: Specialized analysis\n",
    "        self.level3_modules = {\n",
    "            'technical': dspy.Predict(\"document, detailed_analysis -> technical_insights\"),\n",
    "            'legal': dspy.Predict(\"document, detailed_analysis -> legal_considerations\"),\n",
    "            'business': dspy.Predict(\"document, detailed_analysis -> business_impact\")\n",
    "        }\n",
    "\n",
    "    def forward(self, document: str, document_type: str = None) -> dspy.Prediction:\n",
    "        \"\"\"Perform multi-level analysis.\"\"\"\n",
    "        # Level 1: Basic analysis\n",
    "        level1_result = self.level1(document=document)\n",
    "\n",
    "        # Level 2: Determine document type and analyze\n",
    "        doc_type = document_type or self.classify_document(document)\n",
    "        level2_result = self.level2_classifier(\n",
    "            document=document,\n",
    "            summary=level1_result.summary\n",
    "        )\n",
    "\n",
    "        # Level 3: Specialized analysis if available\n",
    "        level3_result = None\n",
    "        if doc_type in self.level3_modules:\n",
    "            level3_result = self.level3_modules[doc_type](\n",
    "                document=document,\n",
    "                detailed_analysis=getattr(level2_result, level2_result.__class__.__name__.lower(), '')\n",
    "            )\n",
    "\n",
    "        # Combine all results\n",
    "        final_result = {\n",
    "            'summary': level1_result.summary,\n",
    "            'key_points': level1_result.key_points,\n",
    "            'document_type': doc_type,\n",
    "            'level2_analysis': level2_result,\n",
    "            'level3_analysis': level3_result\n",
    "        }\n",
    "\n",
    "        return dspy.Prediction(**final_result)\n",
    "\n",
    "    def classify_document(self, document: str) -> str:\n",
    "        \"\"\"Classify document type.\"\"\"\n",
    "        text_lower = document.lower()\n",
    "        indicators = {\n",
    "            'technical': ['code', 'algorithm', 'implementation', 'programming'],\n",
    "            'legal': ['contract', 'agreement', 'liability', 'jurisdiction'],\n",
    "            'business': ['revenue', 'profit', 'market', 'strategy']\n",
    "        }\n",
    "\n",
    "        scores = {doc_type: sum(1 for indicator in indicators if indicator in text_lower)\n",
    "                 for doc_type, indicators in indicators.items()}\n",
    "\n",
    "        return max(scores.keys(), key=scores.get) if scores else 'general'\n",
    "\n",
    "# Use hierarchical analyzer\n",
    "analyzer = DocumentAnalyzer()\n",
    "result = analyzer(\n",
    "    document=\"The code implements a sorting algorithm using Python. It includes error handling and unit tests. \"\n",
    "            \"The implementation is covered by an MIT license.\",\n",
    "    document_type=\"technical\"\n",
    ")\n",
    "\n",
    "print(f\"Summary: {result.summary}\")\n",
    "print(f\"Document Type: {result.document_type}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4904e0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Feedback Loop Composition\n",
    "\n",
    "### Iterative Refinement Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e48bc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterativeRefiner(dspy.Module):\n",
    "    \"\"\"Module that iteratively refines outputs.\"\"\"\n",
    "\n",
    "    def __init__(self, base_module, refinement_module, max_iterations: int = 3):\n",
    "        \"\"\"\n",
    "        Initialize iterative refiner.\n",
    "\n",
    "        Args:\n",
    "            base_module: Module to generate initial output\n",
    "            refinement_module: Module to refine outputs\n",
    "            max_iterations: Maximum number of refinement iterations\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.base_module = base_module\n",
    "        self.refinement_module = refinement_module\n",
    "        self.max_iterations = max_iterations\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        \"\"\"Generate and iteratively refine output.\"\"\"\n",
    "        # Generate initial output\n",
    "        current_output = self.base_module(**kwargs)\n",
    "\n",
    "        # Iteratively refine\n",
    "        for iteration in range(self.max_iterations):\n",
    "            # Check if refinement is needed\n",
    "            if self.is_satisfactory(current_output):\n",
    "                break\n",
    "\n",
    "            # Refine current output\n",
    "            refinement_prompt = self.create_refinement_prompt(\n",
    "                current_output, iteration, **kwargs\n",
    "            )\n",
    "\n",
    "            refined = self.refinement_module(\n",
    "                original=current_output,\n",
    "                refinement_prompt=refinement_prompt,\n",
    "                iteration=iteration + 1\n",
    "            )\n",
    "\n",
    "            # Update output\n",
    "            current_output = self.merge_outputs(current_output, refined)\n",
    "\n",
    "        # Add iteration info\n",
    "        current_output.iterations = iteration + 1\n",
    "\n",
    "        return current_output\n",
    "\n",
    "    def is_satisfactory(self, output: dspy.Prediction) -> bool:\n",
    "        \"\"\"Check if output meets quality criteria.\"\"\"\n",
    "        # Check confidence if available\n",
    "        if hasattr(output, 'confidence'):\n",
    "            return output.confidence >= 0.9\n",
    "        return True\n",
    "\n",
    "    def create_refinement_prompt(self, output: dspy.Prediction, iteration: int, **kwargs) -> str:\n",
    "        \"\"\"Create prompt for refinement.\"\"\"\n",
    "        if iteration == 0:\n",
    "            return \"Please refine this output to be more detailed and comprehensive.\"\n",
    "        elif iteration == 1:\n",
    "            return \"Please improve clarity and add more examples.\"\n",
    "        else:\n",
    "            return \"Please review and polish the output for final delivery.\"\n",
    "\n",
    "    def merge_outputs(self, original: dspy.Prediction, refined: dspy.Prediction) -> dspy.Prediction:\n",
    "        \"\"\"Merge original and refined outputs.\"\"\"\n",
    "        # Use refined output but keep metadata from original\n",
    "        merged = refined.__dict__.copy()\n",
    "        if hasattr(original, 'confidence'):\n",
    "            merged['original_confidence'] = original.confidence\n",
    "        return dspy.Prediction(**merged)\n",
    "\n",
    "# Create iterative refiner\n",
    "base = dspy.Predict(\"prompt -> response\")\n",
    "refiner = dspy.ChainOfThought(\"original, refinement_prompt -> refined_response\")\n",
    "\n",
    "iterative_module = IterativeRefiner(base, refiner)\n",
    "\n",
    "result = iterative_module(\n",
    "    prompt=\"Explain quantum computing\"\n",
    ")\n",
    "print(f\"Final response after {result.iterations} iterations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5c42da",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Performance Optimization\n",
    "\n",
    "### Lazy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ec8808",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyComposer(dspy.Module):\n",
    "    \"\"\"Composer that lazily evaluates modules only when needed.\"\"\"\n",
    "\n",
    "    def __init__(self, modules: List[dspy.Module]):\n",
    "        super().__init__()\n",
    "        self.modules = modules\n",
    "        self._results_cache = {}\n",
    "\n",
    "    def forward(self, required_outputs: List[str], **kwargs):\n",
    "        \"\"\"Execute only modules needed for required outputs.\"\"\"\n",
    "        # Map outputs to modules\n",
    "        output_to_module = self.map_outputs_to_modules(required_outputs)\n",
    "\n",
    "        # Execute required modules\n",
    "        executed = []\n",
    "        for module_name in output_to_module.values():\n",
    "            if module_name not in executed:\n",
    "                module = getattr(self, module_name)\n",
    "                result = module(**kwargs)\n",
    "                self._results_cache[module_name] = result\n",
    "                executed.append(module_name)\n",
    "\n",
    "        # Return only required outputs\n",
    "        return self.extract_required_outputs(required_outputs, **kwargs)\n",
    "\n",
    "    def map_outputs_to_modules(self, required_outputs: List[str]) -> Dict[str, str]:\n",
    "        \"\"\"Map required outputs to module names.\"\"\"\n",
    "        mapping = {\n",
    "            'summary': 'summarizer',\n",
    "            'sentiment': 'sentiment_analyzer',\n",
    "            'topics': 'topic_extractor',\n",
    "            'entities': 'entity_recognizer'\n",
    "        }\n",
    "\n",
    "        return {output: mapping.get(output, 'default_module')\n",
    "                for output in required_outputs\n",
    "                if output in mapping}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679576f1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce662e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchProcessor(dspy.Module):\n",
    "    \"\"\"Process multiple inputs efficiently in batches.\"\"\"\n",
    "\n",
    "    def __init__(self, module: dspy.Module, batch_size: int = 10):\n",
    "        super().__init__()\n",
    "        self.module = module\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, inputs: List[Dict[str, Any]]) -> List[dspy.Prediction]:\n",
    "        \"\"\"Process inputs in batches.\"\"\"\n",
    "        results = []\n",
    "\n",
    "        for i in range(0, len(inputs), self.batch_size):\n",
    "            batch = inputs[i:i + self.batch_size]\n",
    "\n",
    "            # Process batch\n",
    "            batch_results = self.process_batch(batch)\n",
    "            results.extend(batch_results)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def process_batch(self, batch: List[Dict[str, Any]]) -> List[dspy.Prediction]:\n",
    "        \"\"\"Process a single batch.\"\"\"\n",
    "        # This could be optimized to use parallel processing\n",
    "        return [self.module(**item) for item in batch]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb49e78a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Best Practices\n",
    "\n",
    "### 1. Design for Testability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ec8bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestableComposer(dspy.Module):\n",
    "    \"\"\"Composer designed for easy testing.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Use dependency injection\n",
    "        self.module1 = self.create_module1()\n",
    "        self.module2 = self.create_module2()\n",
    "\n",
    "    def create_module1(self):\n",
    "        \"\"\"Factory method for module1 (can be overridden in tests).\"\"\"\n",
    "        return dspy.Predict(\"text -> analysis\")\n",
    "\n",
    "    def create_module2(self):\n",
    "        \"\"\"Factory method for module2 (can be overridden in tests).\"\"\"\n",
    "        return dspy.Predict(\"analysis -> report\")\n",
    "\n",
    "    def forward(self, text: str):\n",
    "        # Intermediate results can be inspected\n",
    "        intermediate = self.module1(text=text)\n",
    "        final = self.module2(analysis=intermediate.analysis)\n",
    "        return final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f953ee",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 2. Handle Failure Gracefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38628d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResilientComposer(dspy.Module):\n",
    "    \"\"\"Composer that handles module failures.\"\"\"\n",
    "\n",
    "    def __init__(self, modules: List[dspy.Module]):\n",
    "        super().__init__()\n",
    "        self.modules = modules\n",
    "        self.fallback_modules = self.create_fallbacks()\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        results = {}\n",
    "        errors = []\n",
    "\n",
    "        for i, module in enumerate(self.modules):\n",
    "            try:\n",
    "                result = module(**{k: v for k, v in kwargs.items()\n",
    "                                 if self.module_needs_input(module, k)})\n",
    "                results[f\"module_{i}\"] = result\n",
    "\n",
    "            except Exception as e:\n",
    "                errors.append(f\"Module {i}: {e}\")\n",
    "                if i in self.fallback_modules:\n",
    "                    try:\n",
    "                        fallback_result = self.fallback_modules[i](**kwargs)\n",
    "                        results[f\"module_{i}_fallback\"] = fallback_result\n",
    "                    except Exception as fallback_error:\n",
    "                        errors.append(f\"Module {i} fallback failed: {fallback_error}\")\n",
    "\n",
    "        return dspy.Prediction(results=results, errors=errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8410a607",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 3. Use Type Hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47547f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Union\n",
    "from dspy import Module, Prediction\n",
    "\n",
    "class TypedComposer(Module):\n",
    "    \"\"\"Composer with full type annotations.\"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.preprocessor: Module = self._create_preprocessor()\n",
    "        self.analyzer: Module = self._create_analyzer()\n",
    "\n",
    "    def _create_preprocessor(self) -> Module:\n",
    "        return dspy.Predict(\"raw_text -> processed_text\")\n",
    "\n",
    "    def _create_analyzer(self) -> Module:\n",
    "        return dspy.Predict(\"processed_text -> analysis, confidence\")\n",
    "\n",
    "    def forward(self, raw_text: str) -> Prediction:\n",
    "        \"\"\"Process text with type safety.\"\"\"\n",
    "        # Preprocess\n",
    "        pre_result: Prediction = self.preprocessor(raw_text=raw_text)\n",
    "\n",
    "        # Analyze\n",
    "        analysis_result: Prediction = self.analyzer(\n",
    "            processed_text=pre_result.processed_text\n",
    "        )\n",
    "\n",
    "        return Prediction(\n",
    "            processed_text=pre_result.processed_text,\n",
    "            analysis=analysis_result.analysis,\n",
    "            confidence=analysis_result.confidence\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bfe118",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Module composition enables:\n",
    "\n",
    "- **Complex workflows** from simple modules\n",
    "- **Flexible architectures** that adapt to needs\n",
    "- **Optimized execution** through parallel and lazy evaluation\n",
    "- **Error resilience** with fallbacks and retries\n",
    "- **Testable and maintainable** code structures\n",
    "\n",
    "## Advanced Composition Patterns\n",
    "\n",
    "### Section-by-Section Writing Pattern\n",
    "\n",
    "The section-by-section writing pattern is essential for generating long-form content like articles, reports, or documentation. This pattern maintains context and coherence while generating content piece by piece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b41fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SectionBySectionWriter(dspy.Module):\n",
    "    \"\"\"Writes long-form content section by section with context management.\"\"\"\n",
    "\n",
    "    def __init__(self, section_generator: dspy.Module, max_context_sections: int = 3):\n",
    "        \"\"\"\n",
    "        Initialize section-by-section writer.\n",
    "\n",
    "        Args:\n",
    "            section_generator: Module that generates individual sections\n",
    "            max_context_sections: Number of previous sections to keep in context\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.section_generator = section_generator\n",
    "        self.max_context_sections = max_context_sections\n",
    "        self.generated_sections = []\n",
    "        self.section_context = {}\n",
    "\n",
    "    def forward(self, outline: List[Dict], topic: str, **kwargs):\n",
    "        \"\"\"\n",
    "        Generate content section by section following an outline.\n",
    "\n",
    "        Args:\n",
    "            outline: Structured outline with section information\n",
    "            topic: Overall topic for context\n",
    "            **kwargs: Additional parameters for content generation\n",
    "\n",
    "        Returns:\n",
    "            Complete generated content with metadata\n",
    "        \"\"\"\n",
    "        self.generated_sections = []\n",
    "\n",
    "        # Generate each section in order\n",
    "        for i, section_info in enumerate(outline):\n",
    "            # Get context from previous sections\n",
    "            context = self._get_section_context(i)\n",
    "\n",
    "            # Generate current section\n",
    "            section_content = self._generate_section(\n",
    "                section_info=section_info,\n",
    "                context=context,\n",
    "                topic=topic,\n",
    "                **kwargs\n",
    "            )\n",
    "\n",
    "            # Store generated section\n",
    "            self.generated_sections.append({\n",
    "                'title': section_info.get('title', f'Section {i+1}'),\n",
    "                'content': section_content,\n",
    "                'word_count': len(section_content.split()),\n",
    "                'section_number': i + 1\n",
    "            })\n",
    "\n",
    "        # Combine all sections\n",
    "        full_content = self._combine_sections()\n",
    "\n",
    "        return dspy.Prediction(\n",
    "            content=full_content,\n",
    "            sections=self.generated_sections,\n",
    "            total_word_count=sum(s['word_count'] for s in self.generated_sections),\n",
    "            total_sections=len(self.generated_sections)\n",
    "        )\n",
    "\n",
    "    def _get_section_context(self, current_section_index: int) -> str:\n",
    "        \"\"\"Get context from recent sections.\"\"\"\n",
    "        context_sections = []\n",
    "\n",
    "        # Include previous sections within context window\n",
    "        start_index = max(0, current_section_index - self.max_context_sections)\n",
    "\n",
    "        for i in range(start_index, current_section_index):\n",
    "            if i < len(self.generated_sections):\n",
    "                section = self.generated_sections[i]\n",
    "                context_sections.append(\n",
    "                    f\"Section {section['section_number']}: {section['title']}\\n\"\n",
    "                    f\"Content: {section['content'][:200]}...\"  # First 200 chars\n",
    "                )\n",
    "\n",
    "        return \"\\n\\n\".join(context_sections) if context_sections else \"\"\n",
    "\n",
    "    def _generate_section(self,\n",
    "                         section_info: Dict,\n",
    "                         context: str,\n",
    "                         topic: str,\n",
    "                         **kwargs) -> str:\n",
    "        \"\"\"Generate a single section with appropriate context.\"\"\"\n",
    "        # Prepare section-specific prompt\n",
    "        section_prompt = self._create_section_prompt(\n",
    "            section_info=section_info,\n",
    "            context=context,\n",
    "            topic=topic\n",
    "        )\n",
    "\n",
    "        # Generate section content\n",
    "        result = self.section_generator(\n",
    "            section_prompt=section_prompt,\n",
    "            word_limit=section_info.get('word_count', 500),\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        return result.content\n",
    "\n",
    "    def _create_section_prompt(self,\n",
    "                              section_info: Dict,\n",
    "                              context: str,\n",
    "                              topic: str) -> str:\n",
    "        \"\"\"Create a comprehensive prompt for section generation.\"\"\"\n",
    "        prompt_parts = [\n",
    "            f\"Topic: {topic}\",\n",
    "            f\"Section Title: {section_info.get('title', 'Untitled Section')}\",\n",
    "            f\"Section Purpose: {section_info.get('purpose', 'Explain this aspect of the topic')}\"\n",
    "        ]\n",
    "\n",
    "        if context:\n",
    "            prompt_parts.append(\n",
    "                f\"\\nPrevious Sections Context:\\n{context}\\n\"\n",
    "                \"Ensure your section flows naturally from the previous content.\"\n",
    "            )\n",
    "\n",
    "        if section_info.get('keywords'):\n",
    "            prompt_parts.append(\n",
    "                f\"\\nKeywords to include: {', '.join(section_info['keywords'])}\"\n",
    "            )\n",
    "\n",
    "        if section_info.get('perspective'):\n",
    "            prompt_parts.append(\n",
    "                f\"\\nWrite from this perspective: {section_info['perspective']}\"\n",
    "            )\n",
    "\n",
    "        return \"\\n\".join(prompt_parts)\n",
    "\n",
    "    def _combine_sections(self) -> str:\n",
    "        \"\"\"Combine all sections into a coherent document.\"\"\"\n",
    "        document_parts = []\n",
    "\n",
    "        for section in self.generated_sections:\n",
    "            # Add section title\n",
    "            document_parts.append(f\"\\n## {section['title']}\\n\")\n",
    "\n",
    "            # Add section content\n",
    "            document_parts.append(section['content'])\n",
    "\n",
    "            # Add transition\n",
    "            if section['section_number'] < len(self.generated_sections):\n",
    "                next_section = self.generated_sections[section['section_number']]\n",
    "                transition = self._create_transition(\n",
    "                    current_section=section,\n",
    "                    next_section=next_section\n",
    "                )\n",
    "                if transition:\n",
    "                    document_parts.append(f\"\\n{transition}\\n\")\n",
    "\n",
    "        return \"\".join(document_parts)\n",
    "\n",
    "    def _create_transition(self, current_section: Dict, next_section: Dict) -> str:\n",
    "        \"\"\"Create a smooth transition between sections.\"\"\"\n",
    "        transition_generator = dspy.Predict(\n",
    "            \"current_section, next_section -> transition_text\"\n",
    "        )\n",
    "\n",
    "        result = transition_generator(\n",
    "            current_section=f\"{current_section['title']}: {current_section['content'][-100:]}\",\n",
    "            next_section=next_section['title']\n",
    "        )\n",
    "\n",
    "        return result.transition_text\n",
    "\n",
    "\n",
    "# Example: Using the Section-by-Section Writer\n",
    "class ArticleSectionGenerator(dspy.Module):\n",
    "    \"\"\"Specialized module for generating article sections.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_section = dspy.ChainOfThought(\n",
    "            \"section_prompt, word_limit -> content\"\n",
    "        )\n",
    "\n",
    "    def forward(self, section_prompt: str, word_limit: int = 500) -> dspy.Prediction:\n",
    "        \"\"\"Generate content for a single section.\"\"\"\n",
    "        result = self.generate_section(\n",
    "            section_prompt=section_prompt,\n",
    "            word_limit=str(word_limit)\n",
    "        )\n",
    "\n",
    "        # Ensure content meets word limit\n",
    "        content = result.content\n",
    "        words = content.split()\n",
    "\n",
    "        if len(words) > word_limit * 1.2:  # Allow 20% overflow\n",
    "            content = \" \".join(words[:word_limit])\n",
    "            content += \"...\"  # Indicate truncation\n",
    "        elif len(words) < word_limit * 0.8:  # Require at least 80%\n",
    "            # Expand content if too short\n",
    "            expander = dspy.Predict(\n",
    "                \"content, target_length -> expanded_content\"\n",
    "            )\n",
    "            expanded = expander(\n",
    "                content=content,\n",
    "                target_length=str(word_limit)\n",
    "            )\n",
    "            content = expanded.expanded_content\n",
    "\n",
    "        return dspy.Prediction(content=content)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "outline = [\n",
    "    {\n",
    "        'title': 'Introduction',\n",
    "        'purpose': 'Introduce the topic and outline the article',\n",
    "        'word_count': 300,\n",
    "        'keywords': ['overview', 'introduction', 'scope']\n",
    "    },\n",
    "    {\n",
    "        'title': 'Background',\n",
    "        'purpose': 'Provide necessary background information',\n",
    "        'word_count': 500,\n",
    "        'keywords': ['history', 'context', 'foundation']\n",
    "    },\n",
    "    {\n",
    "        'title': 'Main Analysis',\n",
    "        'purpose': 'Present detailed analysis and findings',\n",
    "        'word_count': 800,\n",
    "        'perspective': 'analytical'\n",
    "    },\n",
    "    {\n",
    "        'title': 'Conclusion',\n",
    "        'purpose': 'Summarize key points and provide future outlook',\n",
    "        'word_count': 300,\n",
    "        'keywords': ['summary', 'conclusion', 'future']\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create and use the writer\n",
    "section_gen = ArticleSectionGenerator()\n",
    "writer = SectionBySectionWriter(section_gen, max_context_sections=2)\n",
    "\n",
    "result = writer(\n",
    "    outline=outline,\n",
    "    topic=\"The Impact of AI on Education\",\n",
    "    writing_style=\"academic\"\n",
    ")\n",
    "\n",
    "print(f\"Generated {result.total_sections} sections\")\n",
    "print(f\"Total word count: {result.total_word_count}\")\n",
    "print(\"\\nFirst section preview:\")\n",
    "print(result.sections[0]['content'][:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5059b3",
   "metadata": {},
   "source": [
    "This pattern is particularly useful for:\n",
    "- **Long-form article generation** where maintaining coherence is crucial\n",
    "- **Documentation writing** with structured sections\n",
    "- **Report generation** following specific formats\n",
    "- **Educational content** with progressive concept building\n",
    "- **Research synthesis** combining findings from multiple sources\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Start simple** - Compose basic modules first\n",
    "2. **Use patterns** - Follow established composition patterns\n",
    "3. **Handle failures** - Build resilient systems\n",
    "4. **Optimize wisely** - Use parallel and batch processing\n",
    "5. **Document composition** - Make architectural decisions clear\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- [Module Exercises](./07-exercises.md) - Practice composition techniques\n",
    "- [Practical Examples](../examples/chapter03/) - See composition in action\n",
    "- [Advanced Topics](../07-advanced-topics.md) - Explore advanced patterns\n",
    "- [Real-World Applications](../06-real-world-applications/) - Apply to real problems\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [Design Patterns](https://refactoring.guru/) - General design patterns\n",
    "- [DSPy GitHub](https://github.com/stanfordnlp/dspy) - Module implementation details\n",
    "- [Performance Guide](../09-appendices/performance.md) - Optimization techniques"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
