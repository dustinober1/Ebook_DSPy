{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2965d43",
   "metadata": {},
   "source": [
    "# TypedPredictor: Type-Safe Language Model Wrappers\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- **Previous Section**: [Predict Module](./02-predict-module.md) - Understanding of basic prediction\n",
    "- **Chapter 2**: Typed Signatures - Familiarity with typed signature design\n",
    "- **Required Knowledge**: Python type hints, Pydantic models\n",
    "- **Difficulty Level**: Intermediate to Advanced\n",
    "- **Estimated Reading Time**: 40 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this section, you will:\n",
    "- Understand how TypedPredictor differs from regular Predict\n",
    "- Master type-safe prediction with structured outputs\n",
    "- Learn to implement TypedPredictor as an LM wrapper for signatures\n",
    "- Use Pydantic models for complex output validation\n",
    "- Apply TypedPredictor in production scenarios requiring guaranteed output formats\n",
    "\n",
    "## Introduction to TypedPredictor\n",
    "\n",
    "TypedPredictor is a specialized module that wraps language models to implement signatures with strict type guarantees. While `dspy.Predict` handles basic input-output mapping, TypedPredictor adds a critical layer: **runtime type validation and automatic parsing** of model outputs into structured Python objects.\n",
    "\n",
    "### The Core Concept\n",
    "\n",
    "As described in the foundational DSPy paper \"Compiling Declarative Language Model Calls into Self-Improving Pipelines,\" TypedPredictor serves as the bridge between declarative signatures and the underlying language model:\n",
    "\n",
    "```\n",
    "Signature (What) -> TypedPredictor (LM Wrapper) -> LM (How) -> Validated Output\n",
    "```\n",
    "\n",
    "TypedPredictor ensures that:\n",
    "1. The LM receives properly formatted prompts based on your signature\n",
    "2. The LM output is parsed and validated against your type definitions\n",
    "3. Invalid outputs are caught and can trigger retry mechanisms\n",
    "\n",
    "## How TypedPredictor Differs from Predict\n",
    "\n",
    "### Regular Predict: Flexible but Unvalidated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0009a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "# Standard Predict - outputs are strings\n",
    "class BasicQA(dspy.Signature):\n",
    "    \"\"\"Answer questions accurately.\"\"\"\n",
    "    question: str = dspy.InputField()\n",
    "    answer: str = dspy.OutputField()\n",
    "\n",
    "basic_qa = dspy.Predict(BasicQA)\n",
    "result = basic_qa(question=\"What is 2+2?\")\n",
    "\n",
    "# result.answer could be \"4\", \"four\", \"The answer is 4\", etc.\n",
    "# No guarantee of format or structure\n",
    "print(type(result.answer))  # <class 'str'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16ef61b",
   "metadata": {},
   "source": [
    "### TypedPredictor: Strict Type Enforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8080a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "\n",
    "class StructuredAnswer(BaseModel):\n",
    "    \"\"\"Structured answer with metadata.\"\"\"\n",
    "    answer: str = Field(description=\"The direct answer\")\n",
    "    confidence: float = Field(ge=0.0, le=1.0, description=\"Confidence 0-1\")\n",
    "    sources: List[str] = Field(default_factory=list, description=\"Supporting sources\")\n",
    "\n",
    "class TypedQA(dspy.Signature):\n",
    "    \"\"\"Answer questions with structured output.\"\"\"\n",
    "    question: str = dspy.InputField()\n",
    "    response: StructuredAnswer = dspy.OutputField()\n",
    "\n",
    "# TypedPredictor enforces the StructuredAnswer schema\n",
    "typed_qa = dspy.TypedPredictor(TypedQA)\n",
    "result = typed_qa(question=\"What is 2+2?\")\n",
    "\n",
    "# result.response is guaranteed to be a StructuredAnswer object\n",
    "print(type(result.response))  # <class 'StructuredAnswer'>\n",
    "print(result.response.answer)      # \"4\"\n",
    "print(result.response.confidence)  # 0.99\n",
    "print(result.response.sources)     # [\"mathematical axioms\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2823b49",
   "metadata": {},
   "source": [
    "## TypedPredictor as an LM Wrapper\n",
    "\n",
    "The key insight from the DSPy paper is that TypedPredictor acts as an **LM wrapper that implements signatures**. This means:\n",
    "\n",
    "### 1. Automatic Prompt Construction\n",
    "\n",
    "TypedPredictor translates your signature into appropriate prompts for the underlying LM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b6c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataExtractor(dspy.Signature):\n",
    "    \"\"\"Extract structured data from text.\"\"\"\n",
    "    text: str = dspy.InputField(desc=\"Raw text to analyze\")\n",
    "    entities: List[dict] = dspy.OutputField(desc=\"Extracted entities with types\")\n",
    "    relationships: List[str] = dspy.OutputField(desc=\"Relationships between entities\")\n",
    "\n",
    "# TypedPredictor generates prompts that instruct the LM to:\n",
    "# 1. Return data in a parseable format (JSON)\n",
    "# 2. Follow the schema defined by your output types\n",
    "# 3. Include all required fields\n",
    "\n",
    "extractor = dspy.TypedPredictor(DataExtractor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aef618",
   "metadata": {},
   "source": [
    "### 2. Output Parsing and Validation\n",
    "\n",
    "TypedPredictor automatically parses LM outputs into your defined types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62021f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, validator\n",
    "from typing import Literal\n",
    "\n",
    "class SentimentResult(BaseModel):\n",
    "    \"\"\"Validated sentiment analysis result.\"\"\"\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"]\n",
    "    score: float\n",
    "    key_phrases: List[str]\n",
    "\n",
    "    @validator('score')\n",
    "    def validate_score(cls, v):\n",
    "        if not -1.0 <= v <= 1.0:\n",
    "            raise ValueError('Score must be between -1 and 1')\n",
    "        return v\n",
    "\n",
    "class SentimentAnalysis(dspy.Signature):\n",
    "    \"\"\"Analyze text sentiment with validation.\"\"\"\n",
    "    text: str = dspy.InputField()\n",
    "    analysis: SentimentResult = dspy.OutputField()\n",
    "\n",
    "analyzer = dspy.TypedPredictor(SentimentAnalysis)\n",
    "result = analyzer(text=\"I absolutely love this product!\")\n",
    "\n",
    "# The output is validated:\n",
    "# - sentiment must be one of the allowed values\n",
    "# - score must be in valid range\n",
    "# - key_phrases must be a list\n",
    "print(result.analysis.sentiment)    # \"positive\"\n",
    "print(result.analysis.score)        # 0.92\n",
    "print(result.analysis.key_phrases)  # [\"love\", \"absolutely\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbed70a",
   "metadata": {},
   "source": [
    "### 3. Retry on Validation Failure\n",
    "\n",
    "When validation fails, TypedPredictor can automatically retry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6d2107",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrictOutput(BaseModel):\n",
    "    \"\"\"Output with strict validation rules.\"\"\"\n",
    "    category: Literal[\"A\", \"B\", \"C\"]\n",
    "    reasoning: str = Field(min_length=50)  # Must be at least 50 chars\n",
    "    tags: List[str] = Field(min_items=2, max_items=5)\n",
    "\n",
    "class Classifier(dspy.Signature):\n",
    "    \"\"\"Classify with strict output requirements.\"\"\"\n",
    "    input_text: str = dspy.InputField()\n",
    "    classification: StrictOutput = dspy.OutputField()\n",
    "\n",
    "# Configure with retries for validation failures\n",
    "classifier = dspy.TypedPredictor(\n",
    "    Classifier,\n",
    "    max_retries=3,  # Retry up to 3 times on validation failure\n",
    "    explain_errors=True  # Include validation errors in retry prompts\n",
    ")\n",
    "\n",
    "# If the LM returns invalid output (e.g., category=\"D\"),\n",
    "# TypedPredictor will retry with the error message included\n",
    "result = classifier(input_text=\"Sample text for classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bba040",
   "metadata": {},
   "source": [
    "## Practical Applications\n",
    "\n",
    "### 1. API Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea61c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Union, Optional\n",
    "from enum import Enum\n",
    "\n",
    "class StatusCode(int, Enum):\n",
    "    OK = 200\n",
    "    CREATED = 201\n",
    "    BAD_REQUEST = 400\n",
    "    NOT_FOUND = 404\n",
    "    SERVER_ERROR = 500\n",
    "\n",
    "class ErrorResponse(BaseModel):\n",
    "    code: StatusCode\n",
    "    message: str\n",
    "    details: Optional[dict] = None\n",
    "\n",
    "class SuccessResponse(BaseModel):\n",
    "    code: StatusCode\n",
    "    data: dict\n",
    "    metadata: Optional[dict] = None\n",
    "\n",
    "class APIResponseSignature(dspy.Signature):\n",
    "    \"\"\"Generate structured API responses.\"\"\"\n",
    "    request_type: str = dspy.InputField(desc=\"Type of API request\")\n",
    "    request_data: dict = dspy.InputField(desc=\"Request payload\")\n",
    "    response: Union[SuccessResponse, ErrorResponse] = dspy.OutputField()\n",
    "\n",
    "api_generator = dspy.TypedPredictor(APIResponseSignature)\n",
    "\n",
    "# Generate API response\n",
    "result = api_generator(\n",
    "    request_type=\"GET /users/123\",\n",
    "    request_data={\"include\": [\"profile\", \"settings\"]}\n",
    ")\n",
    "\n",
    "# Response is guaranteed to match one of the schemas\n",
    "print(result.response.code)  # StatusCode.OK (200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106b3775",
   "metadata": {},
   "source": [
    "### 2. Document Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fadd7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "from datetime import date\n",
    "\n",
    "class Entity(BaseModel):\n",
    "    name: str\n",
    "    entity_type: Literal[\"PERSON\", \"ORG\", \"LOCATION\", \"DATE\", \"OTHER\"]\n",
    "    confidence: float\n",
    "    start_pos: int\n",
    "    end_pos: int\n",
    "\n",
    "class DocumentSection(BaseModel):\n",
    "    title: str\n",
    "    content: str\n",
    "    importance: Literal[\"high\", \"medium\", \"low\"]\n",
    "\n",
    "class DocumentAnalysis(BaseModel):\n",
    "    title: str\n",
    "    author: Optional[str]\n",
    "    date: Optional[str]\n",
    "    summary: str = Field(min_length=100, max_length=500)\n",
    "    entities: List[Entity]\n",
    "    sections: List[DocumentSection]\n",
    "    keywords: List[str] = Field(min_items=3, max_items=10)\n",
    "\n",
    "class AnalyzeDocument(dspy.Signature):\n",
    "    \"\"\"Perform comprehensive document analysis.\"\"\"\n",
    "    document_text: str = dspy.InputField(desc=\"Full document text\")\n",
    "    analysis: DocumentAnalysis = dspy.OutputField()\n",
    "\n",
    "doc_analyzer = dspy.TypedPredictor(AnalyzeDocument)\n",
    "\n",
    "# Analyze a document\n",
    "result = doc_analyzer(document_text=long_document)\n",
    "\n",
    "# All fields are properly typed and validated\n",
    "for entity in result.analysis.entities:\n",
    "    print(f\"{entity.name} ({entity.entity_type}): {entity.confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7a5db4",
   "metadata": {},
   "source": [
    "### 3. Code Generation with Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a9ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, validator\n",
    "import ast\n",
    "\n",
    "class CodeOutput(BaseModel):\n",
    "    \"\"\"Generated code with validation.\"\"\"\n",
    "    code: str\n",
    "    language: Literal[\"python\", \"javascript\", \"typescript\"]\n",
    "    imports: List[str]\n",
    "    description: str\n",
    "\n",
    "    @validator('code')\n",
    "    def validate_python_syntax(cls, v, values):\n",
    "        if values.get('language') == 'python':\n",
    "            try:\n",
    "                ast.parse(v)\n",
    "            except SyntaxError as e:\n",
    "                raise ValueError(f\"Invalid Python syntax: {e}\")\n",
    "        return v\n",
    "\n",
    "class GenerateCode(dspy.Signature):\n",
    "    \"\"\"Generate validated code.\"\"\"\n",
    "    task_description: str = dspy.InputField()\n",
    "    requirements: List[str] = dspy.InputField()\n",
    "    generated_code: CodeOutput = dspy.OutputField()\n",
    "\n",
    "code_generator = dspy.TypedPredictor(GenerateCode, max_retries=3)\n",
    "\n",
    "result = code_generator(\n",
    "    task_description=\"Create a function to calculate fibonacci numbers\",\n",
    "    requirements=[\"Use recursion\", \"Add memoization\", \"Include type hints\"]\n",
    ")\n",
    "\n",
    "# Code is guaranteed to have valid Python syntax\n",
    "print(result.generated_code.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924813d4",
   "metadata": {},
   "source": [
    "## Advanced TypedPredictor Patterns\n",
    "\n",
    "### Nested Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb7102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Address(BaseModel):\n",
    "    street: str\n",
    "    city: str\n",
    "    country: str\n",
    "    postal_code: str\n",
    "\n",
    "class Company(BaseModel):\n",
    "    name: str\n",
    "    industry: str\n",
    "    headquarters: Address\n",
    "    founded_year: int\n",
    "\n",
    "class Person(BaseModel):\n",
    "    name: str\n",
    "    role: str\n",
    "    company: Optional[Company]\n",
    "    contact: Optional[dict]\n",
    "\n",
    "class EntityExtraction(dspy.Signature):\n",
    "    \"\"\"Extract nested entity structures.\"\"\"\n",
    "    text: str = dspy.InputField()\n",
    "    people: List[Person] = dspy.OutputField()\n",
    "\n",
    "# TypedPredictor handles arbitrarily nested structures\n",
    "extractor = dspy.TypedPredictor(EntityExtraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a34e8e",
   "metadata": {},
   "source": [
    "### Union Types for Flexible Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1430b57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "class TextResponse(BaseModel):\n",
    "    type: Literal[\"text\"] = \"text\"\n",
    "    content: str\n",
    "\n",
    "class TableResponse(BaseModel):\n",
    "    type: Literal[\"table\"] = \"table\"\n",
    "    headers: List[str]\n",
    "    rows: List[List[str]]\n",
    "\n",
    "class ChartData(BaseModel):\n",
    "    type: Literal[\"chart\"] = \"chart\"\n",
    "    chart_type: Literal[\"bar\", \"line\", \"pie\"]\n",
    "    labels: List[str]\n",
    "    values: List[float]\n",
    "\n",
    "class FlexibleResponse(dspy.Signature):\n",
    "    \"\"\"Generate flexible response formats.\"\"\"\n",
    "    query: str = dspy.InputField()\n",
    "    data_type: str = dspy.InputField(desc=\"Preferred output format\")\n",
    "    response: Union[TextResponse, TableResponse, ChartData] = dspy.OutputField()\n",
    "\n",
    "responder = dspy.TypedPredictor(FlexibleResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def4649a",
   "metadata": {},
   "source": [
    "### Custom Validation Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6519cc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, root_validator\n",
    "\n",
    "class ConsistentAnalysis(BaseModel):\n",
    "    \"\"\"Analysis with cross-field validation.\"\"\"\n",
    "    sentiment: Literal[\"positive\", \"negative\", \"neutral\"]\n",
    "    sentiment_score: float\n",
    "    recommendation: str\n",
    "\n",
    "    @root_validator\n",
    "    def validate_consistency(cls, values):\n",
    "        sentiment = values.get('sentiment')\n",
    "        score = values.get('sentiment_score', 0)\n",
    "\n",
    "        # Ensure score matches sentiment\n",
    "        if sentiment == \"positive\" and score < 0:\n",
    "            raise ValueError(\"Positive sentiment requires non-negative score\")\n",
    "        if sentiment == \"negative\" and score > 0:\n",
    "            raise ValueError(\"Negative sentiment requires non-positive score\")\n",
    "\n",
    "        return values\n",
    "\n",
    "class ReviewAnalysis(dspy.Signature):\n",
    "    \"\"\"Analyze review with consistency checks.\"\"\"\n",
    "    review_text: str = dspy.InputField()\n",
    "    analysis: ConsistentAnalysis = dspy.OutputField()\n",
    "\n",
    "analyzer = dspy.TypedPredictor(ReviewAnalysis, max_retries=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5981c6",
   "metadata": {},
   "source": [
    "## TypedPredictor in the Compilation Process\n",
    "\n",
    "TypedPredictor integrates seamlessly with DSPy's compilation (optimization) process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6667273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot, MIPRO\n",
    "\n",
    "class StructuredQA(dspy.Signature):\n",
    "    \"\"\"QA with structured output.\"\"\"\n",
    "    context: str = dspy.InputField()\n",
    "    question: str = dspy.InputField()\n",
    "    answer: StructuredAnswer = dspy.OutputField()\n",
    "\n",
    "# Create TypedPredictor module\n",
    "typed_qa = dspy.TypedPredictor(StructuredQA)\n",
    "\n",
    "# Define metric that works with structured output\n",
    "def qa_metric(example, pred, trace=None):\n",
    "    if not hasattr(pred, 'answer'):\n",
    "        return 0.0\n",
    "\n",
    "    # Access structured fields directly\n",
    "    correctness = example.expected_answer.lower() in pred.answer.answer.lower()\n",
    "    confidence_bonus = pred.answer.confidence if correctness else 0\n",
    "\n",
    "    return 0.7 * float(correctness) + 0.3 * confidence_bonus\n",
    "\n",
    "# Compile with BootstrapFewShot\n",
    "optimizer = BootstrapFewShot(metric=qa_metric, max_bootstrapped_demos=4)\n",
    "compiled_qa = optimizer.compile(typed_qa, trainset=training_examples)\n",
    "\n",
    "# Or use MIPRO for more advanced optimization\n",
    "mipro = MIPRO(metric=qa_metric, auto=\"medium\")\n",
    "optimized_qa = mipro.compile(typed_qa, trainset=training_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae688500",
   "metadata": {},
   "source": [
    "## Advanced TypedPredictor Implementation Patterns\n",
    "\n",
    "### 1. Schema Composition and Inheritance\n",
    "\n",
    "Create complex, reusable schemas with inheritance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23976e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Generic, TypeVar\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "class BaseResponse(BaseModel, Generic[T]):\n",
    "    \"\"\"Base response schema with common fields.\"\"\"\n",
    "    success: bool = True\n",
    "    message: str = \"Operation completed\"\n",
    "    data: T\n",
    "\n",
    "    class Config:\n",
    "        # Enable JSON schema for complex types\n",
    "        schema_extra = {\n",
    "            \"example\": {\n",
    "                \"success\": True,\n",
    "                \"message\": \"Data retrieved successfully\",\n",
    "                \"data\": {}\n",
    "            }\n",
    "        }\n",
    "\n",
    "class ValidationMetadata(BaseModel):\n",
    "    \"\"\"Metadata for validation results.\"\"\"\n",
    "    validation_version: str = \"1.0\"\n",
    "    schema_hash: str\n",
    "    validation_timestamp: str\n",
    "\n",
    "    def compute_hash(self, schema_dict: dict) -> str:\n",
    "        \"\"\"Compute hash for schema validation.\"\"\"\n",
    "        import hashlib\n",
    "        import json\n",
    "        schema_str = json.dumps(schema_dict, sort_keys=True)\n",
    "        return hashlib.sha256(schema_str.encode()).hexdigest()[:16]\n",
    "\n",
    "# Compose complex schemas\n",
    "class AnalysisResult(BaseModel):\n",
    "    \"\"\"Complex analysis result with nested structures.\"\"\"\n",
    "    summary: str = Field(..., min_length=10, description=\"Executive summary\")\n",
    "    details: dict = Field(default_factory=dict, description=\"Detailed findings\")\n",
    "    confidence: float = Field(..., ge=0.0, le=1.0, description=\"Confidence score\")\n",
    "    sources: List[str] = Field(default_factory=list, description=\"Reference sources\")\n",
    "    metadata: ValidationMetadata = Field(..., description=\"Validation metadata\")\n",
    "\n",
    "# Use in TypedPredictor\n",
    "class AnalyzeDataSignature(dspy.Signature):\n",
    "    \"\"\"Analyze data with comprehensive output validation.\"\"\"\n",
    "    input_data: dict = dspy.InputField(desc=\"Data to analyze\")\n",
    "    context: str = dspy.InputField(desc=\"Analysis context and requirements\")\n",
    "    analysis: BaseResponse[AnalysisResult] = dspy.OutputField()\n",
    "\n",
    "analyzer = dspy.TypedPredictor(AnalyzeDataSignature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a3d764",
   "metadata": {},
   "source": [
    "### 2. Dynamic Schema Generation\n",
    "\n",
    "Generate schemas based on runtime requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import create_model, Field\n",
    "from typing import Dict, Any\n",
    "\n",
    "class DynamicSchemaPredictor:\n",
    "    \"\"\"TypedPredictor with dynamic schema generation.\"\"\"\n",
    "\n",
    "    def __init__(self, base_fields: Dict[str, Any]):\n",
    "        self.base_fields = base_fields\n",
    "        self.model_cache = {}\n",
    "\n",
    "    def create_dynamic_model(self, name: str, additional_fields: Dict[str, Any] = None):\n",
    "        \"\"\"Create a Pydantic model dynamically.\"\"\"\n",
    "        # Combine base and additional fields\n",
    "        all_fields = {**self.base_fields, **(additional_fields or {})}\n",
    "\n",
    "        # Create model name\n",
    "        model_name = f\"Dynamic{name.replace(' ', '')}Model\"\n",
    "\n",
    "        # Check cache first\n",
    "        if model_name in self.model_cache:\n",
    "            return self.model_cache[model_name]\n",
    "\n",
    "        # Create dynamic model\n",
    "        DynamicModel = create_model(\n",
    "            model_name,\n",
    "            **all_fields\n",
    "        )\n",
    "\n",
    "        # Cache the model\n",
    "        self.model_cache[model_name] = DynamicModel\n",
    "        return DynamicModel\n",
    "\n",
    "    def create_typed_predictor(self, schema_name: str, signature_fields: Dict[str, Any]):\n",
    "        \"\"\"Create TypedPredictor with dynamic schema.\"\"\"\n",
    "        # Generate dynamic model\n",
    "        OutputModel = self.create_dynamic_model(schema_name)\n",
    "\n",
    "        # Create signature class\n",
    "        signature_dict = {\n",
    "            '__annotations__': {}\n",
    "        }\n",
    "\n",
    "        for field_name, field_config in signature_fields.items():\n",
    "            if field_config.get('input'):\n",
    "                signature_dict['__annotations__'][field_name] = str\n",
    "                signature_dict[field_name] = dspy.InputField(\n",
    "                    desc=field_config.get('description', '')\n",
    "                )\n",
    "            else:\n",
    "                signature_dict['__annotations__'][field_name] = OutputModel\n",
    "                signature_dict[field_name] = dspy.OutputField(\n",
    "                    desc=field_config.get('description', '')\n",
    "                )\n",
    "\n",
    "        # Create signature dynamically\n",
    "        DynamicSignature = type(f\"{schema_name}Signature\", (dspy.Signature,), signature_dict)\n",
    "\n",
    "        # Return TypedPredictor\n",
    "        return dspy.TypedPredictor(DynamicSignature)\n",
    "\n",
    "# Usage example\n",
    "base_fields = {\n",
    "    'id': int,\n",
    "    'timestamp': str,\n",
    "    'status': str,\n",
    "    'result': Dict[str, Any]\n",
    "}\n",
    "\n",
    "dynamic_predictor = DynamicSchemaPredictor(base_fields)\n",
    "\n",
    "# Create a data processor with dynamic schema\n",
    "processor = dynamic_predictor.create_typed_predictor(\n",
    "    schema_name=\"DataProcessor\",\n",
    "    signature_fields={\n",
    "        'raw_data': {'input': True, 'description': 'Raw input data'},\n",
    "        'processed': {'input': False, 'description': 'Processed output with validation'}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d18c08",
   "metadata": {},
   "source": [
    "### 3. Streaming TypedPredictor\n",
    "\n",
    "Handle real-time data validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4365e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import AsyncGenerator\n",
    "import asyncio\n",
    "\n",
    "class StreamingTypedPredictor:\n",
    "    \"\"\"TypedPredictor for streaming data validation.\"\"\"\n",
    "\n",
    "    def __init__(self, signature, batch_size: int = 10, timeout: float = 5.0):\n",
    "        self.predictor = dspy.TypedPredictor(signature)\n",
    "        self.batch_size = batch_size\n",
    "        self.timeout = timeout\n",
    "        self.buffer = []\n",
    "\n",
    "    async def process_stream(self, data_stream: AsyncGenerator[dict, None]) -> AsyncGenerator[dict, None]:\n",
    "        \"\"\"Process streaming data with validation.\"\"\"\n",
    "        async for data_item in data_stream:\n",
    "            self.buffer.append(data_item)\n",
    "\n",
    "            # Process batch when full or timeout\n",
    "            if len(self.buffer) >= self.batch_size:\n",
    "                async for validated_item in self._process_batch():\n",
    "                    yield validated_item\n",
    "                self.buffer.clear()\n",
    "\n",
    "        # Process remaining items\n",
    "        if self.buffer:\n",
    "            async for validated_item in self._process_batch():\n",
    "                yield validated_item\n",
    "\n",
    "    async def _process_batch(self) -> AsyncGenerator[dict, None]:\n",
    "        \"\"\"Process a batch of items.\"\"\"\n",
    "        # Create batch processing prompt\n",
    "        batch_prompt = self._create_batch_prompt(self.buffer)\n",
    "\n",
    "        # Validate entire batch\n",
    "        try:\n",
    "            result = await asyncio.wait_for(\n",
    "                self._predict_async(batch_prompt),\n",
    "                timeout=self.timeout\n",
    "            )\n",
    "\n",
    "            # Extract validated items\n",
    "            if hasattr(result, 'validated_data'):\n",
    "                for item in result.validated_data:\n",
    "                    yield item\n",
    "\n",
    "        except asyncio.TimeoutError:\n",
    "            # Fallback to individual processing\n",
    "            for item in self.buffer:\n",
    "                yield item  # Return original if validation fails\n",
    "\n",
    "    def _create_batch_prompt(self, items: List[dict]) -> str:\n",
    "        \"\"\"Create prompt for batch processing.\"\"\"\n",
    "        return f\"\"\"\n",
    "        Validate and process the following batch of data items:\n",
    "        {json.dumps(items, indent=2)}\n",
    "\n",
    "        Ensure all items conform to the required schema.\n",
    "        Return validated items in order.\n",
    "        \"\"\"\n",
    "\n",
    "    async def _predict_async(self, prompt: str):\n",
    "        \"\"\"Async prediction wrapper.\"\"\"\n",
    "        # In a real implementation, this would use an async-compatible LM\n",
    "        loop = asyncio.get_event_loop()\n",
    "        return await loop.run_in_executor(None, self.predictor, input_text=prompt)\n",
    "\n",
    "# Example usage\n",
    "class StreamingDataSignature(dspy.Signature):\n",
    "    \"\"\"Process streaming data with validation.\"\"\"\n",
    "    input_data: List[dict] = dspy.InputField(desc=\"Batch of data items\")\n",
    "    validated_data: List[dict] = dspy.OutputField(desc=\"Validated data items\")\n",
    "    validation_errors: List[str] = dspy.OutputField(desc=\"Any validation errors found\")\n",
    "\n",
    "stream_validator = StreamingTypedPredictor(StreamingDataSignature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0092b009",
   "metadata": {},
   "source": [
    "### 4. Conditional TypedPredictor\n",
    "\n",
    "Different validation rules based on conditions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b5ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import Union, Optional\n",
    "\n",
    "class DataClass(str, Enum):\n",
    "    TEXT = \"text\"\n",
    "    NUMERIC = \"numeric\"\n",
    "    STRUCTURED = \"structured\"\n",
    "    MIXED = \"mixed\"\n",
    "\n",
    "class ConditionalTypedPredictor:\n",
    "    \"\"\"TypedPredictor with conditional validation logic.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.classifier = dspy.Predict(\"text -> data_class\")\n",
    "        self.predictors = {\n",
    "            DataClass.TEXT: dspy.TypedPredictor(TextValidationSignature),\n",
    "            DataClass.NUMERIC: dspy.TypedPredictor(NumericValidationSignature),\n",
    "            DataClass.STRUCTURED: dspy.TypedPredictor(StructuredValidationSignature),\n",
    "            DataClass.MIXED: dspy.TypedPredictor(MixedValidationSignature)\n",
    "        }\n",
    "\n",
    "    def forward(self, input_data: str) -> dspy.Prediction:\n",
    "        \"\"\"Route to appropriate validator based on data class.\"\"\"\n",
    "        # First classify the input\n",
    "        classification = self.classifier(text=input_data)\n",
    "        data_class = DataClass(classification.data_class.lower())\n",
    "\n",
    "        # Route to appropriate validator\n",
    "        predictor = self.predictors[data_class]\n",
    "        result = predictor(input_data=input_data)\n",
    "\n",
    "        # Add metadata\n",
    "        result.data_class = data_class\n",
    "        result.validator_type = type(predictor).__name__\n",
    "\n",
    "        return result\n",
    "\n",
    "# Define different validation schemas\n",
    "class TextValidationResult(BaseModel):\n",
    "    \"\"\"Validation result for text data.\"\"\"\n",
    "    is_valid: bool\n",
    "    language: str\n",
    "    sentiment: str\n",
    "    entities: List[str]\n",
    "    quality_score: float\n",
    "\n",
    "class NumericValidationResult(BaseModel):\n",
    "    \"\"\"Validation result for numeric data.\"\"\"\n",
    "    is_valid: bool\n",
    "    data_type: str  # int, float, decimal\n",
    "    range_check: bool\n",
    "    outliers: List[float]\n",
    "    statistics: dict\n",
    "\n",
    "class StructuredValidationResult(BaseModel):\n",
    "    \"\"\"Validation result for structured data.\"\"\"\n",
    "    is_valid: bool\n",
    "    schema_version: str\n",
    "    missing_fields: List[str]\n",
    "    extra_fields: List[str]\n",
    "    field_types: dict\n",
    "    nested_objects: int\n",
    "\n",
    "# Signature definitions\n",
    "class TextValidationSignature(dspy.Signature):\n",
    "    \"\"\"Validate text data.\"\"\"\n",
    "    input_data: str = dspy.InputField()\n",
    "    validation: TextValidationResult = dspy.OutputField()\n",
    "\n",
    "class NumericValidationSignature(dspy.Signature):\n",
    "    \"\"\"Validate numeric data.\"\"\"\n",
    "    input_data: str = dspy.InputField()\n",
    "    validation: NumericValidationResult = dspy.OutputField()\n",
    "\n",
    "class StructuredValidationSignature(dspy.Signature):\n",
    "    \"\"\"Validate structured data.\"\"\"\n",
    "    input_data: str = dspy.InputField()\n",
    "    validation: StructuredValidationResult = dspy.OutputField()\n",
    "\n",
    "class MixedValidationSignature(dspy.Signature):\n",
    "    \"\"\"Validate mixed-type data.\"\"\"\n",
    "    input_data: str = dspy.InputField()\n",
    "    validation: dict = dspy.OutputField(desc=\"Mixed validation results\")\n",
    "\n",
    "# Usage\n",
    "conditional_validator = ConditionalTypedPredictor()\n",
    "result = conditional_validator(input_data=\"Sample text data...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995e5673",
   "metadata": {},
   "source": [
    "### 5. TypedPredictor with Versioning\n",
    "\n",
    "Maintain backward compatibility with schema evolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7a5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Dict, List, Optional\n",
    "import json\n",
    "\n",
    "class VersionedTypedPredictor:\n",
    "    \"\"\"TypedPredictor with schema versioning support.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.versions = {}\n",
    "        self.migration_handlers = {}\n",
    "        self.current_version = \"1.0.0\"\n",
    "\n",
    "    def register_version(self, version: str, model_class: type, migration_handler=None):\n",
    "        \"\"\"Register a schema version.\"\"\"\n",
    "        self.versions[version] = model_class\n",
    "        if migration_handler:\n",
    "            self.migration_handlers[version] = migration_handler\n",
    "\n",
    "    def migrate_data(self, data: dict, from_version: str, to_version: str) -> dict:\n",
    "        \"\"\"Migrate data between schema versions.\"\"\"\n",
    "        current_data = data\n",
    "\n",
    "        # Apply migrations in order\n",
    "        versions = sorted(self.versions.keys())\n",
    "        start_idx = versions.index(from_version)\n",
    "        end_idx = versions.index(to_version)\n",
    "\n",
    "        for i in range(start_idx, end_idx):\n",
    "            current_version = versions[i]\n",
    "            next_version = versions[i + 1]\n",
    "\n",
    "            if next_version in self.migration_handlers:\n",
    "                current_data = self.migration_handlers[next_version](current_data)\n",
    "\n",
    "        return current_data\n",
    "\n",
    "    def create_predictor(self, version: str = None):\n",
    "        \"\"\"Create TypedPredictor for specific version.\"\"\"\n",
    "        target_version = version or self.current_version\n",
    "\n",
    "        if target_version not in self.versions:\n",
    "            raise ValueError(f\"Version {target_version} not registered\")\n",
    "\n",
    "        model_class = self.versions[target_version]\n",
    "\n",
    "        # Create dynamic signature\n",
    "        class VersionedSignature(dspy.Signature):\n",
    "            \"\"\"Versioned data processing signature.\"\"\"\n",
    "            input_data: dict = dspy.InputField(desc=\"Input data\")\n",
    "            version: str = dspy.InputField(desc=\"Target schema version\")\n",
    "            output: model_class = dspy.OutputField(desc=\"Validated output\")\n",
    "\n",
    "        return dspy.TypedPredictor(VersionedSignature)\n",
    "\n",
    "    def process_with_versioning(self, input_data: dict, input_version: str,\n",
    "                              target_version: str = None) -> dspy.Prediction:\n",
    "        \"\"\"Process data with automatic version migration.\"\"\"\n",
    "        target_version = target_version or self.current_version\n",
    "\n",
    "        # Migrate data if needed\n",
    "        if input_version != target_version:\n",
    "            migrated_data = self.migrate_data(input_data, input_version, target_version)\n",
    "        else:\n",
    "            migrated_data = input_data\n",
    "\n",
    "        # Process with target version schema\n",
    "        predictor = self.create_predictor(target_version)\n",
    "        return predictor(input_data=migrated_data, version=target_version)\n",
    "\n",
    "# Example schema versions\n",
    "class UserProfileV1(BaseModel):\n",
    "    \"\"\"User profile schema v1.0.\"\"\"\n",
    "    name: str\n",
    "    email: str\n",
    "    age: Optional[int] = None\n",
    "\n",
    "class UserProfileV2(BaseModel):\n",
    "    \"\"\"User profile schema v2.0 - added fields.\"\"\"\n",
    "    name: str = Field(..., min_length=2)\n",
    "    email: str = Field(..., regex=r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$')\n",
    "    age: Optional[int] = Field(None, ge=0, le=150)\n",
    "    phone: Optional[str] = None\n",
    "    preferences: dict = Field(default_factory=dict)\n",
    "\n",
    "# Migration handler from v1 to v2\n",
    "def migrate_v1_to_v2(data: dict) -> dict:\n",
    "    \"\"\"Migrate user profile from v1 to v2.\"\"\"\n",
    "    migrated = data.copy()\n",
    "    migrated['preferences'] = {}  # Add new field\n",
    "    migrated['phone'] = None  # Add new field\n",
    "    return migrated\n",
    "\n",
    "# Register versions\n",
    "versioned_predictor = VersionedTypedPredictor()\n",
    "versioned_predictor.register_version(\"1.0.0\", UserProfileV1)\n",
    "versioned_predictor.register_version(\"2.0.0\", UserProfileV2, migrate_v1_to_v2)\n",
    "\n",
    "# Usage\n",
    "old_data = {\"name\": \"John Doe\", \"email\": \"john@example.com\"}\n",
    "result = versioned_predictor.process_with_versioning(\n",
    "    input_data=old_data,\n",
    "    input_version=\"1.0.0\",\n",
    "    target_version=\"2.0.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9702fc",
   "metadata": {},
   "source": [
    "### 6. TypedPredictor with Performance Optimization\n",
    "\n",
    "Optimize for high-throughput scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df3305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from functools import lru_cache\n",
    "import multiprocessing\n",
    "from typing import List, Tuple\n",
    "\n",
    "class OptimizedTypedPredictor:\n",
    "    \"\"\"High-performance TypedPredictor with optimization strategies.\"\"\"\n",
    "\n",
    "    def __init__(self, signature, batch_size: int = 32, max_workers: int = None):\n",
    "        self.predictor = dspy.TypedPredictor(signature)\n",
    "        self.batch_size = batch_size\n",
    "        self.max_workers = max_workers or multiprocessing.cpu_count()\n",
    "        self.executor = ThreadPoolExecutor(max_workers=self.max_workers)\n",
    "\n",
    "        # Validation cache\n",
    "        self._validation_cache = {}\n",
    "        self._cache_size_limit = 10000\n",
    "\n",
    "    @lru_cache(maxsize=1000)\n",
    "    def _cached_schema_validation(self, data_hash: str, schema_hash: str) -> bool:\n",
    "        \"\"\"Cached schema validation.\"\"\"\n",
    "        # In practice, this would validate against cached schema\n",
    "        return True\n",
    "\n",
    "    def process_batch_parallel(self, batch_data: List[dict]) -> List[dspy.Prediction]:\n",
    "        \"\"\"Process a batch of items in parallel.\"\"\"\n",
    "        # Split batch into chunks\n",
    "        chunks = [batch_data[i:i + self.batch_size]\n",
    "                 for i in range(0, len(batch_data), self.batch_size)]\n",
    "\n",
    "        # Process chunks in parallel\n",
    "        futures = []\n",
    "        for chunk in chunks:\n",
    "            future = self.executor.submit(self._process_chunk, chunk)\n",
    "            futures.append(future)\n",
    "\n",
    "        # Collect results\n",
    "        results = []\n",
    "        for future in as_completed(futures):\n",
    "            chunk_results = future.result()\n",
    "            results.extend(chunk_results)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _process_chunk(self, chunk: List[dict]) -> List[dspy.Prediction]:\n",
    "        \"\"\"Process a chunk of items.\"\"\"\n",
    "        results = []\n",
    "\n",
    "        # Create batch prompt for chunk\n",
    "        batch_prompt = self._create_optimized_batch_prompt(chunk)\n",
    "\n",
    "        try:\n",
    "            # Process entire chunk\n",
    "            chunk_result = self.predictor(batch_input=batch_prompt)\n",
    "\n",
    "            # Parse individual results\n",
    "            if hasattr(chunk_result, 'outputs'):\n",
    "                results = chunk_result.outputs\n",
    "            else:\n",
    "                # Fallback to individual processing\n",
    "                for item in chunk:\n",
    "                    result = self.predictor(**item)\n",
    "                    results.append(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle errors gracefully\n",
    "            for item in chunk:\n",
    "                error_result = dspy.Prediction(\n",
    "                    error=str(e),\n",
    "                    original_input=item\n",
    "                )\n",
    "                results.append(error_result)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _create_optimized_batch_prompt(self, chunk: List[dict]) -> str:\n",
    "        \"\"\"Create optimized batch processing prompt.\"\"\"\n",
    "        # Pre-validate cached items\n",
    "        uncached_items = []\n",
    "        for item in chunk:\n",
    "            item_hash = self._compute_item_hash(item)\n",
    "            if item_hash not in self._validation_cache:\n",
    "                uncached_items.append(item)\n",
    "\n",
    "        # Create efficient prompt\n",
    "        prompt = f\"\"\"\n",
    "        Process this batch of {len(chunk)} items efficiently.\n",
    "\n",
    "        Items to process:\n",
    "        {json.dumps(uncached_items, indent=2)}\n",
    "\n",
    "        Apply schema validation and return structured results.\n",
    "        Use batch processing for efficiency.\n",
    "        \"\"\"\n",
    "\n",
    "        return prompt\n",
    "\n",
    "    def _compute_item_hash(self, item: dict) -> str:\n",
    "        \"\"\"Compute hash for item caching.\"\"\"\n",
    "        import hashlib\n",
    "        import json\n",
    "        item_str = json.dumps(item, sort_keys=True)\n",
    "        return hashlib.md5(item_str.encode()).hexdigest()[:16]\n",
    "\n",
    "    def optimize_schema(self, sample_data: List[dict]) -> dict:\n",
    "        \"\"\"Optimize schema based on sample data.\"\"\"\n",
    "        # Analyze common patterns\n",
    "        field_frequencies = {}\n",
    "        field_types = {}\n",
    "\n",
    "        for item in sample_data:\n",
    "            for field, value in item.items():\n",
    "                field_frequencies[field] = field_frequencies.get(field, 0) + 1\n",
    "                field_types[field] = type(value).__name__\n",
    "\n",
    "        # Generate optimized schema\n",
    "        schema = {\n",
    "            \"required_fields\": [f for f, freq in field_frequencies.items()\n",
    "                              if freq > len(sample_data) * 0.8],\n",
    "            \"optional_fields\": [f for f, freq in field_frequencies.items()\n",
    "                              if freq <= len(sample_data) * 0.8],\n",
    "            \"field_types\": field_types,\n",
    "            \"optimizations\": {\n",
    "                \"use_optional\": len(field_frequencies) > 10,\n",
    "                \"batch_size\": self.batch_size,\n",
    "                \"cache_enabled\": True\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return schema\n",
    "\n",
    "    def get_performance_metrics(self) -> dict:\n",
    "        \"\"\"Get performance metrics.\"\"\"\n",
    "        return {\n",
    "            \"batch_size\": self.batch_size,\n",
    "            \"max_workers\": self.max_workers,\n",
    "            \"cache_size\": len(self._validation_cache),\n",
    "            \"cache_hit_rate\": getattr(self, '_cache_hits', 0) / max(1, getattr(self, '_cache_requests', 1))\n",
    "        }\n",
    "\n",
    "# Usage example for high-throughput scenario\n",
    "signature = dspy.Signature(\"data -> validated_output\")\n",
    "optimized_predictor = OptimizedTypedPredictor(signature, batch_size=64)\n",
    "\n",
    "# Process large dataset\n",
    "large_dataset = [{\"data\": f\"item_{i}\"} for i in range(1000)]\n",
    "results = optimized_predictor.process_batch_parallel(large_dataset)\n",
    "\n",
    "# Get performance metrics\n",
    "metrics = optimized_predictor.get_performance_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73988b2d",
   "metadata": {},
   "source": [
    "## Error Handling and Debugging\n",
    "\n",
    "### Handling Validation Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540938b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import ValidationError\n",
    "\n",
    "class RobustTypedPredictor:\n",
    "    \"\"\"Wrapper with robust error handling.\"\"\"\n",
    "\n",
    "    def __init__(self, signature, fallback_fn=None):\n",
    "        self.predictor = dspy.TypedPredictor(signature, max_retries=3)\n",
    "        self.fallback_fn = fallback_fn\n",
    "\n",
    "    def __call__(self, **kwargs):\n",
    "        try:\n",
    "            return self.predictor(**kwargs)\n",
    "        except ValidationError as e:\n",
    "            print(f\"Validation failed after retries: {e}\")\n",
    "            if self.fallback_fn:\n",
    "                return self.fallback_fn(**kwargs)\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            print(f\"Prediction error: {e}\")\n",
    "            raise\n",
    "\n",
    "# Usage with fallback\n",
    "def simple_fallback(**kwargs):\n",
    "    \"\"\"Fallback to unstructured response.\"\"\"\n",
    "    simple = dspy.Predict(\"question -> answer\")\n",
    "    return simple(**kwargs)\n",
    "\n",
    "robust_qa = RobustTypedPredictor(TypedQA, fallback_fn=simple_fallback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6112073d",
   "metadata": {},
   "source": [
    "### Debugging Type Mismatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20d6556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "# Enable detailed tracing\n",
    "dspy.settings.configure(trace=\"all\")\n",
    "\n",
    "class DebugSignature(dspy.Signature):\n",
    "    \"\"\"Signature for debugging.\"\"\"\n",
    "    input_text: str = dspy.InputField()\n",
    "    output: ComplexStructure = dspy.OutputField()\n",
    "\n",
    "predictor = dspy.TypedPredictor(DebugSignature)\n",
    "\n",
    "# Run prediction\n",
    "result = predictor(input_text=\"Test input\")\n",
    "\n",
    "# Inspect the raw LM output before parsing\n",
    "print(\"Raw LM response:\", predictor.lm.last_request_.response)\n",
    "\n",
    "# Check what was sent to the LM\n",
    "print(\"Prompt sent:\", predictor.lm.last_request_.prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61290100",
   "metadata": {},
   "source": [
    "## Best Practices\n",
    "\n",
    "### 1. Start Simple, Add Complexity Gradually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b202854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with simple types\n",
    "class SimpleOutput(BaseModel):\n",
    "    result: str\n",
    "    confidence: float\n",
    "\n",
    "# Add complexity as needed\n",
    "class EnhancedOutput(SimpleOutput):\n",
    "    sources: List[str] = []\n",
    "    metadata: Optional[dict] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9eae40",
   "metadata": {},
   "source": [
    "### 2. Use Descriptive Field Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d58e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WellDocumentedOutput(BaseModel):\n",
    "    \"\"\"Output with clear descriptions for the LM.\"\"\"\n",
    "    category: str = Field(\n",
    "        description=\"One of: technology, business, science, other\"\n",
    "    )\n",
    "    summary: str = Field(\n",
    "        description=\"A 2-3 sentence summary of the main points\"\n",
    "    )\n",
    "    key_facts: List[str] = Field(\n",
    "        description=\"List of 3-5 key factual statements from the text\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fe24a3",
   "metadata": {},
   "source": [
    "### 3. Set Appropriate Retry Limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea34564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simple outputs - fewer retries\n",
    "simple_predictor = dspy.TypedPredictor(SimpleSignature, max_retries=2)\n",
    "\n",
    "# For complex outputs - more retries\n",
    "complex_predictor = dspy.TypedPredictor(ComplexSignature, max_retries=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486471df",
   "metadata": {},
   "source": [
    "### 4. Combine with Assertions for Additional Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b25282",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidatedPredictor(dspy.Module):\n",
    "    \"\"\"TypedPredictor with additional semantic validation.\"\"\"\n",
    "\n",
    "    def __init__(self, signature):\n",
    "        super().__init__()\n",
    "        self.typed_predict = dspy.TypedPredictor(signature)\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        result = self.typed_predict(**kwargs)\n",
    "\n",
    "        # Additional semantic checks beyond type validation\n",
    "        dspy.Assert(\n",
    "            len(result.output.summary) >= 50,\n",
    "            \"Summary must be at least 50 characters\"\n",
    "        )\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f6b63f",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "TypedPredictor is a powerful module that brings type safety to language model interactions:\n",
    "\n",
    "- **Type-Safe Outputs**: Guarantees outputs match your defined schemas\n",
    "- **LM Wrapper Pattern**: Acts as the bridge between signatures and language models\n",
    "- **Automatic Validation**: Uses Pydantic for runtime validation\n",
    "- **Retry Mechanisms**: Handles validation failures gracefully\n",
    "- **Compilation Compatible**: Works seamlessly with DSPy optimizers\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Use TypedPredictor** when you need guaranteed output structure\n",
    "2. **Leverage Pydantic models** for complex validation rules\n",
    "3. **Configure appropriate retries** for your use case complexity\n",
    "4. **Combine with assertions** for semantic validation beyond types\n",
    "5. **Start simple** and add complexity as requirements evolve\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- [ChainOfThought Module](./03-chainofthought.md) - Add reasoning to typed predictions\n",
    "- [Assertions Module](./08-assertions.md) - Combine type safety with semantic constraints\n",
    "- [Custom Modules](./05-custom-modules.md) - Build custom typed modules\n",
    "- [Exercises](./07-exercises.md) - Practice with TypedPredictor patterns\n",
    "\n",
    "## Further Reading\n",
    "\n",
    "- [DSPy Paper: Compiling Declarative Language Model Calls](https://arxiv.org/abs/2310.03714) - Section on LM wrappers\n",
    "- [Pydantic Documentation](https://docs.pydantic.dev/) - Advanced validation patterns\n",
    "- [DSPy Documentation: TypedPredictor](https://dspy-docs.vercel.app/docs/deep-dive/typed-predictor)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
