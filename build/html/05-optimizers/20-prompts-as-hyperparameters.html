<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Prompts as Auto-Optimized Hyperparameters - DSPy: A Practical Guide</title>


        <!-- Custom HTML head -->

        <meta name="description" content="The most comprehensive DSPy guide with complete coverage of 9 research papers, advanced optimization techniques, and production-ready applications">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon-de23e50b.svg">
        <link rel="shortcut icon" href="../favicon-8114d1fc.png">
        <link rel="stylesheet" href="../css/variables-8adf115d.css">
        <link rel="stylesheet" href="../css/general-2459343d.css">
        <link rel="stylesheet" href="../css/chrome-ae938929.css">
        <link rel="stylesheet" href="../css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="../highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="../tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="../ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../assets/custom-5fe0be54.css">


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "../searchindex-8a4736e7.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc-90eb277b.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">DSPy: A Practical Guide</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>
                        <a href="https://github.com/dustinober1/Ebook_DSPy" title="Git repository" aria-label="Git repository">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span>
                        </a>
                        <a href="https://github.com/dustinober1/Ebook_DSPy/edit/main/src/05-optimizers/20-prompts-as-hyperparameters.md" title="Suggest an edit" aria-label="Suggest an edit" rel="edit">
                            <span class=fa-svg id="git-edit-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M421.7 220.3l-11.3 11.3-22.6 22.6-205 205c-6.6 6.6-14.8 11.5-23.8 14.1L30.8 511c-8.4 2.5-17.5 .2-23.7-6.1S-1.5 489.7 1 481.2L38.7 353.1c2.6-9 7.5-17.2 14.1-23.8l205-205 22.6-22.6 11.3-11.3 33.9 33.9 62.1 62.1 33.9 33.9zM96 353.9l-9.3 9.3c-.9 .9-1.6 2.1-2 3.4l-25.3 86 86-25.3c1.3-.4 2.5-1.1 3.4-2l9.3-9.3H112c-8.8 0-16-7.2-16-16V353.9zM453.3 19.3l39.4 39.4c25 25 25 65.5 0 90.5l-14.5 14.5-22.6 22.6-11.3 11.3-33.9-33.9-62.1-62.1L314.3 67.7l11.3-11.3 22.6-22.6 14.5-14.5c25-25 65.5-25 90.5 0z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="prompts-as-auto-optimized-hyperparameters"><a class="header" href="#prompts-as-auto-optimized-hyperparameters">Prompts as Auto-Optimized Hyperparameters</a></h1>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p>In traditional machine learning, hyperparameters such as learning rate, batch size, and model architecture are carefully tuned to optimize performance. In the context of language models and DSPy, prompts themselves can be treated as trainable hyperparameters that are automatically optimized to maximize performance on specific tasks.</p>
<p>This revolutionary approach treats prompt engineering not as an art form requiring manual crafting, but as a systematic optimization problem where the optimal prompt is discovered through automated search and refinement.</p>
<h2 id="the-prompt-hyperparameter-framework"><a class="header" href="#the-prompt-hyperparameter-framework">The Prompt Hyperparameter Framework</a></h2>
<h3 id="conceptual-foundation"><a class="header" href="#conceptual-foundation">Conceptual Foundation</a></h3>
<p>When we treat prompts as hyperparameters, we’re fundamentally changing how we think about prompt engineering:</p>
<pre><code>Traditional Approach:
Manual Prompt Design → Test → Manual Refinement → Repeat

DSPy Hyperparameter Approach:
Prompt Space Definition → Automated Optimization → Optimal Prompt
</code></pre>
<h3 id="types-of-prompt-hyperparameters"><a class="header" href="#types-of-prompt-hyperparameters">Types of Prompt Hyperparameters</a></h3>
<ol>
<li><strong>Instruction Templates</strong>: The structure and wording of task instructions</li>
<li><strong>Few-shot Examples</strong>: Selection and ordering of demonstration examples</li>
<li><strong>Formatting Patterns</strong>: How inputs and outputs are presented</li>
<li><strong>Task Decomposition</strong>: How complex tasks are broken down</li>
<li><strong>Reasoning Steps</strong>: Explicit guidance for thinking processes</li>
</ol>
<h2 id="auto-optimization-architecture"><a class="header" href="#auto-optimization-architecture">Auto-Optimization Architecture</a></h2>
<h3 id="the-optimization-loop"><a class="header" href="#the-optimization-loop">The Optimization Loop</a></h3>
<pre><code class="language-python">import dspy
from typing import List, Dict, Any
import numpy as np
from dataclasses import dataclass

@dataclass
class PromptHyperparameters:
    """Container for prompt hyperparameters"""
    instruction_template: str
    example_selection_strategy: str
    formatting_pattern: str
    reasoning_guidance: str
    task_decomposition: List[str]

class PromptHyperparameterOptimizer:
    """Automated prompt hyperparameter optimization"""

    def __init__(self,
                 base_program: dspy.Module,
                 metric_fn: callable,
                 search_space: Dict[str, Any]):
        self.base_program = base_program
        self.metric_fn = metric_fn
        self.search_space = search_space
        self.optimization_history = []

    def optimize(self,
                 trainset: List[dspy.Example],
                 valset: List[dspy.Example],
                 num_iterations: int = 50) -&gt; PromptHyperparameters:
        """Optimize prompt hyperparameters using systematic search"""

        best_params = None
        best_score = 0.0

        for iteration in range(num_iterations):
            # Sample hyperparameters from search space
            current_params = self._sample_hyperparameters()

            # Create program with current hyperparameters
            optimized_program = self._apply_hyperparameters(
                self.base_program, current_params
            )

            # Evaluate on validation set
            score = self._evaluate_program(optimized_program, valset)

            # Track best configuration
            if score &gt; best_score:
                best_score = score
                best_params = current_params

            self.optimization_history.append({
                'iteration': iteration,
                'params': current_params,
                'score': score
            })

        return best_params

    def _sample_hyperparameters(self) -&gt; PromptHyperparameters:
        """Sample from hyperparameter search space"""
        return PromptHyperparameters(
            instruction_template=np.random.choice(
                self.search_space['instruction_templates']
            ),
            example_selection_strategy=np.random.choice(
                self.search_space['example_strategies']
            ),
            formatting_pattern=np.random.choice(
                self.search_space['formatting_patterns']
            ),
            reasoning_guidance=np.random.choice(
                self.search_space['reasoning_guidance']
            ),
            task_decomposition=np.random.choice(
                self.search_space['task_decompositions'],
                size=np.random.randint(1, 4)
            ).tolist()
        )
</code></pre>
<h2 id="practical-implementation-ir-model-training"><a class="header" href="#practical-implementation-ir-model-training">Practical Implementation: IR Model Training</a></h2>
<h3 id="information-retrieval-with-optimized-prompts"><a class="header" href="#information-retrieval-with-optimized-prompts">Information Retrieval with Optimized Prompts</a></h3>
<pre><code class="language-python">class OptimizedIRRetriever(dspy.Module):
    """IR model with prompts optimized as hyperparameters"""

    def __init__(self, prompt_hyperparams: PromptHyperparameters):
        super().__init__()
        self.hyperparams = prompt_hyperparams

        # Core retrieval components
        self.query_encoder = dspy.Predict(
            f"{prompt_hyperparams.instruction_template} -&gt; encoded_query"
        )

        self.document_ranker = dspy.ChainOfThought(
            f"{prompt_hyperparams.formatting_pattern} -&gt; ranked_documents"
        )

        self.relevance_scorer = dspy.Predict(
            f"{prompt_hyperparams.reasoning_guidance} -&gt; relevance_score"
        )

    def forward(self, query: str, documents: List[str]) -&gt; dspy.Prediction:
        """Execute optimized retrieval pipeline"""

        # Step 1: Encode query using optimized instruction
        encoded_query = self.query_encoder(query=query)

        # Step 2: Apply task decomposition if specified
        if len(self.hyperparams.task_decomposition) &gt; 1:
            # Break down complex query
            sub_queries = self._decompose_query(query)
            all_results = []

            for sub_query in sub_queries:
                results = self.document_ranker(
                    query=sub_query,
                    documents="\n".join(documents),
                    instruction=self.hyperparams.instruction_template
                )
                all_results.append(results)

            # Merge results from sub-queries
            final_results = self._merge_results(all_results)
        else:
            # Single query processing
            final_results = self.document_ranker(
                query=query,
                documents="\n".join(documents),
                instruction=self.hyperparams.instruction_template
            )

        # Step 3: Score relevance using optimized reasoning
        ranked_docs = final_results.ranked_documents.split("\n")
        scored_results = []

        for doc in ranked_docs[:10]:  # Top 10 documents
            score_result = self.relevance_scorer(
                query=query,
                document=doc,
                reasoning_prompt=self.hyperparams.reasoning_guidance
            )
            scored_results.append({
                'document': doc,
                'score': float(score_result.relevance_score),
                'reasoning': score_result.get('reasoning', '')
            })

        # Sort by relevance score
        scored_results.sort(key=lambda x: x['score'], reverse=True)

        return dspy.Prediction(
            ranked_documents=[r['document'] for r in scored_results],
            relevance_scores=[r['score'] for r in scored_results],
            reasoning_steps=[r['reasoning'] for r in scored_results],
            encoded_query=encoded_query.encoded_query
        )
</code></pre>
<h2 id="extreme-few-shot-learning-with-10-examples"><a class="header" href="#extreme-few-shot-learning-with-10-examples">Extreme Few-Shot Learning with 10 Examples</a></h2>
<h3 id="the-challenge-of-minimal-data"><a class="header" href="#the-challenge-of-minimal-data">The Challenge of Minimal Data</a></h3>
<p>Training effective models with only 10 labeled examples represents the frontier of few-shot learning. Traditional approaches fail dramatically in this regime, but prompt hyperparameter optimization enables remarkable performance.</p>
<h3 id="data-efficiency-framework"><a class="header" href="#data-efficiency-framework">Data Efficiency Framework</a></h3>
<pre><code class="language-python">class ExtremeFewShotOptimizer:
    """Specialized optimizer for extreme few-shot scenarios"""

    def __init__(self, base_model: str = "gpt-3.5-turbo"):
        self.base_model = base_model
        self.meta_learning_cache = {}

    def optimize_with_10_examples(self,
                                 task_signature: dspy.Signature,
                                 examples: List[dspy.Example],
                                 num_prompt_variations: int = 100) -&gt; dspy.Module:
        """Optimize for tasks with only 10 labeled examples"""

        # Step 1: Meta-prompt generation
        meta_prompts = self._generate_meta_prompts(
            task_signature, num_prompt_variations
        )

        # Step 2: Cross-validation with 10 examples
        best_prompt = None
        best_cv_score = 0.0

        for meta_prompt in meta_prompts:
            # Perform 5-fold cross-validation with 10 examples
            cv_scores = self._cross_validate_with_10_examples(
                meta_prompt, examples, task_signature
            )

            avg_score = np.mean(cv_scores)

            if avg_score &gt; best_cv_score:
                best_cv_score = avg_score
                best_prompt = meta_prompt

        # Step 3: Create optimized program with best prompt
        optimized_program = self._create_optimized_program(
            best_prompt, task_signature
        )

        return optimized_program

    def _generate_meta_prompts(self,
                              signature: dspy.Signature,
                              num_variations: int) -&gt; List[str]:
        """Generate diverse meta-prompts for optimization"""

        # Use meta-learning to generate effective prompt variations
        meta_instruction = f"""
        Generate {num_variations} different prompts for the following task:
        Task: {signature}

        Each prompt should:
        1. Use different instruction styles (direct, conversational, formal, creative)
        2. Include different levels of guidance (minimal, moderate, detailed)
        3. Suggest different reasoning approaches
        4. Vary in complexity and abstraction

        Make each prompt unique and optimized for few-shot learning.
        """

        # Generate using a powerful model
        prompt_generator = dspy.Predict("task -&gt; prompt_variations")
        result = prompt_generator(task=meta_instruction)

        # Parse and clean the generated prompts
        prompts = self._parse_prompts(result.prompt_variations)

        # Add domain-specific variations if examples provide clues
        if len(self.meta_learning_cache) &gt; 0:
            domain_prompts = self._generate_domain_prompts(signature)
            prompts.extend(domain_prompts)

        return prompts[:num_variations]

    def _cross_validate_with_10_examples(self,
                                        prompt: str,
                                        examples: List[dspy.Example],
                                        signature: dspy.Signature) -&gt; List[float]:
        """Perform cross-validation with only 10 examples"""

        scores = []

        # Create 5 folds of 8 training, 2 testing examples
        folds = self._create_folds_with_10_examples(examples, k=5)

        for fold_train, fold_test in folds:
            # Create temporary program with current prompt
            temp_program = self._create_program_with_prompt(prompt, signature)

            # Compile with training examples
            optimizer = BootstrapFewShot(
                metric=self._create_metric_for_task(signature),
                max_bootstrapped_demos=3  # Very few due to limited data
            )

            compiled = optimizer.compile(temp_program, trainset=fold_train)

            # Evaluate on test examples
            fold_score = self._evaluate_on_examples(compiled, fold_test)
            scores.append(fold_score)

        return scores

    def _create_folds_with_10_examples(self,
                                     examples: List[dspy.Example],
                                     k: int = 5) -&gt; List[tuple]:
        """Create balanced cross-validation folds from 10 examples"""

        # Ensure balanced representation across classes if possible
        folds = []

        # Use leave-two-out cross-validation for 10 examples
        for i in range(len(examples)):
            for j in range(i+1, len(examples)):
                test_set = [examples[i], examples[j]]
                train_set = [ex for idx, ex in enumerate(examples)
                           if idx not in [i, j]]

                # Use only first 5 folds to limit computation
                if len(folds) &lt; 5:
                    folds.append((train_set, test_set))

        return folds
</code></pre>
<h2 id="training-pipeline-for-minimal-data"><a class="header" href="#training-pipeline-for-minimal-data">Training Pipeline for Minimal Data</a></h2>
<h3 id="the-10-example-training-pipeline"><a class="header" href="#the-10-example-training-pipeline">The 10-Example Training Pipeline</a></h3>
<pre><code class="language-python">class TenExampleTrainingPipeline:
    """Complete pipeline for training with minimal data"""

    def __init__(self,
                 task_type: str,
                 base_model: str = "gpt-3.5-turbo"):
        self.task_type = task_type
        self.base_model = base_model
        self.pipeline_components = {}

    def train_with_10_examples(self,
                              examples: List[dspy.Example],
                              task_signature: dspy.Signature) -&gt; Dict[str, Any]:
        """Complete training pipeline using only 10 examples"""

        results = {
            'examples_used': len(examples),
            'optimization_steps': [],
            'final_performance': None,
            'trained_components': {}
        }

        # Step 1: Data Analysis and Augmentation
        print("Step 1: Analyzing and augmenting minimal data...")
        augmented_data = self._augment_minimal_data(examples)
        results['optimization_steps'].append(
            f"Augmented {len(examples)} examples to {len(augmented_data)}"
        )

        # Step 2: Prompt Hyperparameter Optimization
        print("Step 2: Optimizing prompt hyperparameters...")
        prompt_optimizer = ExtremeFewShotOptimizer(self.base_model)
        optimized_program = prompt_optimizer.optimize_with_10_examples(
            task_signature, examples
        )
        results['trained_components']['optimized_program'] = optimized_program

        # Step 3: Meta-Learning Integration
        print("Step 3: Integrating meta-learning...")
        meta_enhanced = self._apply_meta_learning(
            optimized_program, augmented_data
        )
        results['trained_components']['meta_enhanced'] = meta_enhanced

        # Step 4: Few-Shot Fine-Tuning
        print("Step 4: Applying few-shot fine-tuning...")
        fine_tuned = self._few_shot_fine_tune(meta_enhanced, examples)
        results['trained_components']['fine_tuned'] = fine_tuned

        # Step 5: Evaluation and Validation
        print("Step 5: Comprehensive evaluation...")
        evaluation_results = self._comprehensive_evaluation(
            fine_tuned, examples
        )
        results['final_performance'] = evaluation_results

        return results

    def _augment_minimal_data(self,
                             examples: List[dspy.Example]) -&gt; List[dspy.Example]:
        """Strategically augment minimal training data"""

        augmented = examples.copy()

        # Strategy 1: Paraphrase generation
        for example in examples:
            paraphraser = dspy.Predict("text -&gt; paraphrase")
            para_result = paraphraser(text=example.input)

            new_example = example.with_inputs(
                input=para_result.paraphrase
            )
            augmented.append(new_example)

        # Strategy 2: Counterfactual generation
        if self.task_type in ['classification', 'qa']:
            for example in examples:
                counterfactual_gen = dspy.ChainOfThought(
                    "example -&gt; counterfactual_example"
                )
                cf_result = counterfactual_gen(
                    example=str(example)
                )

                # Parse and add counterfactual example
                cf_example = self._parse_counterfactual(
                    cf_result.counterfactual_example, example
                )
                if cf_example:
                    augmented.append(cf_example)

        # Strategy 3: Template-based generation
        templates = self._extract_templates_from_examples(examples)
        for template in templates:
            template_gen = dspy.Predict(
                f"template -&gt; new_example_{self.task_type}"
            )
            new_ex_result = template_gen(template=template)

            new_example = self._parse_template_example(
                new_ex_result[f"new_example_{self.task_type}"], example
            )
            if new_example:
                augmented.append(new_example)

        return augmented

    def _apply_meta_learning(self,
                            program: dspy.Module,
                            augmented_data: List[dspy.Example]) -&gt; dspy.Module:
        """Apply meta-learning to improve generalization"""

        # Create meta-learner that learns how to learn
        meta_learner = MetaLearningWrapper(program)

        # Perform MAML-style adaptation with few examples
        adapted_program = meta_learner.adapt(
            support_set=augmented_data[:8],  # Use 8 for adaptation
            query_set=augmented_data[8:],    # 2 for query
            adaptation_steps=3
        )

        return adapted_program

    def _few_shot_fine_tune(self,
                           program: dspy.Module,
                           examples: List[dspy.Example]) -&gt; dspy.Module:
        """Apply specialized fine-tuning for few-shot scenarios"""

        # Use KNNFewShot for example-based learning
        knn_optimizer = KNNFewShot(
            k=3,  # Use 3 nearest neighbors
            metric=self._create_adaptive_metric(examples)
        )

        # Compile with original 10 examples
        fine_tuned = knn_optimizer.compile(program, trainset=examples)

        # Add self-reflection capability
        reflective_wrapper = ReflectiveWrapper(fine_tuned)
        reflective_program = reflective_wrapper.compile(
            trainset=examples,
            reflection_steps=2
        )

        return reflective_program
</code></pre>
<h2 id="real-world-application-best-in-class-ir-with-10-labels"><a class="header" href="#real-world-application-best-in-class-ir-with-10-labels">Real-World Application: Best-in-Class IR with 10 Labels</a></h2>
<h3 id="case-study-implementation"><a class="header" href="#case-study-implementation">Case Study Implementation</a></h3>
<pre><code class="language-python">class BestInClassIRWith10Labels:
    """Complete implementation of IR system trained with only 10 labels"""

    def __init__(self, document_collection: List[str]):
        self.documents = document_collection
        self.retriever = None
        self.training_history = []

    def train_and_deploy(self,
                        labeled_examples: List[dspy.Example]) -&gt; Dict[str, Any]:
        """Train and deploy IR system with only 10 labeled examples"""

        if len(labeled_examples) != 10:
            raise ValueError("This system requires exactly 10 labeled examples")

        # Phase 1: Setup
        self._setup_initial_components()

        # Phase 2: Train with extreme few-shot learning
        training_results = self._train_with_10_examples(labeled_examples)

        # Phase 3: Optimize prompts as hyperparameters
        optimized_retriever = self._optimize_prompt_hyperparameters(
            labeled_examples
        )

        # Phase 4: Deploy with confidence estimation
        deployed_system = self._deploy_with_confidence_estimation(
            optimized_retriever
        )

        return {
            'training_results': training_results,
            'optimized_retriever': optimized_retriever,
            'deployed_system': deployed_system,
            'performance_metrics': self._measure_performance(deployed_system)
        }

    def _setup_initial_components(self):
        """Setup base IR components"""

        # Initialize base retriever with semantic search
        from dspy.retrieve import ColBERTv2Retriever

        self.base_retriever = ColBERTv2Retriever(
            k=20,  # Retrieve more candidates for re-ranking
            collection=self.documents
        )

        # Initialize query processor
        self.query_processor = dspy.ChainOfThought(
            "query -&gt; processed_query, search_intent"
        )

        # Initialize document ranker
        self.document_ranker = dspy.Predict(
            "query, documents -&gt; ranked_documents"
        )

    def _train_with_10_examples(self,
                               examples: List[dspy.Example]) -&gt; Dict[str, Any]:
        """Train system using only 10 examples"""

        # Create training pipeline
        pipeline = TenExampleTrainingPipeline(
            task_type="information_retrieval"
        )

        # Define IR-specific signature
        ir_signature = dspy.Signature(
            "query, documents -&gt; relevant_documents, relevance_scores"
        )

        # Train with minimal data
        training_results = pipeline.train_with_10_examples(
            examples, ir_signature
        )

        self.training_history.append(training_results)

        return training_results

    def _optimize_prompt_hyperparameters(self,
                                        examples: List[dspy.Example]) -&gt; dspy.Module:
        """Optimize prompts as hyperparameters for IR task"""

        # Define search space for prompt hyperparameters
        search_space = {
            'instruction_templates': [
                "Rank these documents by relevance to the query",
                "Order documents from most to least relevant",
                "Select and rank the most relevant documents",
                "Identify the top documents that answer this query"
            ],
            'example_strategies': ['random', 'diverse', 'representative'],
            'formatting_patterns': [
                "Query: {query}\nDocuments:\n{documents}\nRanking:",
                "Q: {query}\nDocs: {documents}\nRelevant:"
            ],
            'reasoning_guidance': [
                "Consider semantic similarity and query-document matching",
                "Evaluate based on relevance, completeness, and authority",
                "Assess how well each document addresses the query"
            ],
            'task_decompositions': [
                ['direct_ranking'],
                ['query_understanding', 'document_analysis', 'ranking'],
                ['initial_filter', 'detailed_comparison', 'final_rank']
            ]
        }

        # Create IR-specific program
        base_ir_program = self._create_base_ir_program()

        # Optimize hyperparameters
        optimizer = PromptHyperparameterOptimizer(
            base_program=base_ir_program,
            metric_fn=self._ir_metric_function,
            search_space=search_space
        )

        # Use 8 examples for optimization, 2 for validation
        best_params = optimizer.optimize(
            trainset=examples[:8],
            valset=examples[8:],
            num_iterations=30
        )

        # Apply best parameters
        optimized_program = self._apply_hyperparameters(
            base_ir_program, best_params
        )

        return optimized_program

    def _create_base_ir_program(self) -&gt; dspy.Module:
        """Create base IR program for optimization"""

        class BaseIRProgram(dspy.Module):
            def __init__(self):
                super().__init__()
                self.process_query = dspy.ChainOfThought(
                    "query -&gt; processed_query, key_terms"
                )
                self.rank_documents = dspy.Predict(
                    "query, documents -&gt; ranked_documents"
                )

            def forward(self, query: str, documents: List[str]):
                # Process the query
                processed = self.process_query(query=query)

                # Rank documents
                ranked = self.rank_documents(
                    query=processed.processed_query,
                    documents="\n".join(documents)
                )

                return dspy.Prediction(
                    ranked_documents=ranked.ranked_documents,
                    processed_query=processed.processed_query,
                    key_terms=processed.key_terms
                )

        return BaseIRProgram()
</code></pre>
<h2 id="performance-analysis-and-validation"><a class="header" href="#performance-analysis-and-validation">Performance Analysis and Validation</a></h2>
<h3 id="measuring-success-with-minimal-data"><a class="header" href="#measuring-success-with-minimal-data">Measuring Success with Minimal Data</a></h3>
<pre><code class="language-python">def evaluate_ir_with_10_examples(trained_system,
                                test_queries: List[str],
                                ground_truth: Dict[str, List[int]]) -&gt; Dict[str, float]:
    """Comprehensive evaluation of IR system trained with 10 examples"""

    metrics = {
        'precision_at_k': {},
        'recall_at_k': {},
        'ndcg': {},
        'mrr': 0.0,
        'confidence_calibration': 0.0
    }

    # Standard IR metrics
    for k in [1, 3, 5, 10]:
        precisions = []
        recalls = []

        for query in test_queries:
            # Get rankings from trained system
            result = trained_system(query=query, documents=all_documents)
            ranked_docs = parse_ranked_documents(result.ranked_documents)

            # Calculate precision@k
            relevant_retrieved = len(
                set(ranked_docs[:k]) &amp; set(ground_truth[query])
            )
            precision = relevant_retrieved / k
            precisions.append(precision)

            # Calculate recall@k
            total_relevant = len(ground_truth[query])
            recall = relevant_retrieved / total_relevant
            recalls.append(recall)

        metrics['precision_at_k'][k] = np.mean(precisions)
        metrics['recall_at_k'][k] = np.mean(recalls)

    # NDCG calculation
    ndcg_scores = []
    for query in test_queries:
        result = trained_system(query=query, documents=all_documents)
        ndcg = calculate_ndcg(result, ground_truth[query])
        ndcg_scores.append(ndcg)
    metrics['ndcg']['mean'] = np.mean(ndcg_scores)

    # Mean Reciprocal Rank
    mrr_scores = []
    for query in test_queries:
        result = trained_system(query=query, documents=all_documents)
        mrr = calculate_mrr(result, ground_truth[query])
        mrr_scores.append(mrr)
    metrics['mrr'] = np.mean(mrr_scores)

    # Confidence calibration (how well confidence scores predict accuracy)
    calibration_score = calculate_confidence_calibration(
        trained_system, test_queries, ground_truth
    )
    metrics['confidence_calibration'] = calibration_score

    return metrics
</code></pre>
<h2 id="key-insights-and-best-practices"><a class="header" href="#key-insights-and-best-practices">Key Insights and Best Practices</a></h2>
<h3 id="principles-for-success-with-10-examples"><a class="header" href="#principles-for-success-with-10-examples">Principles for Success with 10 Examples</a></h3>
<ol>
<li><strong>Prompt Quality Over Quantity</strong>: With minimal data, the prompt becomes the primary source of task knowledge</li>
<li><strong>Meta-Learning is Essential</strong>: Leverage knowledge from related tasks to compensate for data scarcity</li>
<li><strong>Strategic Data Augmentation</strong>: Every augmentation must be carefully designed to add meaningful variation</li>
<li><strong>Confidence Estimation</strong>: Critical when working with minimal training data</li>
<li><strong>Cross-Validation</strong>: Essential to prevent overfitting with such small datasets</li>
</ol>
<h3 id="common-pitfalls-and-solutions"><a class="header" href="#common-pitfalls-and-solutions">Common Pitfalls and Solutions</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Pitfall</th><th>Solution</th></tr>
</thead>
<tbody>
<tr><td>Overfitting to 10 examples</td><td>Use rigorous cross-validation and regularization</td></tr>
<tr><td>Poor prompt generalization</td><td>Optimize prompts as hyperparameters with diverse search</td></tr>
<tr><td>Catastrophic forgetting</td><td>Maintain meta-knowledge across updates</td></tr>
<tr><td>Evaluation bias</td><td>Use held-out data and multiple metrics</td></tr>
</tbody>
</table>
</div>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<p>In this section, we’ve explored how prompts can be treated as auto-optimized hyperparameters, enabling training of sophisticated models with minimal data. We’ve seen how this approach makes it possible to train best-in-class IR models with only 10 labeled examples.</p>
<p>Next, we’ll explore <a href="21-minimal-data-pipelines.html">Minimal Data Training Pipelines</a>, which extends these concepts to create robust training systems for any task with minimal labeled data.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../05-optimizers/19-instruction-demonstration-interactions.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256 246.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg></span>
                            </a>

                            <a rel="next prefetch" href="../05-optimizers/21-minimal-data-pipelines.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg></span>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../05-optimizers/19-instruction-demonstration-interactions.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256 246.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg></span>
                    </a>

                    <a rel="next prefetch" href="../05-optimizers/21-minimal-data-pipelines.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg></span>
                    </a>
            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>


        <script>
            window.playground_line_numbers = true;
        </script>

        <script>
            window.playground_copyable = true;
        </script>

        <script src="../ace-2a3cd908.js"></script>
        <script src="../mode-rust-2c9d5c9a.js"></script>
        <script src="../editor-16ca416c.js"></script>
        <script src="../theme-dawn-4493f9c8.js"></script>
        <script src="../theme-tomorrow_night-9dbe62a9.js"></script>

        <script src="../elasticlunr-ef4e11c1.min.js"></script>
        <script src="../mark-09e88c2c.min.js"></script>
        <script src="../searcher-c2a407aa.js"></script>

        <script src="../clipboard-1626706a.min.js"></script>
        <script src="../highlight-abc7f01d.js"></script>
        <script src="../book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->



    </div>
    </body>
</html>
