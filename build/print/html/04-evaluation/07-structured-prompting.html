<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Structured Prompting - DSPy: A Practical Guide</title>


        <!-- Custom HTML head -->

        <meta name="description" content="The most comprehensive DSPy guide with complete coverage of 9 research papers, advanced optimization techniques, and production-ready applications">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon-de23e50b.svg">
        <link rel="shortcut icon" href="../favicon-8114d1fc.png">
        <link rel="stylesheet" href="../css/variables-8adf115d.css">
        <link rel="stylesheet" href="../css/general-2459343d.css">
        <link rel="stylesheet" href="../css/chrome-ae938929.css">
        <link rel="stylesheet" href="../css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="../highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="../tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="../ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../assets/print-only-ef201963.css">


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "light";
            const default_dark_theme = "";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc-4ea68664.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                    </div>

                    <h1 class="menu-title">DSPy: A Practical Guide</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>

                    </div>
                </div>


                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="structured-prompting-for-robust-evaluation"><a class="header" href="#structured-prompting-for-robust-evaluation">Structured Prompting for Robust Evaluation</a></h1>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p><strong>Structured Prompting</strong> is a systematic methodology for creating evaluation prompts that ensures consistency, reliability, and robustness in language model assessment. Introduced in late 2024, this approach addresses the variability and inconsistency issues that plague ad-hoc prompt engineering in evaluation scenarios.</p>
<p>The key innovation is the formalization of prompt creation into a structured process that:</p>
<ul>
<li>Standardizes prompt components</li>
<li>Ensures comprehensive coverage of evaluation aspects</li>
<li>Reduces ambiguity in task instructions</li>
<li>Enables reproducible evaluation across different models and settings</li>
</ul>
<h2 id="why-structured-prompting-matters"><a class="header" href="#why-structured-prompting-matters">Why Structured Prompting Matters</a></h2>
<h3 id="problems-with-ad-hoc-prompting"><a class="header" href="#problems-with-ad-hoc-prompting">Problems with Ad-Hoc Prompting</a></h3>
<p>Traditional ad-hoc prompting suffers from several issues:</p>
<ol>
<li><strong>Inconsistency</strong>: Different evaluators create wildly different prompts</li>
<li><strong>Ambiguity</strong>: Unclear instructions lead to model confusion</li>
<li><strong>Coverage Gaps</strong>: Important aspects of the task may be omitted</li>
<li><strong>Reproducibility</strong>: Difficult to replicate results across setups</li>
<li><strong>Bias</strong>: Unconscious biases in prompt formulation</li>
</ol>
<h3 id="benefits-of-structured-prompting"><a class="header" href="#benefits-of-structured-prompting">Benefits of Structured Prompting</a></h3>
<pre><code class="language-python"># Ad-hoc approach (problematic)
ad_hoc_prompt = "Tell me about the medical risks in this trial."

# Structured approach (robust)
structured_prompt = """
Task: Risk Assessment Evaluation

Context: You are evaluating a medical research paper for potential risks.
Please analyze the following randomized controlled trial (RCT).

Instructions:
1. Identify all potential risks mentioned
2. Categorize risks by severity (mild/moderate/severe)
3. Note the frequency of each risk
4. Assess if risks are adequately addressed
5. Provide a confidence score for your assessment

Format your response as:
- Risk Category: [Name] - Frequency - Severity
- Overall Assessment: [Summary]
- Confidence Score: [0-1]

Trial Text: {trial_text}
"""
</code></pre>
<h2 id="the-structured-prompting-framework"><a class="header" href="#the-structured-prompting-framework">The Structured Prompting Framework</a></h2>
<h3 id="core-components"><a class="header" href="#core-components">Core Components</a></h3>
<p>A structured prompt consists of five essential components:</p>
<ol>
<li><strong>Task Definition</strong>: Clear specification of what to evaluate</li>
<li><strong>Context Setting</strong>: Background information and role definition</li>
<li><strong>Explicit Instructions</strong>: Step-by-step guidance</li>
<li><strong>Output Format</strong>: Precise formatting requirements</li>
<li><strong>Examples</strong>: Demonstration of expected responses</li>
</ol>
<h3 id="implementation-in-dspy"><a class="header" href="#implementation-in-dspy">Implementation in DSPy</a></h3>
<pre><code class="language-python">import dspy
from typing import Dict, List, Optional

class StructuredPromptEvaluator(dspy.Module):
    """Base class for structured prompting evaluators."""

    def __init__(self, task_spec: Dict):
        super().__init__()
        self.task_spec = task_spec
        self.prompt_template = self._build_structured_prompt()

    def _build_structured_prompt(self) -&gt; str:
        """Build a structured prompt from task specification."""
        components = []

        # Task Definition
        components.append(f"Task: {self.task_spec['task_name']}")
        components.append(f"Objective: {self.task_spec['objective']}")

        # Context Setting
        if 'context' in self.task_spec:
            components.append(f"Context: {self.task_spec['context']}")

        # Instructions
        components.append("\nInstructions:")
        for i, instruction in enumerate(self.task_spec['instructions'], 1):
            components.append(f"{i}. {instruction}")

        # Output Format
        components.append("\nOutput Format:")
        components.append(self.task_spec['output_format'])

        # Examples (if provided)
        if 'examples' in self.task_spec:
            components.append("\nExamples:")
            for example in self.task_spec['examples']:
                components.append(f"Input: {example['input']}")
                components.append(f"Output: {example['output']}\n")

        # Input placeholder
        components.append("\nInput: {input}")

        return "\n".join(components)

    def forward(self, **kwargs):
        """Execute the structured prompt."""
        prompt = self.prompt_template.format(**kwargs)
        return dspy.Predict(prompt)

# Example: Medical Risk Assessment
medical_risk_spec = {
    "task_name": "Medical Risk Assessment",
    "objective": "Evaluate potential risks in medical research papers",
    "context": "You are a medical safety officer reviewing clinical trials.",
    "instructions": [
        "Identify all potential risks and side effects mentioned",
        "Categorize each risk by severity (mild/moderate/severe)",
        "Note the frequency or percentage of each risk",
        "Assess if adequate monitoring is described",
        "Identify any missing safety considerations"
    ],
    "output_format": """
Risk Assessment Report:
{risk_summary}

Severity Breakdown:
- Mild: {mild_risks}
- Moderate: {moderate_risks}
- Severe: {severe_risks}

Safety Assessment: {safety_assessment}
Confidence Score: [0-1]
""",
    "examples": [
        {
            "input": "Trial reported headache in 15% of participants...",
            "output": """Risk Assessment Report:
- Headache: 15% - Mild
- Nausea: 8% - Mild
- Elevated liver enzymes: 2% - Moderate

Severity Breakdown:
- Mild: Headache, Nausea
- Moderate: Elevated liver enzymes
- Severe: None identified

Safety Assessment: Adequate monitoring described for liver enzymes
Confidence Score: 0.9"""
        }
    ]
}

evaluator = StructuredPromptEvaluator(medical_risk_spec)
</code></pre>
<h2 id="advanced-structured-prompting-techniques"><a class="header" href="#advanced-structured-prompting-techniques">Advanced Structured Prompting Techniques</a></h2>
<h3 id="1-template-based-prompt-generation"><a class="header" href="#1-template-based-prompt-generation">1. Template-Based Prompt Generation</a></h3>
<pre><code class="language-python">class PromptTemplate:
    """Template system for generating structured prompts."""

    def __init__(self, template_type: str):
        self.template_type = template_type
        self.templates = self._load_templates()

    def generate_prompt(self, task_config: Dict) -&gt; str:
        """Generate a structured prompt from configuration."""
        template = self.templates[self.template_type]

        # Fill template with task-specific content
        prompt = template.format(**task_config)

        # Add task-specific adaptations
        if self.template_type == "classification":
            prompt = self._add_classification_guidelines(prompt, task_config)
        elif self.template_type == "generation":
            prompt = self._add_generation_constraints(prompt, task_config)

        return prompt

    def _add_classification_guidelines(self, prompt: str, config: Dict) -&gt; str:
        """Add specific guidelines for classification tasks."""
        guidelines = "\n\nClassification Guidelines:\n"
        guidelines += "- Consider all possible categories\n"
        guidelines += "- Provide reasoning for your choice\n"
        guidelines += "- Assign confidence scores\n"

        if 'categories' in config:
            guidelines += "\nValid Categories:\n"
            for cat in config['categories']:
                guidelines += f"- {cat}: {cat['description']}\n"

        return prompt + guidelines

    def _add_generation_constraints(self, prompt: str, config: Dict) -&gt; str:
        """Add specific constraints for generation tasks."""
        constraints = "\n\nGeneration Constraints:\n"

        if 'length' in config:
            constraints += f"- Length: {config['length']} words\n"

        if 'style' in config:
            constraints += f"- Style: {config['style']}\n"

        if 'include_elements' in config:
            constraints += "- Must include:\n"
            for element in config['include_elements']:
                constraints += f"  * {element}\n"

        return prompt + constraints

# Usage example
template_system = PromptTemplate("classification")

classification_config = {
    "task_name": "Sentiment Classification",
    "objective": "Classify text sentiment",
    "categories": [
        {"name": "positive", "description": "Expressing positive emotions"},
        {"name": "negative", "description": "Expressing negative emotions"},
        {"name": "neutral", "description": "No strong emotion expressed"}
    ],
    "input_text": "The product exceeded my expectations!"
}

prompt = template_system.generate_prompt(classification_config)
</code></pre>
<h3 id="2-modular-prompt-components"><a class="header" href="#2-modular-prompt-components">2. Modular Prompt Components</a></h3>
<pre><code class="language-python">class PromptComponent:
    """Base class for reusable prompt components."""

    def __init__(self, name: str):
        self.name = name

    def render(self, context: Dict) -&gt; str:
        """Render the component with given context."""
        raise NotImplementedError

class TaskDefinition(PromptComponent):
    """Component for defining the evaluation task."""

    def __init__(self, task_name: str, objective: str):
        super().__init__("task_definition")
        self.task_name = task_name
        self.objective = objective

    def render(self, context: Dict) -&gt; str:
        return f"""Task: {self.task_name}
Objective: {self.objective}"""

class InstructionBlock(PromptComponent):
    """Component for structured instructions."""

    def __init__(self, instructions: List[str]):
        super().__init__("instructions")
        self.instructions = instructions

    def render(self, context: Dict) -&gt; str:
        instruction_text = "\n".join(
            f"{i+1}. {inst}" for i, inst in enumerate(self.instructions)
        )
        return f"Instructions:\n{instruction_text}"

class OutputFormat(PromptComponent):
    """Component for specifying output format."""

    def __init__(self, format_spec: str):
        super().__init__("output_format")
        self.format_spec = format_spec

    def render(self, context: Dict) -&gt; str:
        return f"Output Format:\n{self.format_spec}"

class StructuredPromptBuilder:
    """Builder for assembling structured prompts from components."""

    def __init__(self):
        self.components = []

    def add_component(self, component: PromptComponent):
        """Add a component to the prompt."""
        self.components.append(component)
        return self

    def build(self, context: Optional[Dict] = None) -&gt; str:
        """Build the complete structured prompt."""
        if context is None:
            context = {}

        parts = []
        for component in self.components:
            parts.append(component.render(context))

        return "\n\n".join(parts)

# Example: Building a complex evaluation prompt
builder = StructuredPromptBuilder()

builder.add_component(TaskDefinition(
    "Medical Literature Review",
    "Extract and categorize adverse events from clinical trials"
))

builder.add_component(InstructionBlock([
    "Read the entire trial report carefully",
    "Identify all mentioned adverse events",
    "Categorize by type (e.g., cardiovascular, neurological)",
    "Note severity and frequency for each event",
    "Highlight any unexpected or severe events"
]))

builder.add_component(OutputFormat("""
Adverse Event Summary:
- Event Name: [Type] - Frequency - Severity
- Total Events: [count]
- Most Common: [event]
- Most Severe: [event]

Assessment: [overall safety assessment]
"""))

prompt = builder.build()
</code></pre>
<h2 id="structured-prompting-for-different-evaluation-types"><a class="header" href="#structured-prompting-for-different-evaluation-types">Structured Prompting for Different Evaluation Types</a></h2>
<h3 id="1-classification-evaluation"><a class="header" href="#1-classification-evaluation">1. Classification Evaluation</a></h3>
<pre><code class="language-python">class ClassificationEvaluator(dspy.Module):
    """Structured evaluator for classification tasks."""

    def __init__(self, categories: List[str], description: str):
        super().__init__()
        self.categories = categories
        self.description = description
        self.evaluator = self._build_evaluator()

    def _build_evaluator(self):
        """Build the structured evaluation prompt."""
        prompt_template = f"""
Classification Task: {self.description}

Categories:
{self._format_categories()}

Evaluation Instructions:
1. Analyze the input text thoroughly
2. Consider each category carefully
3. Select the most appropriate category
4. Provide reasoning for your choice
5. Assign a confidence score (0-1)

Input: {{input}}

Output Format:
Category: [selected category]
Reasoning: [detailed explanation]
Confidence: [0-1]
"""
        return dspy.Predict(prompt_template)

    def _format_categories(self) -&gt; str:
        """Format categories for display."""
        return "\n".join(f"- {cat}" for cat in self.categories)

    def forward(self, input_text: str):
        return self.evaluator(input=input_text)

# Usage
sentiment_evaluator = ClassificationEvaluator(
    categories=["positive", "negative", "neutral"],
    description="Classify the sentiment of the given text"
)
</code></pre>
<h3 id="2-generation-quality-evaluation"><a class="header" href="#2-generation-quality-evaluation">2. Generation Quality Evaluation</a></h3>
<pre><code class="language-python">class GenerationEvaluator(dspy.Module):
    """Structured evaluator for generated text quality."""

    def __init__(self, criteria: List[str]):
        super().__init__()
        self.criteria = criteria
        self.evaluator = self._build_evaluator()

    def _build_evaluator(self):
        """Build the structured evaluation prompt."""
        criteria_text = "\n".join(
            f"- {criterion}" for criterion in self.criteria
        )

        prompt_template = f"""
Text Quality Evaluation

Evaluation Criteria:
{criteria_text}

Instructions:
1. Read the original prompt and generated response
2. Evaluate the response against each criterion
3. Score each criterion (1-5, where 5 is excellent)
4. Provide specific feedback for improvement
5. Calculate overall quality score

Original Prompt: {{prompt}}
Generated Response: {{response}}

Evaluation Format:
Criterion Scores:
{self._criterion_format()}

Overall Score: [average of criteria]
Strengths: [list of positive aspects]
Improvements: [specific suggestions]
"""
        return dspy.Predict(prompt_template)

    def _criterion_format(self) -&gt; str:
        """Generate criterion evaluation format."""
        return "\n".join(
            f"- {criterion}: [1-5] - [brief justification]"
            for criterion in self.criteria
        )

    def forward(self, prompt: str, response: str):
        return self.evaluator(prompt=prompt, response=response)

# Usage
quality_evaluator = GenerationEvaluator([
    "relevance", "coherence", "accuracy", "completeness", "clarity"
])
</code></pre>
<h3 id="3-comparison-evaluation"><a class="header" href="#3-comparison-evaluation">3. Comparison Evaluation</a></h3>
<pre><code class="language-python">class ComparisonEvaluator(dspy.Module):
    """Structured evaluator for comparing multiple outputs."""

    def __init__(self, comparison_aspects: List[str]):
        super().__init__()
        self.comparison_aspects = comparison_aspects
        self.evaluator = self._build_evaluator()

    def _build_evaluator(self):
        """Build the structured comparison prompt."""
        aspects_text = "\n".join(
            f"- {aspect}" for aspect in self.comparison_aspects
        )

        prompt_template = f"""
Response Comparison Analysis

Comparison Aspects:
{aspects_text}

Instructions:
1. Examine all responses carefully
2. Compare responses on each aspect
3. Identify strengths and weaknesses of each
4. Rank responses from best to worst
5. Provide justification for rankings

Original Prompt: {{prompt}}
Response A: {{response_a}}
Response B: {{response_b}}
Response C: {{response_c}}

Comparison Format:
Aspect-by-Aspect Analysis:
{self._comparison_format()}

Ranking:
1. [Response]: [justification]
2. [Response]: [justification]
3. [Response]: [justification]

Overall Recommendation: [which response to use]
"""
        return dspy.Predict(prompt_template)

    def _comparison_format(self) -&gt; str:
        """Generate comparison analysis format."""
        return "\n".join(
            f"- {aspect}: A [score] vs B [score] vs C [score] - [analysis]"
            for aspect in self.comparison_aspects
        )

    def forward(self, prompt: str, responses: List[str]):
        # Ensure we have exactly 3 responses for the template
        while len(responses) &lt; 3:
            responses.append("")

        return self.evaluator(
            prompt=prompt,
            response_a=responses[0],
            response_b=responses[1],
            response_c=responses[2]
        )
</code></pre>
<h2 id="best-practices-for-structured-prompting"><a class="header" href="#best-practices-for-structured-prompting">Best Practices for Structured Prompting</a></h2>
<h3 id="1-clear-task-decomposition"><a class="header" href="#1-clear-task-decomposition">1. Clear Task Decomposition</a></h3>
<pre><code class="language-python"># Good: Break down complex tasks
task_breakdown = {
    "main_task": "Evaluate medical paper quality",
    "subtasks": [
        "Check methodology soundness",
        "Verify statistical analysis",
        "Assess clinical significance",
        "Evaluate generalizability"
    ]
}

# Poor: Vague single instruction
vague_task = "Evaluate if the paper is good"
</code></pre>
<h3 id="2-explicit-output-specifications"><a class="header" href="#2-explicit-output-specifications">2. Explicit Output Specifications</a></h3>
<pre><code class="language-python"># Good: Precise formatting requirements
output_spec = """
Findings Report:
- Study Design: [type] - [quality score 1-5]
- Sample Size: [n] - [adequacy assessment]
- Statistical Methods: [methods] - [appropriateness]
- Bias Risk: [low/medium/high] - [justification]
- Overall Quality: [score 1-10] - [summary]
"""

# Poor: Unclear output expectations
vague_output = "Tell me about the study quality"
</code></pre>
<h3 id="3-comprehensive-coverage"><a class="header" href="#3-comprehensive-coverage">3. Comprehensive Coverage</a></h3>
<pre><code class="language-python"># Good: Check all important aspects
evaluation_aspects = [
    "methodological rigor",
    "statistical validity",
    "clinical relevance",
    "ethical considerations",
    "limitations and weaknesses",
    "conclusions justification"
]
</code></pre>
<h3 id="4-contextual-grounding"><a class="header" href="#4-contextual-grounding">4. Contextual Grounding</a></h3>
<pre><code class="language-python"># Good: Provide relevant context
context = """
You are an expert clinical trial reviewer with 15 years of experience.
Your role is to assess trial quality for publication in a top-tier journal.
Consider current standards in clinical research methodology.
"""
</code></pre>
<h2 id="integration-with-dspy-evaluation"><a class="header" href="#integration-with-dspy-evaluation">Integration with DSPy Evaluation</a></h2>
<h3 id="structured-evaluation-metrics"><a class="header" href="#structured-evaluation-metrics">Structured Evaluation Metrics</a></h3>
<pre><code class="language-python">class StructuredMetric(dspy.Metric):
    """Custom metric for evaluating structured prompt outputs."""

    def __init__(self, structure_validator, content_evaluator):
        self.structure_validator = structure_validator
        self.content_evaluator = content_evaluator

    def __call__(self, example, pred, trace=None):
        """Evaluate both structure and content quality."""
        # Check if output follows required structure
        structure_score = self.structure_validator(pred.output)

        # Evaluate content quality
        content_score = self.content_evaluator(
            example=example,
            prediction=pred.output
        )

        # Combine scores
        total_score = 0.6 * structure_score + 0.4 * content_score
        return total_score

# Usage in evaluation
structured_metric = StructuredMetric(
    structure_validator=validate_output_format,
    content_evaluator=evaluate_content_quality
)

evaluate = dspy.Evaluate(
    devset=test_set,
    metric=structured_metric,
    num_threads=4
)
</code></pre>
<h2 id="exercises"><a class="header" href="#exercises">Exercises</a></h2>
<ol>
<li>
<p><strong>Create a Structured Prompt</strong>: Design a structured prompt for evaluating code quality. Include all five core components.</p>
</li>
<li>
<p><strong>Template System</strong>: Implement a template-based system for generating structured prompts for different tasks (classification, generation, comparison).</p>
</li>
<li>
<p><strong>Component Reuse</strong>: Create reusable prompt components that can be mixed and matched for different evaluation scenarios.</p>
</li>
<li>
<p><strong>Metric Integration</strong>: Build a custom DSPy metric that evaluates both the structure and content of model responses to structured prompts.</p>
</li>
<li>
<p><strong>Comparative Analysis</strong>: Compare evaluation results from structured vs. ad-hoc prompts on the same dataset to quantify the improvement.</p>
</li>
</ol>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../04-evaluation/05-best-practices.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256 246.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg></span>
                            </a>

                            <a rel="next prefetch" href="../04-evaluation/08-llm-as-a-judge.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg></span>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../04-evaluation/05-best-practices.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256 246.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg></span>
                    </a>

                    <a rel="next prefetch" href="../04-evaluation/08-llm-as-a-judge.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg></span>
                    </a>
            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>






        <script src="../clipboard-1626706a.min.js"></script>
        <script src="../highlight-abc7f01d.js"></script>
        <script src="../book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->



    </div>
    </body>
</html>
