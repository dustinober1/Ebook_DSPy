<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Choosing Optimizers - DSPy: A Practical Guide</title>


        <!-- Custom HTML head -->

        <meta name="description" content="The most comprehensive DSPy guide with complete coverage of 9 research papers, advanced optimization techniques, and production-ready applications">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon-de23e50b.svg">
        <link rel="shortcut icon" href="../favicon-8114d1fc.png">
        <link rel="stylesheet" href="../css/variables-8adf115d.css">
        <link rel="stylesheet" href="../css/general-2459343d.css">
        <link rel="stylesheet" href="../css/chrome-ae938929.css">
        <link rel="stylesheet" href="../css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="../highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="../tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="../ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../assets/print-only-ef201963.css">


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "light";
            const default_dark_theme = "";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc-4ea68664.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                    </div>

                    <h1 class="menu-title">DSPy: A Practical Guide</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>

                    </div>
                </div>


                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="choosing-optimizers-decision-guide-and-trade-offs"><a class="header" href="#choosing-optimizers-decision-guide-and-trade-offs">Choosing Optimizers: Decision Guide and Trade-offs</a></h1>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p>DSPy offers multiple optimization strategies, each with distinct strengths and ideal use cases. This chapter provides a comprehensive guide to help you select the right optimizer for your specific needs.</p>
<h2 id="quick-reference-guide"><a class="header" href="#quick-reference-guide">Quick Reference Guide</a></h2>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Optimizer</th><th>Best For</th><th>Data Requirements</th><th>Speed</th><th>Performance</th><th>Complexity</th></tr>
</thead>
<tbody>
<tr><td><strong>None (Baseline)</strong></td><td>Simple tasks, quick prototyping</td><td>None</td><td>Fastest</td><td>Baseline</td><td>Low</td></tr>
<tr><td><strong>BootstrapFewShot</strong></td><td>General improvement</td><td>10-100 examples</td><td>Fast</td><td>Good</td><td>Medium</td></tr>
<tr><td><strong>KNNFewShot</strong></td><td>Dynamic context, large datasets</td><td>100+ examples</td><td>Medium</td><td>Good</td><td>Medium</td></tr>
<tr><td><strong>MIPRO</strong></td><td>Maximum performance</td><td>20-200 examples</td><td>Slow</td><td>Excellent</td><td>High</td></tr>
<tr><td><strong><a href="08-reflective-prompt-evolution.html">RPE</a></strong></td><td>Complex reasoning, exploration</td><td>30+ examples</td><td>Slow</td><td>Excellent</td><td>High</td></tr>
<tr><td><strong>Fine-Tuning</strong></td><td>Domain-specific, cost-sensitive</td><td>1000+ examples</td><td>Very Slow</td><td>Excellent</td><td>Very High</td></tr>
</tbody>
</table>
</div>
<h2 id="decision-framework"><a class="header" href="#decision-framework">Decision Framework</a></h2>
<h3 id="step-1-analyze-your-constraints"><a class="header" href="#step-1-analyze-your-constraints">Step 1: Analyze Your Constraints</a></h3>
<pre><code class="language-python">class OptimizationConstraints:
    def __init__(self):
        # Data constraints
        self.num_examples = None
        self.data_quality = None  # high, medium, low
        self.data_diversity = None  # high, medium, low

        # Resource constraints
        self.time_budget = None  # minutes, hours, days
        self.compute_budget = None  # CPU, single GPU, multi-GPU
        self.memory_limit = None  # GB

        # Performance requirements
        self.target_accuracy = None  # percentage
        self.latency_requirement = None  # ms, seconds
        self.inference_frequency = None  # per day, per hour, per minute

        # Task characteristics
        self.task_complexity = None  # simple, moderate, complex
        self.domain_specificity = None  # general, specialized
        self.explanation_needed = False

def analyze_constraints():
    """Interactive constraint analysis."""
    constraints = OptimizationConstraints()

    print("=== Optimization Constraint Analysis ===\n")

    # Data questions
    constraints.num_examples = int(input(
        "How many training examples do you have? "
    ))

    print("\nData quality (1=low, 2=medium, 3=high):")
    constraints.data_quality = input(
        "How accurate/clean is your data? "
    )

    # Resource questions
    print("\nTime budget:")
    print("1. Minutes (quick prototype)")
    print("2. Hours (reasonable effort)")
    print("3. Days (extensive optimization)")
    time_choice = input("Your time budget? ")
    time_mapping = {"1": "minutes", "2": "hours", "3": "days"}
    constraints.time_budget = time_mapping.get(time_choice, "hours")

    # Performance questions
    constraints.target_accuracy = float(input(
        "\nWhat's your target accuracy improvement (%)? "
    ))

    # Task complexity
    print("\nTask complexity:")
    print("1. Simple (e.g., basic classification)")
    print("2. Moderate (e.g., QA with reasoning)")
    print("3. Complex (e.g., multi-step reasoning)")
    complexity_choice = input("Your task complexity? ")
    complexity_mapping = {"1": "simple", "2": "moderate", "3": "complex"}
    constraints.task_complexity = complexity_mapping.get(complexity_choice, "moderate")

    return constraints

# Example usage
constraints = analyze_constraints()
</code></pre>
<h3 id="step-2-optimizer-recommendations"><a class="header" href="#step-2-optimizer-recommendations">Step 2: Optimizer Recommendations</a></h3>
<pre><code class="language-python">def recommend_optimizer(constraints):
    """Provide optimizer recommendations based on constraints."""
    recommendations = []

    # Rule-based recommendations
    if constraints.num_examples &lt; 10:
        recommendations.append({
            "optimizer": "None (Baseline)",
            "reason": "Insufficient data for optimization",
            "confidence": "High"
        })

    elif constraints.time_budget == "minutes":
        recommendations.append({
            "optimizer": "BootstrapFewShot",
            "config": {"max_bootstrapped_demos": 4},
            "reason": "Fast optimization with minimal setup",
            "confidence": "High"
        })

    elif constraints.num_examples &gt; 100 and constraints.task_complexity != "complex":
        recommendations.append({
            "optimizer": "KNNFewShot",
            "config": {"k": 5},
            "reason": "Efficient with large datasets",
            "confidence": "High"
        })

    if constraints.task_complexity == "complex" and constraints.target_accuracy &gt; 10:
        recommendations.append({
            "optimizer": "MIPRO",
            "config": {"num_candidates": 15, "auto": "medium"},
            "reason": "Best for complex tasks requiring maximum performance",
            "confidence": "High"
        })

        # Also suggest RPE for complex reasoning tasks
        if constraints.num_examples &gt;= 30:
            recommendations.append({
                "optimizer": "ReflectivePromptEvolution",
                "config": {"population_size": 10, "generations": 5},
                "reason": "Evolutionary approach excellent for complex multi-step reasoning",
                "confidence": "Medium"
            })

    if constraints.domain_specificity == "specialized" and constraints.num_examples &gt; 1000:
        recommendations.append({
            "optimizer": "Fine-Tuning",
            "config": {"use_qlora": True, "epochs": 3},
            "reason": "Optimal for domain-specific applications",
            "confidence": "Medium"
        })

    if constraints.inference_frequency == "per minute" and constraints.compute_budget == "CPU":
        recommendations.append({
            "optimizer": "Fine-Tuning",
            "config": {"model_size": "&lt;3B", "quantize": True},
            "reason": "Cost-effective for high-frequency inference",
            "confidence": "Medium"
        })

    return recommendations

# Get recommendations
recommendations = recommend_optimizer(constraints)
print("\n=== Optimizer Recommendations ===")
for i, rec in enumerate(recommendations, 1):
    print(f"\n{i}. {rec['optimizer']}")
    print(f"   Reason: {rec['reason']}")
    print(f"   Confidence: {rec['confidence']}")
    if 'config' in rec:
        print(f"   Suggested config: {rec['config']}")
</code></pre>
<h2 id="use-case-analysis"><a class="header" href="#use-case-analysis">Use Case Analysis</a></h2>
<h3 id="use-case-1-quick-prototype-for-startup"><a class="header" href="#use-case-1-quick-prototype-for-startup">Use Case 1: Quick Prototype for Startup</a></h3>
<p><strong>Scenario</strong>: Building an MVP for a customer support bot</p>
<p><strong>Constraints</strong>:</p>
<ul>
<li>Limited data (50 examples)</li>
<li>Tight deadline (2 days)</li>
<li>Moderate accuracy required (70%+)</li>
<li>CPU inference only</li>
</ul>
<p><strong>Recommendation</strong>:</p>
<pre><code class="language-python">optimizer = BootstrapFewShot(
    metric=answer_accuracy,
    max_bootstrapped_demos=8,
    max_labeled_demos=4
)

# Quick iteration cycle
prototype = optimizer.compile(SupportBot(), trainset=examples)
</code></pre>
<p><strong>Why</strong>:</p>
<ul>
<li>Fast to implement and test</li>
<li>Works with limited data</li>
<li>Provides reasonable improvement quickly</li>
<li>Easy to iterate and refine</li>
</ul>
<h3 id="use-case-2-enterprise-rag-system"><a class="header" href="#use-case-2-enterprise-rag-system">Use Case 2: Enterprise RAG System</a></h3>
<p><strong>Scenario</strong>: Large-scale document QA for legal firm</p>
<p><strong>Constraints</strong>:</p>
<ul>
<li>Large dataset (10,000 examples)</li>
<li>High accuracy required (95%+)</li>
<li>Domain-specific (legal terminology)</li>
<li>Inference cost matters</li>
</ul>
<p><strong>Recommendation</strong>:</p>
<pre><code class="language-python"># Stage 1: Quick baseline
baseline = BootstrapFewShot(metric=f1_score).compile(
    LegalRAG(), trainset=trainset[:1000]
)

# Stage 2: Advanced optimization
optimizer = MIPRO(
    metric=weighted_metric,
    num_candidates=20,
    auto="heavy"
)
optimized = optimizer.compile(LegalRAG(), trainset=trainset)

# Stage 3: Fine-tune for cost efficiency
if inference_cost_high:
    fine_tuner = FineTuneForDomain()
    final_model = fine_tuner.fine_tune(optimized, domain_data)
</code></pre>
<p><strong>Why</strong>:</p>
<ul>
<li>Start with BootstrapFewShot for quick baseline</li>
<li>Use MIPRO for maximum performance</li>
<li>Consider fine-tuning for long-term cost efficiency</li>
</ul>
<h3 id="use-case-3-complex-multi-hop-reasoning"><a class="header" href="#use-case-3-complex-multi-hop-reasoning">Use Case 3: Complex Multi-hop Reasoning</a></h3>
<p><strong>Scenario</strong>: Question answering requiring multiple reasoning steps (e.g., HotpotQA, complex medical diagnosis)</p>
<p><strong>Constraints</strong>:</p>
<ul>
<li>Multi-step reasoning required</li>
<li>Complex problem decomposition needed</li>
<li>Medium dataset size (50-500 examples)</li>
<li>High accuracy critical (&gt;90%)</li>
</ul>
<p><strong>Recommendation</strong>:</p>
<pre><code class="language-python"># RPE for complex reasoning tasks
optimizer = ReflectivePromptEvolution(
    metric=multi_hop_accuracy,
    population_size=12,
    generations=6,
    mutation_rate=0.3,
    diversity_weight=0.4
)

reasoning_system = optimizer.compile(
    MultiHopReasoner(),
    trainset=complex_qa_examples,
    valset=val_examples
)

# Combine with Chain of Thought for best results
final_system = ChainOfThoughtEnhanced(reasoning_system)
</code></pre>
<p><strong>Why</strong>:</p>
<ul>
<li>RPE excels at discovering novel reasoning patterns</li>
<li>Evolutionary approach explores multiple solution paths</li>
<li>Self-reflection improves reasoning quality over time</li>
<li>Diversity maintenance prevents converging on suboptimal approaches</li>
</ul>
<h3 id="use-case-4-real-time-classification-api"><a class="header" href="#use-case-4-real-time-classification-api">Use Case 4: Real-time Classification API</a></h3>
<p><strong>Scenario</strong>: Content moderation for social platform</p>
<p><strong>Constraints</strong>:</p>
<ul>
<li>High throughput (1000+ requests/second)</li>
<li>Low latency requirement (&lt;100ms)</li>
<li>Continuous learning (new content types)</li>
<li>Good accuracy sufficient (85%+)</li>
</ul>
<p><strong>Recommendation</strong>:</p>
<pre><code class="language-python"># KNNFewShot for adaptive context
optimizer = KNNFewShot(
    k=3,
    similarity_fn=semantic_similarity,
    cache_embeddings=True
)

classifier = optimizer.compile(
    ContentModerator(),
    trainset=moderation_examples
)

# Option: Fine-tune small model for deployment
if latency_critical:
    small_model = fine_tune_classifier(
        base_model="gemma-2b",
        training_data=examples,
        quantize=True
    )
</code></pre>
<p><strong>Why</strong>:</p>
<ul>
<li>KNNFewShot provides context-aware classification</li>
<li>Embedding caching improves speed</li>
<li>Small fine-tuned model for production if needed</li>
</ul>
<h2 id="performance-comparison"><a class="header" href="#performance-comparison">Performance Comparison</a></h2>
<h3 id="benchmark-methodology"><a class="header" href="#benchmark-methodology">Benchmark Methodology</a></h3>
<pre><code class="language-python">import time
import pandas as pd

def benchmark_optimizers(program, trainset, testset, optimizers):
    """Compare optimizer performance."""
    results = []

    for name, optimizer_config in optimizers.items():
        print(f"\nTesting {name}...")

        # Record start time
        start_time = time.time()

        # Compile/prepare model
        if name == "Baseline":
            compiled = program
        else:
            optimizer = optimizer_config['optimizer']
            compiled = optimizer.compile(
                program,
                trainset=trainset,
                **optimizer_config.get('kwargs', {})
            )

        # Record compilation time
        compile_time = time.time() - start_time

        # Evaluate performance
        eval_start = time.time()
        accuracy = evaluate(compiled, testset)
        eval_time = time.time() - eval_start

        # Calculate inference speed
        speed_start = time.time()
        for example in testset[:10]:  # Sample for speed test
            _ = compiled(**example.inputs())
        avg_inference_time = (time.time() - speed_start) / 10

        results.append({
            'Optimizer': name,
            'Accuracy': accuracy,
            'Compilation Time (s)': compile_time,
            'Evaluation Time (s)': eval_time,
            'Avg Inference (ms)': avg_inference_time * 1000,
            'Parameters': str(optimizer_config.get('kwargs', {}))
        })

    return pd.DataFrame(results)

# Example benchmark
optimizers_to_test = {
    "Baseline": {},
    "BootstrapFewShot": {
        "optimizer": BootstrapFewShot(metric=accuracy_metric),
        "kwargs": {"max_bootstrapped_demos": 8}
    },
    "KNNFewShot": {
        "optimizer": KNNFewShot(k=5),
        "kwargs": {}
    },
    "MIPRO": {
        "optimizer": MIPRO(metric=accuracy_metric),
        "kwargs": {"num_candidates": 10, "auto": "medium"}
    },
    "RPE": {
        "optimizer": ReflectivePromptEvolution(metric=accuracy_metric),
        "kwargs": {"population_size": 8, "generations": 4}
    }
}

results_df = benchmark_optimizers(
    my_program,
    trainset,
    testset,
    optimizers_to_test
)

print(results_df)
</code></pre>
<h3 id="expected-performance-patterns"><a class="header" href="#expected-performance-patterns">Expected Performance Patterns</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Optimizer</th><th>Accuracy Gain</th><th>Compile Time</th><th>Inference Speed</th><th>Best For</th></tr>
</thead>
<tbody>
<tr><td>Baseline</td><td>0%</td><td>&lt; 1s</td><td>Fastest</td><td>Quick testing</td></tr>
<tr><td>BootstrapFewShot</td><td>5-15%</td><td>1-5 min</td><td>Fast</td><td>Most tasks</td></tr>
<tr><td>KNNFewShot</td><td>5-12%</td><td>1-2 min</td><td>Medium</td><td>Context tasks</td></tr>
<tr><td>MIPRO</td><td>10-25%</td><td>5-30 min</td><td>Fast</td><td>Complex tasks</td></tr>
<tr><td>RPE</td><td>12-28%</td><td>10-45 min</td><td>Fast</td><td>Complex reasoning</td></tr>
<tr><td>Fine-Tuning</td><td>15-30%</td><td>1-4 hrs</td><td>Fast-Medium</td><td>Production</td></tr>
</tbody>
</table>
</div>
<h2 id="optimization-strategies"><a class="header" href="#optimization-strategies">Optimization Strategies</a></h2>
<h3 id="strategy-1-progressive-optimization"><a class="header" href="#strategy-1-progressive-optimization">Strategy 1: Progressive Optimization</a></h3>
<pre><code class="language-python">def progressive_optimization(program, trainset, valset):
    """Start simple and progressively add optimization."""
    stages = [
        {
            "name": "Baseline",
            "optimizer": None,
            "description": "No optimization"
        },
        {
            "name": "BootstrapFewShot",
            "optimizer": BootstrapFewShot(metric=accuracy_metric),
            "config": {"max_bootstrapped_demos": 4},
            "description": "Basic few-shot learning"
        },
        {
            "name": "KNNFewShot",
            "optimizer": KNNFewShot(k=3),
            "description": "Context-aware examples"
        },
        {
            "name": "MIPRO",
            "optimizer": MIPRO(metric=accuracy_metric, auto="medium"),
            "description": "Full optimization"
        },
        {
            "name": "RPE",
            "optimizer": ReflectivePromptEvolution(metric=accuracy_metric),
            "config": {"population_size": 8, "generations": 4},
            "description": "Evolutionary optimization for complex reasoning"
        }
    ]

    results = {}
    best_program = program
    best_score = 0

    for stage in stages:
        print(f"\n=== Stage: {stage['name']} ===")
        print(f"Description: {stage['description']}")

        if stage['optimizer']:
            compiled = stage['optimizer'].compile(
                best_program,
                trainset=trainset,
                **stage.get('config', {})
            )
        else:
            compiled = program

        # Evaluate
        score = evaluate(compiled, valset)
        results[stage['name']] = score

        print(f"Score: {score:.3f}")

        # Keep the best
        if score &gt; best_score:
            best_score = score
            best_program = compiled
            print("✓ New best model!")

    return best_program, results

# Use progressive optimization
final_model, all_scores = progressive_optimization(
    my_program,
    trainset,
    valset
)
</code></pre>
<h3 id="strategy-2-ensemble-approaches"><a class="header" href="#strategy-2-ensemble-approaches">Strategy 2: Ensemble Approaches</a></h3>
<pre><code class="language-python">class EnsembleOptimizer:
    """Combine multiple optimized programs."""
    def __init__(self):
        self.models = []
        self.weights = []

    def add_model(self, model, weight=1.0):
        self.models.append(model)
        self.weights.append(weight)

    def predict(self, **kwargs):
        predictions = []
        for model, weight in zip(self.models, self.weights):
            pred = model(**kwargs)
            predictions.append((pred, weight))

        # Weighted voting for classification
        if hasattr(predictions[0][0], 'answer'):
            answers = {}
            for pred, weight in predictions:
                answer = pred.answer
                answers[answer] = answers.get(answer, 0) + weight
            best_answer = max(answers, key=answers.get)
            return dspy.Prediction(answer=best_answer)

        return predictions[0][0]  # Return first for other cases

# Create ensemble
ensemble = EnsembleOptimizer()

# Add different optimized versions
ensemble.add_model(bootstrap_model, weight=0.3)
ensemble.add_model(knn_model, weight=0.3)
ensemble.add_model(mipro_model, weight=0.4)
</code></pre>
<h3 id="strategy-3-adaptive-optimization"><a class="header" href="#strategy-3-adaptive-optimization">Strategy 3: Adaptive Optimization</a></h3>
<pre><code class="language-python">def adaptive_optimization(program, trainset, valset, target_accuracy):
    """Automatically select optimizer based on data characteristics."""
    # Analyze data
    num_examples = len(trainset)
    diversity_score = calculate_diversity(trainset)

    # Start with appropriate optimizer
    if num_examples &lt; 20:
        optimizer = BootstrapFewShot(metric=accuracy_metric)
        print("Using BootstrapFewShot (small dataset)")
    elif diversity_score &gt; 0.7:
        optimizer = KNNFewShot(k=5)
        print("Using KNNFewShot (high diversity)")
    else:
        optimizer = MIPRO(metric=accuracy_metric, auto="medium")
        print("Using MIPRO (general case)")

    # Initial optimization
    compiled = optimizer.compile(program, trainset=trainset)
    score = evaluate(compiled, valset)

    print(f"Initial score: {score:.3f}")

    # If still below target, try more advanced optimization
    if score &lt; target_accuracy and num_examples &gt; 50:
        print("Trying MIPRO for better performance...")
        mipro = MIPRO(metric=accuracy_metric, auto="heavy")
        compiled = mipro.compile(program, trainset=trainset)
        score = evaluate(compiled, valset)
        print(f"Final score: {score:.3f}")

    return compiled

# Use adaptive optimization
final_model = adaptive_optimization(
    my_program,
    trainset,
    valset,
    target_accuracy=0.85
)
</code></pre>
<h2 id="cost-benefit-analysis"><a class="header" href="#cost-benefit-analysis">Cost-Benefit Analysis</a></h2>
<h3 id="optimization-cost-calculator"><a class="header" href="#optimization-cost-calculator">Optimization Cost Calculator</a></h3>
<pre><code class="language-python">def calculate_optimization_cost(optimizer_type, config, data_size):
    """Estimate time and compute cost of optimization."""
    costs = {
        "BootstrapFewShot": {
            "time_per_example": 0.5,  # seconds
            "base_time": 60,  # seconds
            "compute_multiplier": 1.0
        },
        "KNNFewShot": {
            "time_per_example": 0.2,
            "base_time": 30,
            "compute_multiplier": 1.2
        },
        "MIPRO": {
            "time_per_example": 5.0,
            "base_time": 300,
            "compute_multiplier": 3.0
        },
        "RPE": {
            "time_per_example": 8.0,
            "base_time": 600,
            "compute_multiplier": 5.0
        },
        "FineTuning": {
            "time_per_example": 10.0,
            "base_time": 1800,
            "compute_multiplier": 10.0
        }
    }

    if optimizer_type not in costs:
        return None

    cost_info = costs[optimizer_type]
    estimated_time = (
        cost_info["base_time"] +
        cost_info["time_per_example"] * data_size
    )

    # Adjust for configuration
    if optimizer_type == "MIPRO":
        candidates = config.get("num_candidates", 10)
        estimated_time *= candidates / 10

    return {
        "optimizer": optimizer_type,
        "estimated_time_minutes": estimated_time / 60,
        "estimated_time_hours": estimated_time / 3600,
        "compute_units": estimated_time * cost_info["compute_multiplier"] / 3600
    }

# Example usage
for optimizer in ["BootstrapFewShot", "KNNFewShot", "MIPRO", "RPE", "FineTuning"]:
    cost = calculate_optimization_cost(optimizer, {}, 1000)
    print(f"\n{optimizer}:")
    print(f"  Time: {cost['estimated_time_minutes']:.1f} minutes")
    print(f"  Compute: {cost['compute_units']:.1f} units")
</code></pre>
<h3 id="roi-analysis"><a class="header" href="#roi-analysis">ROI Analysis</a></h3>
<pre><code class="language-python">def analyze_roi(optimization_costs, performance_gains, inference_volume):
    """Analyze return on investment for optimization."""
    analysis = {}

    for optimizer, cost in optimization_costs.items():
        gain = performance_gains.get(optimizer, 0)
        monthly_savings = gain * inference_volume * 0.001  # Example value

        roi = {
            "optimizer": optimizer,
            "optimization_cost": cost["compute_units"] * 10,  # $10 per unit
            "monthly_savings": monthly_savings,
            "payback_period_days": (cost["compute_units"] * 10) / (monthly_savings / 30),
            "annual_roi": (monthly_savings * 12 - cost["compute_units"] * 10) / (cost["compute_units"] * 10)
        }

        analysis[optimizer] = roi

    return analysis

# Example ROI analysis
costs = {
    "BootstrapFewShot": calculate_optimization_cost("BootstrapFewShot", {}, 1000),
    "MIPRO": calculate_optimization_cost("MIPRO", {}, 1000)
}

gains = {
    "BootstrapFewShot": 0.08,  # 8% improvement
    "MIPRO": 0.15  # 15% improvement
}

roi_analysis = analyze_roi(costs, gains, inference_volume=100000)
for optimizer, analysis in roi_analysis.items():
    print(f"\n{optimizer} ROI:")
    print(f"  Payback period: {analysis['payback_period_days']:.1f} days")
    print(f"  Annual ROI: {analysis['annual_roi']:.1%}")
</code></pre>
<h2 id="optimization-order-effects"><a class="header" href="#optimization-order-effects">Optimization Order Effects</a></h2>
<p>When combining multiple optimization strategies, the order of application significantly impacts final performance.</p>
<h3 id="why-order-matters"><a class="header" href="#why-order-matters">Why Order Matters</a></h3>
<p>Research on joint optimization demonstrates that <strong>fine-tuning first, then prompt optimization</strong> consistently outperforms the reverse order:</p>
<pre><code class="language-python"># OPTIMAL ORDER
# Fine-tuning -&gt; Prompt Optimization
# Improvement: 3.5x beyond individual approaches

# SUBOPTIMAL ORDER
# Prompt Optimization -&gt; Fine-tuning
# Improvement: Only 1.8x (prompts don't transfer well)

def demonstrate_order_effects(program, trainset, testset, base_model):
    """Show impact of optimization order."""
    results = {}

    # Baseline
    results["baseline"] = evaluate(program, testset)

    # Order 1: Fine-tune first (RECOMMENDED)
    finetuned = finetune(base_model, trainset)
    dspy.settings.configure(lm=finetuned)
    optimizer = MIPRO(metric=accuracy, auto="medium")
    compiled = optimizer.compile(program, trainset=trainset)
    results["ft_then_po"] = evaluate(compiled, testset)

    # Order 2: Prompt optimize first (NOT RECOMMENDED)
    dspy.settings.configure(lm=base_model)
    compiled_base = optimizer.compile(program, trainset=trainset)
    finetuned_after = finetune(base_model, trainset)
    dspy.settings.configure(lm=finetuned_after)
    # Note: prompts optimized for base model may not work well
    results["po_then_ft"] = evaluate(compiled_base, testset)

    print(f"Baseline: {results['baseline']:.2%}")
    print(f"Fine-tune -&gt; Prompt Opt: {results['ft_then_po']:.2%}")
    print(f"Prompt Opt -&gt; Fine-tune: {results['po_then_ft']:.2%}")

    return results
</code></pre>
<h3 id="the-optimization-order-decision-tree"><a class="header" href="#the-optimization-order-decision-tree">The Optimization Order Decision Tree</a></h3>
<pre><code>Starting optimization?
|
+-- Have compute for fine-tuning?
|   +-- Yes: Fine-tune first
|   |       |
|   |       +-- Need maximum performance?
|   |           +-- Yes: MIPRO or COPA
|   |           +-- No: BootstrapFewShot
|   |
|   +-- No: Skip to prompt optimization
|           |
|           +-- Complex task?
|               +-- Yes: MIPRO or RPE
|               +-- No: BootstrapFewShot or KNNFewShot
</code></pre>
<h2 id="synergy-quantification"><a class="header" href="#synergy-quantification">Synergy Quantification</a></h2>
<p>Combined optimization approaches achieve synergistic effects that exceed the sum of individual improvements.</p>
<h3 id="measuring-synergy"><a class="header" href="#measuring-synergy">Measuring Synergy</a></h3>
<pre><code class="language-python">def calculate_synergy(baseline, ft_only, po_only, combined):
    """
    Calculate synergistic improvement from combined optimization.

    Synergy = Combined - (Baseline + FT_Improvement + PO_Improvement)

    A positive synergy indicates the approaches work better together
    than they would independently.
    """
    ft_improvement = ft_only - baseline
    po_improvement = po_only - baseline
    additive_expected = baseline + ft_improvement + po_improvement

    synergy = combined - additive_expected
    synergy_multiplier = combined / additive_expected if additive_expected &gt; 0 else 0

    return {
        "baseline": baseline,
        "fine_tuning_only": ft_only,
        "prompt_opt_only": po_only,
        "combined": combined,
        "additive_expected": additive_expected,
        "synergy_absolute": synergy,
        "synergy_multiplier": synergy_multiplier
    }

# Example from research benchmarks:
# Baseline: 12%
# Fine-tuning only: 28% (+16%)
# Prompt optimization only: 20% (+8%)
# Combined: 45% (not 36%!)

synergy_result = calculate_synergy(
    baseline=0.12,
    ft_only=0.28,
    po_only=0.20,
    combined=0.45
)

print(f"Expected additive: {synergy_result['additive_expected']:.2%}")
print(f"Actual combined: {synergy_result['combined']:.2%}")
print(f"Synergy: {synergy_result['synergy_absolute']:.2%}")
print(f"Synergy multiplier: {synergy_result['synergy_multiplier']:.2f}x")
# Output: Synergy multiplier: 1.25x (25% better than additive)
</code></pre>
<h3 id="benchmark-synergy-results"><a class="header" href="#benchmark-synergy-results">Benchmark Synergy Results</a></h3>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Task</th><th>Baseline</th><th>FT Only</th><th>PO Only</th><th>Expected</th><th>Combined</th><th>Synergy</th></tr>
</thead>
<tbody>
<tr><td>MultiHopQA</td><td>12%</td><td>28%</td><td>20%</td><td>36%</td><td>45%</td><td>3.5x</td></tr>
<tr><td>GSM8K Math</td><td>11%</td><td>32%</td><td>22%</td><td>43%</td><td>55%</td><td>2.8x</td></tr>
<tr><td>AQuA</td><td>9%</td><td>35%</td><td>28%</td><td>54%</td><td>69%</td><td>3.4x</td></tr>
<tr><td>Classification</td><td>65%</td><td>82%</td><td>78%</td><td>95%*</td><td>91%</td><td>N/A</td></tr>
</tbody>
</table>
</div>
<p>*Note: Classification ceiling effects limit synergy measurement.</p>
<h3 id="when-synergy-is-highest"><a class="header" href="#when-synergy-is-highest">When Synergy Is Highest</a></h3>
<p>Synergy is most pronounced when:</p>
<ol>
<li><strong>Task complexity is high</strong>: Multi-step reasoning tasks</li>
<li><strong>Base model capability is low</strong>: Smaller models (&lt; 13B)</li>
<li><strong>Instructions are complex</strong>: Multi-part requirements</li>
<li><strong>Domain is specialized</strong>: Technical/domain-specific content</li>
</ol>
<pre><code class="language-python">def predict_synergy_potential(task_complexity, model_size, instruction_complexity):
    """
    Estimate potential synergy from combined optimization.

    Higher values indicate greater potential benefit.
    """
    # Empirical factors from research
    complexity_factor = {"simple": 1.0, "moderate": 1.5, "complex": 2.5}
    size_factor = {"&lt;7B": 2.0, "7-13B": 1.5, "&gt;13B": 1.0}
    instruction_factor = {"basic": 1.0, "detailed": 1.5, "multi_step": 2.0}

    synergy_potential = (
        complexity_factor.get(task_complexity, 1.0) *
        size_factor.get(model_size, 1.0) *
        instruction_factor.get(instruction_complexity, 1.0)
    )

    return synergy_potential
</code></pre>
<h2 id="joint-optimization-limitations"><a class="header" href="#joint-optimization-limitations">Joint Optimization Limitations</a></h2>
<p>While combined optimization offers powerful improvements, understanding its limitations helps set realistic expectations.</p>
<h3 id="data-requirements"><a class="header" href="#data-requirements">Data Requirements</a></h3>
<pre><code class="language-python">JOINT_OPTIMIZATION_REQUIREMENTS = {
    "minimum_examples": 50,
    "recommended_examples": 100,
    "optimal_examples": 200,
    "warning_threshold": 30
}

def assess_data_sufficiency(num_examples):
    """Check if dataset is sufficient for joint optimization."""
    if num_examples &lt; JOINT_OPTIMIZATION_REQUIREMENTS["warning_threshold"]:
        return {
            "sufficient": False,
            "recommendation": "Use prompt-only optimization (BootstrapFewShot)",
            "reason": "Insufficient data for fine-tuning"
        }
    elif num_examples &lt; JOINT_OPTIMIZATION_REQUIREMENTS["minimum_examples"]:
        return {
            "sufficient": "marginal",
            "recommendation": "Consider lightweight fine-tuning or prompt-only",
            "reason": "Fine-tuning may overfit"
        }
    elif num_examples &lt; JOINT_OPTIMIZATION_REQUIREMENTS["recommended_examples"]:
        return {
            "sufficient": True,
            "recommendation": "Joint optimization viable, use regularization",
            "reason": "Adequate but not ideal for fine-tuning"
        }
    else:
        return {
            "sufficient": True,
            "recommendation": "Full joint optimization recommended",
            "reason": "Sufficient data for robust optimization"
        }

# Example assessment
assessment = assess_data_sufficiency(75)
print(f"Sufficient: {assessment['sufficient']}")
print(f"Recommendation: {assessment['recommendation']}")
</code></pre>
<h3 id="computational-cost-considerations"><a class="header" href="#computational-cost-considerations">Computational Cost Considerations</a></h3>
<pre><code class="language-python">def estimate_joint_optimization_cost(
    num_examples,
    model_size_b,
    optimization_strategy
):
    """
    Estimate computational requirements for joint optimization.

    Returns estimated GPU hours and API calls.
    """
    costs = {
        "fine_tuning_only": {
            "gpu_hours": model_size_b * num_examples / 5000,
            "api_calls": 0
        },
        "prompt_only_bootstrap": {
            "gpu_hours": 0,
            "api_calls": num_examples * 10
        },
        "prompt_only_mipro": {
            "gpu_hours": 0,
            "api_calls": num_examples * 25
        },
        "joint_bootstrap": {
            "gpu_hours": model_size_b * num_examples / 5000,
            "api_calls": num_examples * 10
        },
        "joint_mipro": {
            "gpu_hours": model_size_b * num_examples / 5000,
            "api_calls": num_examples * 25
        },
        "copa": {
            "gpu_hours": model_size_b * num_examples / 5000 * 1.2,
            "api_calls": num_examples * 30
        }
    }

    if optimization_strategy not in costs:
        return None

    cost = costs[optimization_strategy]

    # Rough cost estimate (adjust based on your infrastructure)
    estimated_cost = cost["gpu_hours"] * 2.0 + cost["api_calls"] * 0.002

    return {
        "strategy": optimization_strategy,
        "gpu_hours": cost["gpu_hours"],
        "api_calls": cost["api_calls"],
        "estimated_cost_usd": estimated_cost
    }

# Compare strategies
for strategy in ["prompt_only_bootstrap", "joint_bootstrap", "copa"]:
    cost = estimate_joint_optimization_cost(100, 7, strategy)
    print(f"{strategy}: ${cost['estimated_cost_usd']:.2f}")
</code></pre>
<h3 id="scope-limitations-and-mitigation"><a class="header" href="#scope-limitations-and-mitigation">Scope Limitations and Mitigation</a></h3>
<p>Joint optimization has inherent scope limitations:</p>
<div class="table-wrapper">
<table>
<thead>
<tr><th>Limitation</th><th>Impact</th><th>Mitigation Strategy</th></tr>
</thead>
<tbody>
<tr><td>Domain shift</td><td>Fine-tuned model may not generalize</td><td>Include diverse training data</td></tr>
<tr><td>Prompt brittleness</td><td>Optimized prompts may not transfer</td><td>Test on held-out domains</td></tr>
<tr><td>Computational cost</td><td>Multiple optimization runs needed</td><td>Use progressive optimization</td></tr>
<tr><td>Data requirements</td><td>Need 50-100+ examples</td><td>Data augmentation techniques</td></tr>
<tr><td>Model lock-in</td><td>Fine-tuned weights are model-specific</td><td>Document and version models</td></tr>
</tbody>
</table>
</div>
<pre><code class="language-python">def mitigate_scope_limitations(trainset, valset):
    """
    Apply mitigation strategies for joint optimization limitations.
    """
    mitigations = []

    # 1. Check domain diversity
    domains = set(getattr(ex, 'domain', 'unknown') for ex in trainset)
    if len(domains) &lt; 3:
        mitigations.append({
            "issue": "Limited domain diversity",
            "action": "Add examples from related domains",
            "severity": "medium"
        })

    # 2. Check data size
    if len(trainset) &lt; 50:
        mitigations.append({
            "issue": "Insufficient training data",
            "action": "Use data augmentation or reduce fine-tuning epochs",
            "severity": "high"
        })

    # 3. Recommend validation strategy
    if len(valset) &lt; len(trainset) * 0.2:
        mitigations.append({
            "issue": "Small validation set",
            "action": "Use k-fold cross-validation",
            "severity": "medium"
        })

    return mitigations
</code></pre>
<h2 id="copa-the-comprehensive-solution"><a class="header" href="#copa-the-comprehensive-solution">COPA: The Comprehensive Solution</a></h2>
<p>For maximum performance with proper handling of optimization order and synergy, consider using COPA (Combined Optimization and Prompt Adaptation):</p>
<pre><code class="language-python">from copa_optimizer import COPAOptimizer

# COPA automatically handles:
# 1. Proper optimization order (fine-tune first)
# 2. Synergistic combination of approaches
# 3. Data requirement checks
# 4. Computational budgeting

copa = COPAOptimizer(
    base_model_name="mistralai/Mistral-7B-v0.1",
    metric=your_metric,
    finetune_epochs=3,
    prompt_optimizer="mipro"
)

# Achieves 2-26x improvements on complex tasks
optimized, model = copa.optimize(
    program=YourProgram(),
    trainset=train_examples,
    valset=val_examples
)
</code></pre>
<p>See <a href="09-copa-optimizer.html">COPA: Combined Fine-Tuning and Prompt Optimization</a> for complete documentation.</p>
<h2 id="key-takeaways"><a class="header" href="#key-takeaways">Key Takeaways</a></h2>
<ol>
<li><strong>Data Size Matters</strong>: More data enables more sophisticated optimization</li>
<li><strong>Task Complexity Drives Choice</strong>: Complex tasks benefit from MIPRO</li>
<li><strong>Latency vs Accuracy Trade-off</strong>: Consider your specific needs</li>
<li><strong>Progressive Approach Works</strong>: Start simple, iterate to complex</li>
<li><strong>Cost-Benefit Analysis</strong>: Not all optimization justifies the cost</li>
<li><strong>Ensemble Methods</strong>: Can combine strengths of multiple optimizers</li>
<li><strong>Optimization Order</strong>: Always fine-tune first, then apply prompt optimization</li>
<li><strong>Synergy Is Real</strong>: Combined approaches achieve 2-3.5x better than additive</li>
<li><strong>Know Your Limits</strong>: Joint optimization requires 50-100+ examples</li>
</ol>
<h2 id="quick-decision-tree"><a class="header" href="#quick-decision-tree">Quick Decision Tree</a></h2>
<pre><code>Need optimization?
├─ No → Use baseline
└─ Yes
    ├─ &lt; 20 examples?
    │  └─ BootstrapFewShot (k=4)
    ├─ &lt; 100 examples?
    │  ├─ Need quick results?
    │  │  └─ BootstrapFewShot
    │  └─ Can wait longer?
    │     └─ MIPRO (light)
    ├─ Complex multi-step reasoning?
    │  └─ RPE (evolutionary approach)
    ├─ &gt; 100 examples?
    │  ├─ Context matters?
    │  │  └─ KNNFewShot
    │  └─ Maximum performance?
    │     └─ MIPRO (heavy) or RPE
    └─ Domain-specific &amp; &gt; 1000 examples?
       └─ Consider Fine-Tuning
</code></pre>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<p>Now you have a comprehensive understanding of DSPy optimizers. In the exercises, you’ll apply these concepts to real-world scenarios and learn to make informed optimization decisions.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../05-optimizers/13-comprehensive-examples.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256 246.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg></span>
                            </a>

                            <a rel="next prefetch" href="../05-optimizers/14-multistage-optimization-theory.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg></span>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../05-optimizers/13-comprehensive-examples.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256 246.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg></span>
                    </a>

                    <a rel="next prefetch" href="../05-optimizers/14-multistage-optimization-theory.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg></span>
                    </a>
            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>






        <script src="../clipboard-1626706a.min.js"></script>
        <script src="../highlight-abc7f01d.js"></script>
        <script src="../book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->



    </div>
    </body>
</html>
