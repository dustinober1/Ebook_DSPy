<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Caching and Performance - DSPy: A Practical Guide</title>


        <!-- Custom HTML head -->

        <meta name="description" content="The most comprehensive DSPy guide with complete coverage of 9 research papers, advanced optimization techniques, and production-ready applications">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon-de23e50b.svg">
        <link rel="shortcut icon" href="../favicon-8114d1fc.png">
        <link rel="stylesheet" href="../css/variables-8adf115d.css">
        <link rel="stylesheet" href="../css/general-2459343d.css">
        <link rel="stylesheet" href="../css/chrome-ae938929.css">
        <link rel="stylesheet" href="../css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="../highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="../tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="../ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../assets/print-only-ef201963.css">


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "light";
            const default_dark_theme = "";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc-4ea68664.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                    </div>

                    <h1 class="menu-title">DSPy: A Practical Guide</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>

                    </div>
                </div>


                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <h1 id="caching-and-performance-building-high-performance-dspy-applications"><a class="header" href="#caching-and-performance-building-high-performance-dspy-applications">Caching and Performance: Building High-Performance DSPy Applications</a></h1>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<p>Performance is crucial for production DSPy applications. Language model calls can be expensive and slow, making caching and optimization techniques essential for building responsive, cost-effective systems. This chapter explores comprehensive strategies for optimizing DSPy applications through intelligent caching, batching, and performance monitoring.</p>
<h2 id="understanding-performance-bottlenecks"><a class="header" href="#understanding-performance-bottlenecks">Understanding Performance Bottlenecks</a></h2>
<h3 id="common-performance-issues"><a class="header" href="#common-performance-issues">Common Performance Issues</a></h3>
<ol>
<li><strong>Language Model Latency</strong>: Each API call takes time (500ms-5s)</li>
<li><strong>API Rate Limits</strong>: Providers limit request frequency</li>
<li><strong>Token Costs</strong>: Large prompts and frequent calls increase costs</li>
<li><strong>Memory Usage</strong>: Storing contexts and intermediate results</li>
<li><strong>I/O Operations</strong>: Database queries, file reads, network calls</li>
</ol>
<h3 id="performance-metrics"><a class="header" href="#performance-metrics">Performance Metrics</a></h3>
<pre><code class="language-python">import time
from functools import wraps
from collections import defaultdict, deque

class PerformanceMonitor:
    """Monitor and track DSPy performance metrics."""

    def __init__(self):
        self.metrics = defaultdict(list)
        self.start_times = {}

    def time_function(self, func_name):
        """Decorator to time function execution."""
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                start = time.time()
                result = func(*args, **kwargs)
                end = time.time()
                self.metrics[f"{func_name}_duration"].append(end - start)
                return result
            return wrapper
        return decorator

    def record_metric(self, metric_name, value):
        """Record a custom metric."""
        self.metrics[metric_name].append(value)

    def get_statistics(self, metric_name, window=100):
        """Get statistics for a metric."""
        values = self.metrics[metric_name][-window:]
        if not values:
            return None

        return {
            "count": len(values),
            "average": sum(values) / len(values),
            "min": min(values),
            "max": max(values),
            "latest": values[-1]
        }

# Global performance monitor
perf_monitor = PerformanceMonitor()
</code></pre>
<h2 id="caching-strategies"><a class="header" href="#caching-strategies">Caching Strategies</a></h2>
<h3 id="1-result-caching"><a class="header" href="#1-result-caching">1. Result Caching</a></h3>
<pre><code class="language-python">import hashlib
import pickle
from typing import Any, Optional
import redis
import json

class ResultCache:
    """Cache for DSPy module results."""

    def __init__(self, backend="memory", **kwargs):
        self.backend = backend
        self.setup_cache(backend, **kwargs)

    def setup_cache(self, backend, **kwargs):
        """Setup cache backend."""
        if backend == "memory":
            self.cache = {}
        elif backend == "redis":
            self.cache = redis.Redis(
                host=kwargs.get("host", "localhost"),
                port=kwargs.get("port", 6379),
                db=kwargs.get("db", 0)
            )
        elif backend == "file":
            self.cache_dir = kwargs.get("cache_dir", "./cache")
            import os
            os.makedirs(self.cache_dir, exist_ok=True)
        else:
            raise ValueError(f"Unsupported cache backend: {backend}")

    def _generate_key(self, module_name, args, kwargs):
        """Generate cache key from inputs."""
        # Create a deterministic key from function inputs
        key_data = {
            "module": module_name,
            "args": args,
            "kwargs": kwargs
        }
        key_str = json.dumps(key_data, sort_keys=True, default=str)
        return hashlib.md5(key_str.encode()).hexdigest()

    def get(self, module_name, args, kwargs) -&gt; Optional[Any]:
        """Get cached result."""
        key = self._generate_key(module_name, args, kwargs)

        if self.backend == "memory":
            return self.cache.get(key)
        elif self.backend == "redis":
            cached = self.cache.get(key)
            if cached:
                return pickle.loads(cached)
        elif self.backend == "file":
            import os
            cache_file = os.path.join(self.cache_dir, f"{key}.pkl")
            if os.path.exists(cache_file):
                with open(cache_file, 'rb') as f:
                    return pickle.load(f)

        return None

    def set(self, module_name, args, kwargs, result):
        """Cache result."""
        key = self._generate_key(module_name, args, kwargs)

        if self.backend == "memory":
            self.cache[key] = result
        elif self.backend == "redis":
            self.cache.set(key, pickle.dumps(result))
        elif self.backend == "file":
            cache_file = os.path.join(self.cache_dir, f"{key}.pkl")
            with open(cache_file, 'wb') as f:
                pickle.dump(result, f)

    def clear(self):
        """Clear cache."""
        if self.backend == "memory":
            self.cache.clear()
        elif self.backend == "redis":
            self.cache.flushdb()
        elif self.backend == "file":
            import shutil
            shutil.rmtree(self.cache_dir)
            import os
            os.makedirs(self.cache_dir, exist_ok=True)
</code></pre>
<h3 id="2-semantic-caching"><a class="header" href="#2-semantic-caching">2. Semantic Caching</a></h3>
<pre><code class="language-python">import numpy as np
from sentence_transformers import SentenceTransformer

class SemanticCache:
    """Cache that uses semantic similarity for matching."""

    def __init__(self, similarity_threshold=0.9, model_name="all-MiniLM-L6-v2"):
        self.similarity_threshold = similarity_threshold
        self.model = SentenceTransformer(model_name)
        self.cache = []  # List of (embedding, key, value) tuples

    def _get_embedding(self, text):
        """Get text embedding."""
        return self.model.encode(text)

    def _find_similar(self, query_embedding):
        """Find similar cached items."""
        similarities = []
        for cached_embedding, _, _ in self.cache:
            similarity = np.dot(query_embedding, cached_embedding)
            similarities.append(similarity)

        if similarities and max(similarities) &gt;= self.similarity_threshold:
            best_match_idx = np.argmax(similarities)
            return self.cache[best_match_idx][2]  # Return value
        return None

    def get(self, query_text):
        """Get semantically similar cached result."""
        query_embedding = self._get_embedding(query_text)
        return self._find_similar(query_embedding)

    def set(self, text, result):
        """Cache result with semantic indexing."""
        embedding = self._get_embedding(text)
        self.cache.append((embedding, text, result))

        # Limit cache size
        if len(self.cache) &gt; 1000:
            self.cache = self.cache[-1000:]

    def clear(self):
        """Clear semantic cache."""
        self.cache = []
</code></pre>
<h3 id="3-hierarchical-caching"><a class="header" href="#3-hierarchical-caching">3. Hierarchical Caching</a></h3>
<pre><code class="language-python">class HierarchicalCache:
    """Multi-level cache for optimal performance."""

    def __init__(self):
        # L1: In-memory cache (fastest)
        self.l1_cache = ResultCache("memory")
        # L2: Redis cache (fast)
        self.l2_cache = ResultCache("redis", host="localhost", port=6379)
        # L3: File cache (persistent)
        self.l3_cache = ResultCache("file", cache_dir="./cache")

    def get(self, module_name, args, kwargs):
        """Get from cache, checking levels in order."""
        # L1 Cache
        result = self.l1_cache.get(module_name, args, kwargs)
        if result is not None:
            return result

        # L2 Cache
        result = self.l2_cache.get(module_name, args, kwargs)
        if result is not None:
            # Promote to L1
            self.l1_cache.set(module_name, args, kwargs, result)
            return result

        # L3 Cache
        result = self.l3_cache.get(module_name, args, kwargs)
        if result is not None:
            # Promote to L2 and L1
            self.l2_cache.set(module_name, args, kwargs, result)
            self.l1_cache.set(module_name, args, kwargs, result)
            return result

        return None

    def set(self, module_name, args, kwargs, result):
        """Set in all cache levels."""
        self.l1_cache.set(module_name, args, kwargs, result)
        self.l2_cache.set(module_name, args, kwargs, result)
        self.l3_cache.set(module_name, args, kwargs, result)
</code></pre>
<h2 id="batching-and-bulk-processing"><a class="header" href="#batching-and-bulk-processing">Batching and Bulk Processing</a></h2>
<h3 id="1-batch-processing-module"><a class="header" href="#1-batch-processing-module">1. Batch Processing Module</a></h3>
<pre><code class="language-python">import asyncio
from concurrent.futures import ThreadPoolExecutor
from typing import List, Any

class BatchProcessor:
    """Process multiple items in batches for efficiency."""

    def __init__(self, batch_size=10, max_workers=4):
        self.batch_size = batch_size
        self.max_workers = max_workers

    def process_batch(self, items, process_func):
        """Process items in batches."""
        results = []
        for i in range(0, len(items), self.batch_size):
            batch = items[i:i + self.batch_size]
            batch_results = self._process_single_batch(batch, process_func)
            results.extend(batch_results)
        return results

    def _process_single_batch(self, batch, process_func):
        """Process a single batch."""
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = [executor.submit(process_func, item) for item in batch]
            return [future.result() for future in futures]

    async def process_batch_async(self, items, process_func):
        """Process items in batches asynchronously."""
        results = []
        semaphore = asyncio.Semaphore(self.max_workers)

        async def process_with_semaphore(item):
            async with semaphore:
                return await process_func(item)

        tasks = []
        for i in range(0, len(items), self.batch_size):
            batch = items[i:i + self.batch_size]
            batch_tasks = [process_with_semaphore(item) for item in batch]
            tasks.extend(batch_tasks)

        results = await asyncio.gather(*tasks)
        return results
</code></pre>
<h3 id="2-optimized-module-with-caching"><a class="header" href="#2-optimized-module-with-caching">2. Optimized Module with Caching</a></h3>
<pre><code class="language-python">class OptimizedModule(dspy.Module):
    """DSPy module with built-in caching and batching."""

    def __init__(self, cache=None, batch_size=5):
        super().__init__()
        self.cache = cache or HierarchicalCache()
        self.batch_size = batch_size
        self.batch_processor = BatchProcessor(batch_size=batch_size)
        self.pending_requests = []

    @perf_monitor.time_function("cached_forward")
    def forward(self, *args, **kwargs):
        """Forward pass with caching."""
        # Check cache first
        cache_key = f"{self.__class__.__name__}"
        cached_result = self.cache.get(cache_key, args, kwargs)

        if cached_result is not None:
            perf_monitor.record_metric("cache_hit", 1)
            return cached_result

        # Cache miss - process normally
        perf_monitor.record_metric("cache_miss", 1)
        result = self._forward_impl(*args, **kwargs)

        # Cache result
        self.cache.set(cache_key, args, kwargs, result)

        return result

    def _forward_impl(self, *args, **kwargs):
        """Implement actual forward logic."""
        # Override in subclasses
        raise NotImplementedError

    def batch_forward(self, batch_args, batch_kwargs=None):
        """Process multiple forward passes in batch."""
        if batch_kwargs is None:
            batch_kwargs = [{}] * len(batch_args)

        # Combine args and kwargs for cache lookup
        requests = list(zip(batch_args, batch_kwargs))

        # Check cache for each request
        uncached_requests = []
        uncached_indices = []
        cached_results = [None] * len(requests)

        for i, (args, kwargs) in enumerate(requests):
            cache_key = f"{self.__class__.__name__}"
            result = self.cache.get(cache_key, args, kwargs)
            if result is not None:
                cached_results[i] = result
            else:
                uncached_requests.append((args, kwargs))
                uncached_indices.append(i)

        # Process uncached requests in batch
        if uncached_requests:
            batch_results = self._batch_forward_impl(uncached_requests)

            # Update cache and results
            for i, (args, kwargs) in enumerate(uncached_requests):
                result = batch_results[i]
                cache_key = f"{self.__class__.__name__}"
                self.cache.set(cache_key, args, kwargs, result)
                cached_results[uncached_indices[i]] = result

        return cached_results

    def _batch_forward_impl(self, requests):
        """Implement batch processing logic."""
        # Override in subclasses for batch optimization
        results = []
        for args, kwargs in requests:
            result = self._forward_impl(*args, **kwargs)
            results.append(result)
        return results
</code></pre>
<h2 id="memory-optimization"><a class="header" href="#memory-optimization">Memory Optimization</a></h2>
<h3 id="1-memory-pool"><a class="header" href="#1-memory-pool">1. Memory Pool</a></h3>
<pre><code class="language-python">import weakref
from collections import OrderedDict

class MemoryPool:
    """Memory pool for reusing objects and managing memory."""

    def __init__(self, max_size=1000):
        self.max_size = max_size
        self.pool = OrderedDict()
        self.references = weakref.WeakSet()

    def get(self, obj_type):
        """Get object from pool or create new."""
        key = obj_type
        if key in self.pool:
            obj = self.pool.pop(key)
            # Move to end (most recently used)
            self.pool[key] = obj
            return obj
        else:
            return obj_type()

    def release(self, obj, obj_type=None):
        """Release object back to pool."""
        if obj_type is None:
            obj_type = type(obj)

        if len(self.pool) &lt; self.max_size and obj_type not in self.pool:
            self.pool[obj_type] = obj

    def clear(self):
        """Clear memory pool."""
        self.pool.clear()
</code></pre>
<h3 id="2-context-manager-for-large-objects"><a class="header" href="#2-context-manager-for-large-objects">2. Context Manager for Large Objects</a></h3>
<pre><code class="language-python">class ContextWindow:
    """Manage context window size to prevent memory issues."""

    def __init__(self, max_tokens=4096, tokenizer=None):
        self.max_tokens = max_tokens
        self.tokenizer = tokenizer
        self.contexts = []

    def add_context(self, text):
        """Add context while managing window size."""
        # Estimate tokens (rough approximation)
        estimated_tokens = len(text.split()) * 1.3

        # Remove old contexts if window is full
        while self._total_tokens() + estimated_tokens &gt; self.max_tokens and self.contexts:
            self.contexts.pop(0)

        self.contexts.append(text)

    def _total_tokens(self):
        """Estimate total tokens in contexts."""
        return sum(len(ctx.split()) * 1.3 for ctx in self.contexts)

    def get_context(self):
        """Get current context."""
        return "\n".join(self.contexts)

    def clear(self):
        """Clear all contexts."""
        self.contexts = []
</code></pre>
<h2 id="performance-monitoring-and-analytics"><a class="header" href="#performance-monitoring-and-analytics">Performance Monitoring and Analytics</a></h2>
<h3 id="1-performance-profiler"><a class="header" href="#1-performance-profiler">1. Performance Profiler</a></h3>
<pre><code class="language-python">import cProfile
import pstats
import io
from contextlib import contextmanager

class PerformanceProfiler:
    """Profile DSPy application performance."""

    def __init__(self):
        self.profiler = None

    @contextmanager
    def profile(self):
        """Context manager for profiling."""
        self.profiler = cProfile.Profile()
        self.profiler.enable()
        try:
            yield
        finally:
            self.profiler.disable()

    def get_stats(self, sort_by='cumulative'):
        """Get profiling statistics."""
        if not self.profiler:
            return None

        s = io.StringIO()
        ps = pstats.Stats(self.profiler, stream=s).sort_stats(sort_by)
        ps.print_stats()
        return s.getvalue()

    def get_hotspots(self, top_n=10):
        """Get performance hotspots."""
        if not self.profiler:
            return []

        stats = pstats.Stats(self.profiler)
        return stats.get_stats_profile().func_profiles[:top_n]
</code></pre>
<h3 id="2-real-time-performance-dashboard"><a class="header" href="#2-real-time-performance-dashboard">2. Real-time Performance Dashboard</a></h3>
<pre><code class="language-python">import threading
import time
from collections import deque

class PerformanceDashboard:
    """Real-time performance monitoring dashboard."""

    def __init__(self, window_size=100):
        self.window_size = window_size
        self.metrics = {
            'latency': deque(maxlen=window_size),
            'throughput': deque(maxlen=window_size),
            'error_rate': deque(maxlen=window_size),
            'cache_hit_rate': deque(maxlen=window_size),
            'memory_usage': deque(maxlen=window_size)
        }
        self.running = False
        self.thread = None

    def start_monitoring(self, update_interval=1):
        """Start real-time monitoring."""
        self.running = True
        self.thread = threading.Thread(
            target=self._monitor_loop,
            args=(update_interval,),
            daemon=True
        )
        self.thread.start()

    def stop_monitoring(self):
        """Stop monitoring."""
        self.running = False
        if self.thread:
            self.thread.join()

    def _monitor_loop(self, update_interval):
        """Monitoring loop."""
        while self.running:
            self._collect_metrics()
            time.sleep(update_interval)

    def _collect_metrics(self):
        """Collect current metrics."""
        import psutil
        process = psutil.Process()

        # Memory usage
        self.metrics['memory_usage'].append(process.memory_info().rss / 1024 / 1024)  # MB

    def record_latency(self, latency):
        """Record request latency."""
        self.metrics['latency'].append(latency)

    def record_throughput(self, requests_per_second):
        """Record throughput."""
        self.metrics['throughput'].append(requests_per_second)

    def record_error(self):
        """Record an error."""
        self.metrics['error_rate'].append(1)
        # Also record a 0 for successful requests to maintain ratio
        # In practice, you'd track both successes and errors separately

    def record_cache_hit(self):
        """Record cache hit."""
        self.metrics['cache_hit_rate'].append(1)

    def record_cache_miss(self):
        """Record cache miss."""
        self.metrics['cache_hit_rate'].append(0)

    def get_summary(self):
        """Get performance summary."""
        summary = {}
        for metric_name, values in self.metrics.items():
            if values:
                summary[metric_name] = {
                    'current': values[-1],
                    'average': sum(values) / len(values),
                    'min': min(values),
                    'max': max(values)
                }
        return summary
</code></pre>
<h2 id="optimization-techniques"><a class="header" href="#optimization-techniques">Optimization Techniques</a></h2>
<h3 id="1-prompt-optimization"><a class="header" href="#1-prompt-optimization">1. Prompt Optimization</a></h3>
<pre><code class="language-python">class PromptOptimizer:
    """Optimize prompts for better performance and cost efficiency."""

    def __init__(self):
        self.optimization_history = []

    def optimize_prompt_length(self, prompt, target_length=1000):
        """Optimize prompt to reduce length while maintaining effectiveness."""
        if len(prompt) &lt;= target_length:
            return prompt

        # Remove redundant whitespace
        optimized = re.sub(r'\s+', ' ', prompt)

        # Remove examples if too long
        if len(optimized) &gt; target_length:
            lines = optimized.split('\n')
            # Keep only essential parts
            essential_lines = [
                line for line in lines
                if not line.strip().startswith('# Example')
            ]
            optimized = '\n'.join(essential_lines[:len(essential_lines)//2])

        return optimized

    def optimize_examples(self, examples, max_examples=3):
        """Select most diverse examples."""
        if len(examples) &lt;= max_examples:
            return examples

        # Simple diversity selection (could be more sophisticated)
        selected = []
        for i, example in enumerate(examples):
            if i % max(len(examples) // max_examples, 1) == 0:
                selected.append(example)
            if len(selected) &gt;= max_examples:
                break

        return selected
</code></pre>
<h3 id="2-model-selection-optimization"><a class="header" href="#2-model-selection-optimization">2. Model Selection Optimization</a></h3>
<pre><code class="language-python">class ModelOptimizer:
    """Optimize model selection based on task complexity."""

    def __init__(self):
        self.model_costs = {
            "gpt-3.5-turbo": 0.002,  # per 1K tokens
            "gpt-4": 0.03,
            "gpt-4-turbo": 0.01
        }
        self.model_speeds = {
            "gpt-3.5-turbo": 1.0,  # relative speed
            "gpt-4": 0.2,
            "gpt-4-turbo": 0.5
        }

    def select_model(self, task_complexity, speed_priority=False):
        """Select optimal model based on task complexity."""
        if task_complexity &lt; 0.3:
            return "gpt-3.5-turbo"
        elif task_complexity &lt; 0.7:
            return "gpt-4-turbo" if not speed_priority else "gpt-3.5-turbo"
        else:
            return "gpt-4"

    def estimate_cost(self, model, prompt_tokens, completion_tokens):
        """Estimate API cost."""
        cost_per_1k = self.model_costs[model]
        total_tokens = prompt_tokens + completion_tokens
        return (total_tokens / 1000) * cost_per_1k
</code></pre>
<h2 id="putting-it-all-together"><a class="header" href="#putting-it-all-together">Putting It All Together</a></h2>
<h3 id="high-performance-rag-system"><a class="header" href="#high-performance-rag-system">High-Performance RAG System</a></h3>
<pre><code class="language-python">class HighPerformanceRAG(dspy.Module):
    """Optimized RAG system with all performance enhancements."""

    def __init__(self, cache=None, batch_size=5):
        super().__init__()
        self.cache = cache or HierarchicalCache()
        self.batch_processor = BatchProcessor(batch_size=batch_size)
        self.context_window = ContextWindow(max_tokens=3000)
        self.prompt_optimizer = PromptOptimizer()
        self.model_optimizer = ModelOptimizer()
        self.dashboard = PerformanceDashboard()

        # Components
        self.retrieve = dspy.Retrieve(k=5)
        self.rank = dspy.Predict("query, documents -&gt; ranked_documents")
        self.generate = dspy.Predict("context, query -&gt; answer")

    @perf_monitor.time_function("rag_forward")
    def forward(self, query):
        """Optimized forward pass."""
        start_time = time.time()

        # Check cache
        cached = self.cache.get("rag", (query,), {})
        if cached:
            self.dashboard.record_cache_hit()
            return cached

        self.dashboard.record_cache_miss()

        # Retrieve documents
        retrieved = self.retrieve(query=query)
        documents = retrieved.passages

        # Rank documents (can be batched)
        ranked_result = self.rank(query=query, documents="\n".join(documents))
        ranked_docs = ranked_result.ranked_documents.split('\n')

        # Optimize context window
        self.context_window.clear()
        for doc in ranked_docs:
            self.context_window.add_context(doc)

        # Generate answer with optimized prompt
        context = self.context_window.get_context()
        optimized_prompt = self.prompt_optimizer.optimize_prompt_length(
            f"Context: {context}\nQuery: {query}"
        )

        result = self.generate(context=context, query=query)

        # Cache result
        final_result = dspy.Prediction(
            answer=result.answer,
            context=ranked_docs
        )
        self.cache.set("rag", (query,), {}, final_result)

        # Record metrics
        latency = time.time() - start_time
        self.dashboard.record_latency(latency)

        return final_result

    def batch_forward(self, queries):
        """Process multiple queries efficiently."""
        start_time = time.time()

        # Check cache for all queries
        uncached_queries = []
        uncached_indices = []
        cached_results = [None] * len(queries)

        for i, query in enumerate(queries):
            cached = self.cache.get("rag", (query,), {})
            if cached:
                cached_results[i] = cached
                self.dashboard.record_cache_hit()
            else:
                uncached_queries.append(query)
                uncached_indices.append(i)
                self.dashboard.record_cache_miss()

        # Process uncached queries in batch
        if uncached_queries:
            batch_results = self._batch_process_queries(uncached_queries)

            # Cache results and fill return array
            for i, result in enumerate(batch_results):
                query = uncached_queries[i]
                idx = uncached_indices[i]
                self.cache.set("rag", (query,), {}, result)
                cached_results[idx] = result

        # Record throughput
        throughput = len(queries) / (time.time() - start_time)
        self.dashboard.record_throughput(throughput)

        return cached_results

    def _batch_process_queries(self, queries):
        """Process multiple queries in batch."""
        # Retrieve all documents
        all_documents = []
        for query in queries:
            retrieved = self.retrieve(query=query)
            all_documents.append(retrieved.passages)

        # Rank documents in parallel
        def rank_query(args):
            query, docs = args
            rank_result = self.rank(query=query, documents="\n".join(docs))
            return rank_result.ranked_documents.split('\n')

        ranked_results = self.batch_processor.process_batch(
            list(zip(queries, all_documents)),
            rank_query
        )

        # Generate answers
        def generate_answer(args):
            query, docs = args
            context = "\n".join(docs)
            result = self.generate(context=context, query=query)
            return dspy.Prediction(answer=result.answer, context=docs)

        answers = self.batch_processor.process_batch(
            list(zip(queries, ranked_results)),
            generate_answer
        )

        return answers
</code></pre>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<h3 id="1-cache-strategy"><a class="header" href="#1-cache-strategy">1. Cache Strategy</a></h3>
<ul>
<li>Use hierarchical caching for optimal hit rates</li>
<li>Implement cache warming for frequently accessed data</li>
<li>Set appropriate TTL values based on data volatility</li>
<li>Monitor cache hit rates and adjust strategies</li>
</ul>
<h3 id="2-batching-strategy"><a class="header" href="#2-batching-strategy">2. Batching Strategy</a></h3>
<ul>
<li>Batch requests when possible to reduce overhead</li>
<li>Balance batch size against latency requirements</li>
<li>Use async processing for independent operations</li>
<li>Implement backpressure for high-throughput systems</li>
</ul>
<h3 id="3-memory-management"><a class="header" href="#3-memory-management">3. Memory Management</a></h3>
<ul>
<li>Use context windows to limit memory usage</li>
<li>Implement memory pools for object reuse</li>
<li>Monitor memory usage and implement limits</li>
<li>Use generators for large datasets</li>
</ul>
<h3 id="4-performance-monitoring"><a class="header" href="#4-performance-monitoring">4. Performance Monitoring</a></h3>
<ul>
<li>Track key metrics: latency, throughput, error rate</li>
<li>Set up alerts for performance degradation</li>
<li>Use profiling to identify bottlenecks</li>
<li>Continuously optimize based on metrics</li>
</ul>
<h2 id="key-takeaways"><a class="header" href="#key-takeaways">Key Takeaways</a></h2>
<ol>
<li><strong>Caching dramatically reduces</strong> API costs and latency</li>
<li><strong>Batch processing improves</strong> throughput efficiency</li>
<li><strong>Memory optimization prevents</strong> system overload</li>
<li><strong>Performance monitoring</strong> is essential for optimization</li>
<li><strong>Hierarchical strategies</strong> provide best results</li>
<li><strong>Context management</strong> balances quality and performance</li>
</ol>
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<p>In the next section, we’ll explore <strong>Async and Streaming</strong> techniques for building real-time DSPy applications that can handle continuous data flows and concurrent operations.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../07-advanced-topics/01-adapters-tools.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256 246.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg></span>
                            </a>

                            <a rel="next prefetch" href="../07-advanced-topics/03-async-streaming.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg></span>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../07-advanced-topics/01-adapters-tools.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256 246.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg></span>
                    </a>

                    <a rel="next prefetch" href="../07-advanced-topics/03-async-streaming.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg></span>
                    </a>
            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>






        <script src="../clipboard-1626706a.min.js"></script>
        <script src="../highlight-abc7f01d.js"></script>
        <script src="../book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->



    </div>
    </body>
</html>
